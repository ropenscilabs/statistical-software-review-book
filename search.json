[{"path":"index.html","id":"welcome","chapter":"1 Welcome","heading":"1 Welcome","text":"Welcome rOpenSci’s system peer-review \nstatistical software R packages beyond. system extends existing\nsystem software peer\nreview, expanding \nscope \ninclude explicitly statistical software. , direct extension \nrOpenSci Packages: Development, Maintenance, \nPeer Review. book provides guidelines \nauthors develop statistical software, editors reviewers\nprocesses peer review statistical software.invited contribute project filing suggestions issues\nbook’s GitHub\nrepository.\nalso dedicated area discussion rOpenSci\nforum.\nFeedback standards particularly welcome.project lucky support great advisory editorial\ncommittee. committee helped us along way outreach \nstatistical communities, vetting community input prioritizing work.Ben Bolker\n(@bolkerb) McMaster University, CanadaRebecca Killick, Lancaster University, UKStephanie Hicks\n(@stephaniehicks), Johns Hopkins\nUniversity, USAPaula Moraga, King Abdullah University \nScience Technology, Saudi ArabiaLeonardo Collado-Torres\n(@lcolladotor), Lieber Institute \nBrain Development, USAToby Hocking, Northern Arizona University, USAWe also grateful former members advisory board:Max Kuhn\n(@topepos), RStudioMartin Morgan\n(@mt_morgan), Roswell Park Comprehensive\nCancer CenterThis work supported Sloan\nFoundation\norganized R Consortium Working\nGroup.","code":""},{"path":"index.html","id":"contributors","chapter":"1 Welcome","heading":"1.1 Contributors","text":"contributions project gratefully acknowledged using allcontributors package following -contributors specification. Contributions kind welcome!","code":""},{"path":"index.html","id":"content","chapter":"1 Welcome","heading":"1.1.1 Content","text":"","code":""},{"path":"index.html","id":"issue-authors","chapter":"1 Welcome","heading":"1.1.2 Issue Authors","text":"","code":""},{"path":"overview.html","id":"overview","chapter":"2 Overview of the Project and of this Book","heading":"2 Overview of the Project and of this Book","text":"book main document rOpenSci’s project expand peer review \ninclude explicitly statistic software. intended aid software\ndevelopers intending submit statistical software peer-review, \nreviewers statistical software. additional aim project, \ndocumentation, serve blueprint future adoption \nadaptation areas, including computer languages.present book considered extension\nrOpenSci’s guide software Development, Maintenance, Peer\nReview (“Dev Guide”). guidelines \nexpectations software presented Dev Guide also apply \nstatistical software newly expanded system, document\ndescribing additional guides expectations explicitly statistical\nsoftware. Dev Guide thus considered essential reading prior \ncurrent book.chapter summarises overall project aims, scope statistical software\ncurrently able consider, provides brief overview \nstructure purpose book. consists following sections:Motivation: separate system statistical\nsoftware? explain necessity advantages \nstatistical software developed according concretes sets explicit\nstandards.Motivation: separate system statistical\nsoftware? explain necessity advantages \nstatistical software developed according concretes sets explicit\nstandards.Scope Statistical Software Review \nsummarise working definition “statistical software”, scope \nsoftware currently able considered project. scope \nbased explicit categories statistical software, also\nbriefly described.Scope Statistical Software Review \nsummarise working definition “statistical software”, scope \nsoftware currently able considered project. scope \nbased explicit categories statistical software, also\nbriefly described.Prior Art briefly describe \ncomparable systems assessing standardising software.Prior Art briefly describe \ncomparable systems assessing standardising software.Use Book describe \nbook intended read used practice.Use Book describe \nbook intended read used practice.","code":""},{"path":"overview.html","id":"overview-motivation","chapter":"2 Overview of the Project and of this Book","heading":"2.1 Project Motivation","text":"official description R declares “software environment \nstatistical computing graphics”, yet rOpenSci\npreviously deemed explicitly statistical packages scope, owing among\nfactors perceived difficulty devising appropriate system \nassessment review. R nevertheless explicitly statistical computing\nenvironment, rOpenSci developed project expand peer review\nsystem include statistical software., project also offered opportunity reconsider \npotentially improve aspects rOpenSci’s current system peer review, \noperated five years time project began, already\nreviewed >200 packages, primarily areas data life cycle management.\nform packages continues strongly influenced Dev\nGuide, presents sets \n“guidelines” packages \nexpected “meet”. guidelines nevertheless necessarily general, \nlargely developed ongoing response successive developments \ntechnology support software development, continuous integration\nservices. Although Dev Guide effectively provides set “standards” \nsoftware expected adhere, alignment software \nstandards necessarily systematic, particular \ndirect way ascertain standards given piece software\nadheres, may diverge.present project reflects systematic alignment software \nstandards, one enables automated ongoing identification \nstandards given piece software complies. following sets \nstandards statistical software thus far extensive \nprevious “guidelines”, provide ongoing assurance users standard\nsoftware accepted within system, including systematic identification \nways software may diverge standards, explanations .assurance important many areas scientific research, notably\nincluding subject regulation pharmaceutical trials. Software\nused trials must “validated”,\ngenerally process identifying risks associated using\nsoftware. contexts,\nsystem fosters confidence use software assessed according \nstandards. developers, system provides system graded “badges” able\nused identify publicise assessment software \nmeeting exceeding standards set system.","code":""},{"path":"overview.html","id":"overview-scope","chapter":"2 Overview of the Project and of this Book","heading":"2.2 Scope of Statistical Software Review","text":"","code":""},{"path":"overview.html","id":"the-r-language","chapter":"2 Overview of the Project and of this Book","heading":"2.2.1 The R Language","text":"present project represents direct expansion rOpenSci’s current\nscope include\nspecifically statistical software, retaining restriction software\nform R packages. Nevertheless, necessarily mean \nprimary language package needs R. Many R packages include\ncode variety languages, following table summarising\nstatistics top ten languages \n15,948 CRAN packages\n23 Jun 2021 (including code /R, /src, /inst\ndirectories package).Table 2.1: Proportion code lines different languages CRAN packages.Close one half code R packages date written \nR language, clearly justifying primary focus upon language. Collating\npossible ways packaging combining C C++ code yields\n17,752,262 lines code \n33% code, indicating \n75% code \nwritten either R C/C++. anticipate large majority submissions\ncoded one primary languages, cultivate community\nreviewers expertise languages. R packages may nevertheless\nincorporate algorithms coded number languages (Rust), \npackage considered --scope basis computer language\nalone. Developers using less common languages may nevertheless face longer\nprocessing times allow finding reviewers appropriate skills \nlanguages.","code":""},{"path":"overview.html","id":"overview-categories","chapter":"2 Overview of the Project and of this Book","heading":"2.2.2 Categories of Statistical Software","text":"scope statistical software able submitted peer review \nprimarily defined following list categories. software fits\none categories may deemed -scope, submitted \nreview, software can described categories\ngenerally deemed scope. categories \nprimarily defined corresponding standards given detail Chapter\n6, chapter provides brief descriptions categories \naid developers initially estimating whether software may scope.Empirical analyses described Appendix .2 \ndevised identify sub-domains within statistical software, \ndate developed standards following categories:Bayesian Monte Carlo RoutinesRegression Supervised LearningDimensionality Reduction, Clustering, Unsupervised LearningExploratory Data Analysis (EDA) Summary StatisticsTime Series AnalysesMachine LearningSpatial AnalysesEach categories represented set standards, briefly\ndescribed following sub-section. anticipate submissions \ncommonly fit , described , multiple categories, standards\nalso devised inter-compatible possible. Moreover,\nalignment specific categories may always straightforward, \nanticipate submissions require negotiation developers\neditors identify appropriate categories prior full submission.also intend expand system include additional four categories\n:Wrapper PackagesNetwork Analysis SoftwareProbability DistributionsWorkflow SupportWhile software latter four categories beyond scope current\nstandards, invite software developers interested submitting software\nwithin one categories contact us directly enquire \nstatus associated standards, possibility submitting. Finally,\nanticipate sets standards expand time, openly\ninvite form discussion possibility expanding definition \ninclude additional categories.following sub-sections provide brief descriptions chosen\ncategories terms general characteristics inter-relationships\ncategories within empirical analyses.\nstandards Chapter 6 necessarily consider category\nseparately. nevertheless degree overlap categorical\ndefinitions important appreciate. following brief\ndescriptions attempt state potentially problematic \nconfounding areas overlap ambiguity categorical definitions.\nTitles sub-section link directly corresponding standards \nChapter 6.","code":""},{"path":"overview.html","id":"bayesian-and-monte-carlo-routines","chapter":"2 Overview of the Project and of this Book","heading":"2.2.2.1 Bayesian and Monte Carlo Routines","text":"Bayesian Monte Carlo software centres quantitative estimation \ncomponents Baye’s theorem,\nparticularly estimation application prior /posterior probability\ndistributions. procedures implemented estimate properties \ndistributions commonly based random sampling procedures, hence referred\n“Monte Carlo” routines reference random yet quantifiable\nnature casino games.Packages implementing otherwise relying Bayesian Monte Carlo routines\namongst common selected categories. Although roughly equal\nfrequency several categories, category represents central\n“hub” categories discerned empirical\nanalyses. indicates software category\nlikely others also described additional categories.","code":""},{"path":"overview.html","id":"regression-and-supervised-learning","chapter":"2 Overview of the Project and of this Book","heading":"2.2.2.2 Regression and Supervised Learning","text":"Regression Software implements algorithms aim construct analyse one\nmappings two defined data sets (example, set \n“independent” data, \\(X\\), set “dependent” data, \\(Y\\)). contrast, \nanalogous category Unsupervised Learning Software aims construct \nanalyse one mappings defined set input independent\ndata, second set “output” data necessarily known \ngiven prior analysis.Common purposes Regression Software fit models estimate\nrelationships make predictions specified inputs outputs.\nRegression Software includes tools inferential predictive foci,\nBayesian, frequentist, probability-free Machine Learning (ML) approaches,\nparametric non-parametric approaches, discrete outputs (\nclassification tasks) continuous outputs, models algorithms specific\napplications data time series spatial data. many cases\nstandards specific subcategories may apply.category represents important intermediate node emprical\nnetwork Bayesian/Monte Carlo Machine\nLearning (ML) algorithms, well strongly connected several \nnodes. many regression interpolation algorithms developed part\ngeneral frameworks within contexts, nevertheless\nsufficiently many examples regression interpolation algorithms unrelated\ncontexts warrant existence distinct category. \nsaid, algorithms within category share little common, \nimplementation generally devised explicit applied purpose may\ndifficult relate implementations category.","code":""},{"path":"overview.html","id":"overview-unsupervised","chapter":"2 Overview of the Project and of this Book","heading":"2.2.2.3 Dimensionality Reduction, Clustering, and Unsupervised Learning","text":"Software category distinguished Regression Software though \nlatter aiming construct analyse one mappings two defined\ndata sets (example, set “independent” data, \\(X\\), set \n“dependent” data, “Y”), whereas Unsupervised Learning Software aims \nconstruct analyse one mappings defined set input \nindependent data, second set “output” data necessarily\nknown given prior analysis. key distinction Unsupervised\nLearning Software Algorithms output data\nrepresent (generally numerical) transformations input data set, \noutput data discrete labels applied input data. Examples\nformer type include dimensionality reduction ordination software \nalgorithms, examples latter include clustering discrete\npartitioning software algorithms. One primary problems presented \nalgorithms category constrained yield result\nindependent measure correctness accuracy\n(Estivill-Castro 2002). can make assessment accuracy \nreliability algorithms difficult.node representing dimensionality reduction empirical\nnetwork almost central Bayesian/Monte Carlo\ncategory, indicating software category also likely \ndescribed additional categories.","code":""},{"path":"overview.html","id":"overview-eda","chapter":"2 Overview of the Project and of this Book","heading":"2.2.2.4 Exploratory Data Analysis (EDA) and Summary Statistics","text":"Exploration part data analyses, Exploratory Data Analysis (EDA)\nsomething entered exited point prior \n“real” analysis. Exploratory Analyses also strictly limited Data,\nmay extend exploration Models data. category \nthus equally termed, “Exploratory Data Model Analysis”, yet opt \nutilise standard acronym EDA document.EDA nevertheless somewhat different many categories included ,\nprimarily ,EDA software often strong focus upon visualization, category\notherwise explicitly excluded scope project \npresent stage.assessment EDA software requires addressing general questions\nsoftware categories, notably including important\nquestion intended audience(s).empirical analyses revealed strong connection\nEDA visualisation software, EDA software nevertheless differed\nalso connected calculation presentation summary\nstatistics, network relationships reflecting inter-relationships\ndata components.","code":""},{"path":"overview.html","id":"overview-ts","chapter":"2 Overview of the Project and of this Book","heading":"2.2.2.5 Time Series Analyses","text":"category Time Series software arguably easier define \npreceding categories, represents software primary input \nintended temporally structured data. Importantly, “temporally\nstructured” may often imply temporally ordered, need necessarily \ncase. primary definition temporally structured data \npossess kind index can used extract temporal relationships.","code":""},{"path":"overview.html","id":"overview-ml","chapter":"2 Overview of the Project and of this Book","heading":"2.2.2.6 Machine Learning","text":"Machine Learning (ML) routines play central role modern statistical\nanalyses, ML node empirical network\ndiagram roughly equally central, equally\nconnected, Bayesian Monte Carlo node. Machine Learning algorithms\nrepresent perhaps difficult algorithms develop\nstandards methods comparison. input output data can \ncategorically different even incomparable, even may \ncomparable, abiding aims different ML algorithms can differ sufficiently\nmake comparison outputs otherwise equivalent inputs largely\nmeaningless. general ecosystem ML software within R nevertheless offers\nnumber tools may adapted specific stages many ML\nworkflows, may accordingly provide useful contexts \naligning reviewing software standards, even “benchmark”\ncomparisons. Divided three main steps input -> processing -> output,\nuseful tools include:Input Data \nvtreat package “prepares\nmessy real world data predictive modeling reproducible \nstatistically sound manner.” routines package perform series \ntests general sanity input data, may prove generally useful part\nrecommended ML workflow.Algorithms aforementioned diversity ML algorithms fostered \ndeveloped several packages offering unified interfaces. input data,\nstandards suggest particular package use , \nleast considered comparative benchmarks assess\npackages. mlr3\ntidymoels collection packages reflect\nunified ML workflows modular extensible interfaces range ML\nroutines.Output Data several extant packages (post-)processing data\noutput ML algorithms. Many, perhaps even , primarily aim \nderive insightful visualisations output, whether interactive\n(JavaScript-based) form, \nmodelStudio \nmodelDown packages, \nstatic plots using internal graphical routines R, iml\n(Interpretable Machine\nLearning) package. \nlatter package offers host additional functionality useful interpreting\noutput ML algorithms, may prove useful general\nstandards-based contexts.","code":""},{"path":"overview.html","id":"overview-spatial","chapter":"2 Overview of the Project and of this Book","heading":"2.2.2.7 Spatial Analyses","text":"Spatial analyses long tradition R, summarised reflected \nCRAN Task Views Spatial\nSpatio-Temporal\ndata analyses. task views also make immediately apparent \nmajority development domains representations\nspatial data, rather statistical analyses per se.\nSpatial statistical analyses nevertheless strong R, notably\nspatstat \ngstat packages, first published\n2002 2003, respectively.Spatial analyses entail number aspects , necessarily unique\nisolation, considered combination offer sufficiently unique\nchallenges warrant category. unique aspects\ninclude:generally firm embeddedness two dimensionsFrequent assumptions continuous rather discrete processes\n(point-pattern processes notwithstanding)pervasive decrease statistical similarity increasing distance - \n-called “First Law Geography” - observe pervasive\ndifficulties arising auto-correlated observations.huge variety statistical techniques kriging triangulation\ndeveloped almost exclusive application spatial\ndomains.unique challenges arising domain Spatial Temporal\nAnalyses.","code":""},{"path":"overview.html","id":"overview-distributions","chapter":"2 Overview of the Project and of this Book","heading":"2.2.2.8 Probability Distributions","text":"(yet scope) category probability distributions outlier\npreceding network diagram, connected ML \nregression/interpolation algorithms. nevertheless included \ndistinct category anticipate software explicitly represents\nrelies probability distributions subject distinct standards \nassessment procedures, particularly enabling routines tested \nrobustness variety perturbations assumed distributional forms.Packages fall within category include:univariateML \n, “R package maximum likelihood estimation univariate\ndensities,” support 20 different forms probability\ndensity.kdensity ,\n“R package kernel density estimation parametric starts \nasymmetric kernels.” package implements effectively non-parametric\napproach estimating probability densities.overlapping, \n, “R package estimating overlapping empirical distributions.”obverse process estimating fitting probability distributions \narguably drawing samples defined distributions, \nhumanleague package \nexample. package particular application synthesis discrete\npopulations, yet implementation quite generic powerful.","code":""},{"path":"overview.html","id":"overview-wrapper","chapter":"2 Overview of the Project and of this Book","heading":"2.2.2.9 Wrapper Packages","text":"(yet scope) “Wrapper” packages provide interface \npreviously-written software, often different computer language \noriginal implementation. category reasonably unambiguous, \nmay instances “wrapper” additionally offers extension beyond\noriginal implementations, portion package’s\nfunctionality may “wrapped.” Rather internally bundling wrapping\nsoftware, package may also serve wrapper thorough providing access \nexternal interface, web server. Examples potential wrapper\npackages include following:\ngreta package\n(accompanying\nJOSS article) “\nwriting statistical models fitting MCMC optimisation”\nprovides wrapper around google’s\nTensorFlow library. also clearly workflow package, aiming \nprovide single, unified workflow generic machine learning processes\nanalyses.\nnse package (accompanying\nJOSS paper) \noffers “multiple ways calculate numerical standard errors (NSE) \nunivariate (multivariate cases) time series,” providing\nunified interface several R packages provide 30 NSE\nestimators. example wrapper package wrap\neither internal code external interfaces, rather effectively “wraps”\nalgorithms collection R packages.Key Considerations: many wrapper packages may feasible\nreviewers (authors) evaluate quality correctness wrapped\nsoftware, review limited interface added value provided,\nstatistical routines within.Wrapper packages include extent functionality represented wrapped\ncode, computer language wrapped.\n- Internal External: software internally wrap bundle\npreviously developed routines, provide wrapper around \nexternal service? latter, kind service (web-based, \nform remote access)?\n- Language: internally-bundled routines, computer language\ne routines written? bundled? (R packages: \n./src? ./inst? Elsewhere?)\n- Testing: software test correctness wrapped component?\nrely tests wrapped component elsewhere?\n- Unique Advances: unique advances software offer beyond\noffered (internally externally) wrapped software?","code":""},{"path":"overview.html","id":"overview-networks","chapter":"2 Overview of the Project and of this Book","heading":"2.2.2.10 Networks","text":"(yet scope) Network software particular area application \nmight often considered generic algorithms, example\ndescribed \ngrapherator package, \ncategory appropriate input data assumed \nrepresent particular form graphical relationship, \nalgorithms implemented package necessarily specific graphs.\npackage might nevertheless useful developing standards ,\n“implements modular approach benchmark graph generation focusing \nundirected, weighted graphs”. package, indeed several others developed\nauthor Jakob Bossek, may useful \ndeveloping benchmarks comparison graph network models algorithms.Cases software might assessed using generic graph generators\nbenchmarks include:mcMST, “\ntoolbox multi-criteria minimum spanning tree problem.”gwdegree, \npackage , “improving interpretation geometrically-weighted degree\nestimates exponential random graph models.” package essentially\ngenerates one key graph statistic particular class input graphs,\nyet clearly amenable benchmarking, well measures stability \nresponse variable input structures.Network software likely difficult assess compare \ngeneral way includes:tcherry package\n“Learning structure tcherry trees,” \nparticular ways representing relationships categorical data. \npackage uses maximum likelihood techniques find best tcherry tree \nrepresent given input data set. Although clearly form network\nsoftware, package might considered better described \ncategories, accordingly directly assessed assessable \nstandards derived category.BNLearn package “learning \ngraphical structure Bayesian networks.” indubitably network\npackage, yet domain application likely renders incomparable \nnetwork software, difficult assess standardised way.","code":""},{"path":"overview.html","id":"overview-workflow","chapter":"2 Overview of the Project and of this Book","heading":"2.2.2.11 Workflow Support","text":"(yet scope) “Workflow” software may implement particular methods\nalgorithms, rather support tasks around statistical process. \nmany cases, may generic tasks apply across methods. \ninclude:Classes (whether explicit ) representing processing input \noutput data;Generic interfaces multiple statistical methods algorithms;Homogeneous reporting results variety methods algorithms;\nandMethods synthesise, visualise, otherwise collectively report \nanalytic results.Methods Algorithms software may provide specific interface \nspecific method algorithm, although may also general offer\nseveral “workflow” aspects, ambiguity may often arise\ntwo categories. note particular “workflow” node \n\ninteractive network diagram\nmentioned strongly connected “machine learning” node,\ngenerally reflecting software attempts unify varied interfaces \nvaried platforms machine learning.Among numerous examples software category :\nmlr3 package (accompanying\nJOSS paper), provides, “modern object-oriented machine learning\nframework R.”\nfmcmc package\n(accompanying\nJOSS paper), provides unified framework workflow \nMarkov-Chain Monte Carlo analyses.\nbayestestR package (accompanying\nJOSS paper)\n\"describing effects uncertainty, existence significance\nwithin Bayesian framework. packages includes \nalgorithmic implementations, primarily intended aid general\nBayesian workflows unified interface.Workflows also commonly required developed specific areas \napplication, exemplified \ntabular package (accompanying\nJOSS article “Analysis, Seriation, visualisation Archaeological\nCount Data”.Key Considerations: Workflow packages popular add considerable value\nefficiency users. One challenge evaluating packages \nimportance API design potential subjectivity . instance,\nmlr3 well tidymodels similar uses providing common interface\nmultiple predictive models tools automating processes across \nmodels. Similar, multiple packages different approaches handling MCMC\ndata. package makes different choices design different priorities,\nmay may agree reviewers’ opinions applications. Despite \ndifferences, may possible evaluate packages internal cohesion,\nadherence sufficiently clearly stated design goal. Reviewers may able\nevaluate whether package provides unified workflow interface\npackages - require standard relative improvement \nfield rather baseline standards.packages also often contain numerical routines (cross-validation,\nperformance scoring, model comparison), can evaluated correctness\naccuracy.","code":""},{"path":"overview.html","id":"overview-prior-art","chapter":"2 Overview of the Project and of this Book","heading":"2.3 Prior Art","text":"","code":""},{"path":"overview.html","id":"ropensci","chapter":"2 Overview of the Project and of this Book","heading":"2.3.1 rOpenSci","text":"rOpenSci’s current software peer-review process, detailed developer\nguide, based \nblend practices peer review academic practices code review \nopen-source projects. Review takes place via issue thread \n“software-review” repository \nGitHub. review process \nentirely open, issue thread used manage entire process,\ncoordinated rOpenSci’s editors. initial screening scope minimal\nqualification editors, two reviewers provide comments feedback software\npackages. one rounds revisions, packages reach point \napproval, point “accepted” rOpenSci, symbolized \nbadge system, (generally) transferring software \nauthors’ private domain \ngithub.com/ropensci domain.","code":""},{"path":"overview.html","id":"the-journal-of-open-source-software","chapter":"2 Overview of the Project and of this Book","heading":"2.3.2 The Journal of Open Source Software","text":"Journal Open Source Software (JOSS) based\nrOpenSci follows similar approach, greater automation broader\nscope. Journal Statistical Software conducts closed review \nmanuscript software, fewer prescriptive standards. reviewing\npackages acceptance repository,\nBioConductor conducts open\nreview primarily\naimed maintaining minimum standards inter-compatibility.","code":""},{"path":"overview.html","id":"the-debian-system","chapter":"2 Overview of the Project and of this Book","heading":"2.3.3 The Debian System","text":"development software open-source Debian Operating\nSystem guided Debian Developers Debian\nMaintainers. Expressed roughly, maintainers individuals responsible \nmaintenance particular pieces software, developers engage \nactivities supporting development operating system whole. \nsubmission review process Debian almost entirely automated, based \ntools software checker,\nlintian. Debian differs fundamentally \nsystem proposed centred around trust verification \npeople rather software. Submission software Debian largely\nautomatic, bug-free software may often progress automatically \nvarious stages towards acceptance. Software may, however, submitted \nofficial Debian Maintainers Developers. People can become developers \nmaintainers sponsored existing members, subject\nreview potential contribution may able make broader\nDebian community. (Details can seen chapter Debian\nhandbook.)general process software submission acceptance Debian may\ndirect relevance, versioning policy provides useful basis \nversioning system. ongoing development Debian system\nassociated packages proceeds accordance versioned policy\nmanual. new packages\nmust comply current standards time submission, \nlabelled latest version standards comply, noting\n,package old Standards-Version value bug …\njust means -one yet reviewed package changes \nstandards mind.new version standards accompanied simple\nchecklist\ndifferences, explicitly indicating differences divergences \nprevious versions. long software continues pass tests, upgrading\ncurrent standards remains optional. Failing tests response \nupgrading standards serve trigger review software. nominated\nstandards version may updated review confirmed compliance \ncurrent standards. present project adapts aspects \nDebian system, described .","code":""},{"path":"overview.html","id":"other-potential-models","chapter":"2 Overview of the Project and of this Book","heading":"2.3.4 Other Potential Models","text":"Linux Core Infrastructure Initiative\nprovides badges projects meeting development best\npractices.\nBadges graded (passing/silver/gold), awarded package authors\nself-certifying implemented items checklist.","code":""},{"path":"overview.html","id":"overview-use-of-book","chapter":"2 Overview of the Project and of this Book","heading":"2.4 Use of this Book","text":"book primarily intended used two primary audiences \nsoftware developers reviewers. mentioned , also intended\nserve “blueprint” adopted adapted areas, including\ncomputer languages, domains application. book two\nprimary entry points two primary audiences, following\nchapter providing extensive guidelines package development, submission, \nmaintenance, subsequent chapter providing guidelines reviewers \nsoftware submissions. audiences need refer actual\nstandards, general category-specific. book also\nincludes important guidelines editors, particular instruct \ncapabilities automated ropensci-review-bot, associated\nautomatic package checking routines.Importantly, entire project strives cultivate diverse, inclusive, \ngeographically expansive communities, terms software , \nassociated communities developers, reviewers, users. Note \naspects community explicitly addressed throughout \nremainder document, important future revisions return \npoint, ensure following sections appropriately\nmodified ensure effective consideration incorporation \nrepresentativeness inclusiveness communities cultivating surrounding\nsoftware.","code":""},{"path":"pkgdev.html","id":"pkgdev","chapter":"3 Guide for Authors","heading":"3 Guide for Authors","text":"current chapter considered extension corresponding\n“Guide Authors” \nrOpenSci’s “Dev Guide”. principles package development described \nalso apply statistical packages, chapter describing additional\nprocesses practices packages intended submission statistical\nsoftware peer review system.major additional process documentation package complies\ngeneral category-specific standards given Chapter\n6. Authors need document within software every point\ncomplies every general every applicable category-specific\nstandard listed chapter. process facilitated \nsrr package, described \ndetail Sub-section 3.4, .Prior sub-section, chapter begins consideration scope\nstatistical software able considered review, followed \ndescriptions two tools intended used entire process \npackage development. first tool pkgcheck\npackage can used\nconfirm whether software ready submission , enables authors\nlocally run suite checks automatically run package\nsubmission. subsequent sub-section describes autotest\ntool, intended \nused entire process package development. third\nsub-section describes use srr\npackage address major\ntask aligning software general category-specific\nstandards statistical software, final sub-section\ndescribes final step specifying grade badge authors aiming\n.","code":""},{"path":"pkgdev.html","id":"scope","chapter":"3 Guide for Authors","heading":"3.1 Scope","text":"first important task prior submitting package estimate whether\npackage likely considered within scope statistical software.\ndescribed Overview, packages generally\nconsidered scope fit one categories listed\n. Prior submission, authors must choose one\ncategories, document software aligns \ncorresponding standards given Chapter 6, according \nprocedures described . software can aligned\none sets category-specific standards definition \nconsidered scope.Authors encouraged contact us point prior , ,\ndevelopment, ask whether package might scope, \ncategories might fit within. Categorisation packages may always \nstraightforward, particularly encourage authors unsure \nwhether package belongs particular category contact us \ndiscussion. initial judgement whether package belongs \nparticular category may gained examining respective standards. \npackage large number standards particular category may \nconsidered applicable (regardless whether actually \nchecked) likely fit within category. determined \npackage likely fit one -scope categories,\n’ll need apply three primary development tools described \nfollowing two sub-sections.","code":""},{"path":"pkgdev.html","id":"the-pkgcheck-package","chapter":"3 Guide for Authors","heading":"3.2 The pkgcheck package","text":"pkgcheck package can\nused confirm whether software ready submission . checks\nimplemented within package also automatically run upon submission, \npackages expected successfully pass checks prior initial\nsubmission. Packages may submitted main pkgcheck()\nfunction\nindicates , clearly stating,package may submittedThis function accepts single argument local path \npackage checked, returns detailed list checks associated\nresults. return object summary method prints formatted\nresult console indicating whether package ready \nsubmission . See main package\nwebsite details.pkgcheck()\nfunction\nalso applied packages upon initial submission, response \nropensci-review-bot print results issue. unlikely\ncircumstances package unable pass particular checks, explanations\ngiven upon submission checks fail, review may\nproceed spite failures.example result pkgcheck()\nfunction\nmay seen applying skeleton srr (Software Review\nRoclets) package:","code":"\npath <- srr::srr_stats_pkg_skeleton ()\nchecks <- pkgcheck::pkgcheck (path)\nsummary (checks)## \n## ── demo 0.0.0.9000 ─────────────────────────────────────────────────────────────\n## \n## ✔ Package uses 'roxygen2'\n## ✖ Package does not have a 'contributing.md' file\n## ✖ Package does not have a 'CITATION' file\n## ✖ Package does not have a 'codemeta.json' file\n## ✔ All functions have examples\n## ✖ Package 'DESCRIPTION' does not have a URL field\n## ✖ Package 'DESCRIPTION' does not have a BugReports field\n## ✔ Package name is available\n## ✖ Package has no continuous integration checks\n## ✖ Package coverage is 0% (should be at least 75%)\n## ✔ R CMD check found no errors\n## ✔ R CMD check found no warnings\n## ✖ This package still has TODO standards and can not be submitted\n## \n## ℹ Current status:\n## ✖ This package is not ready to be submitted"},{"path":"pkgdev.html","id":"pkgdev-autotest","chapter":"3 Guide for Authors","heading":"3.3 The autotest package","text":"autotest package \nautomated assessment tool packages expected pass order\naccepted submission. package implements form “mutation\ntesting,” examining types input parameters, implementing\ntype-specific mutations, examining response function \npackage mutations. kind mutation testing \neffective way uncover unexpected behaviour authors \nmight necessarily pre-empt. purpose using\nautotest prepare\npackages avoid much possible common situation reviewers\ndiscovering bugs attempt use software ways differ \ntypical uses envisioned authors . Reviews software prepared\nhelp \nautotest less\nburdened discussions often minor technical details, \nable focus “higher level” aspects software quality.Full documentation use\nautotest package\ndevelopment provided package\nwebsite, \nparticularly encourage authors intending develop packages submission\npeer review system step main autotest\nvignette,\napply autotest\ncontinuously throughout package development, ensure \nautotest_package()\nreturns clean (NULL) results package first submitted.","code":""},{"path":"pkgdev.html","id":"pkgdev-srr","chapter":"3 Guide for Authors","heading":"3.4 Alignment with Standards","text":"package sufficiently developed begin alignment \nstandards, issues revealed \nautotest \naddressed, authors need use third tool, ssr (software\nreveiw roclets) package\ninsert general category-specific standards code, \nbegin process documenting within code code\nadheres individual standards. srr\npackage can installed locally\nrunning either one following two lines.srr procedures described detail package\nwebsite, particular \nmain\nvignette.\nAuthors first encouraged obtain local copy source code \n\nvignette,\nstep line order understand procedure works.\ndone , may insert standards package \nrunning following line within local directory package,insert new file R/ directory package called (\ndefault) srr-stats-standards.R. standards initially \nroxygen2 tag @srrstatsTODO, indicate\nstandards yet addressed. tags processed \nsrr roclet needs \nconnected package modifying Roxygen line \nDESCRIPTION file following form:need add srr package anywhere else DESCRIPTION\nfile, need retain line submitting packages CRAN (\nelsewhere). nevertheless retain line times, \ncan easily disable roclet output including #' @srrVerbose FALSE\nsomewhere within documentation. Note srr documentation lines \nused produce -screen output triggered running\nroxygen2::roxygensise(),\nequivalent function,\ndevtools::document(),\nappear actual package documentation.srr roclet recognises \nprocess three tags:@srrstatsTODO flag standards yet addressed;@srrstats flag standards addressed, followed \ndescriptions code addresses standards; @srrstatsNA flag standards deem applicable \ncode, followed explanations deem standards \napplicable.file generated \nsrr_stats_roxygen()\ninitially contains two roxygen2 blocks, \nfirst containing every standard potentially applicable package, tagged\n@srrstatsTODO, second title NA_standards, \ndocument standards deemed applicable. first task generated\nfile move standards approximate locations within package\nlikely addressed. example, standards concerning tests\nmoved somewhere within tests/ directory, standards concerning\ndocumentation main README.Rmd file, within vignette file. \npackage\nskeleton\nincludes code demonstrating include roclet tags within .Rmd files.Moving different standards appropriate locations within code \nbreak initially large single list standards manageable\ngroups dispersed throughout code. standard addressed, \nmoved one locations code near possible relevant\ncode, tag changed @srrstatsTODO @srrstats, brief\ndescription appended explain standard addressed. Standards\ndeemed applicable package grouped together\nwithin single roxygen2 block title \nNA_standards, tag @srrstatsNA, brief description \nstandards deemed applicable.Software submitted review must contain @srrstatsTODO tags –\n, standards must addressed modifying every tag \neither @srrstats @srrstatsNA, described . Two useful functions\naid package alignment standards :srr_stats_pre_submit()\nfunction,\nconfirms standards addressed prior submission.srr_report()\nfunction,\ngenerates summary report hyperlinks locations within \ncode standards placed.output functions included result \npkgcheck()\nfunction,\nrun locally, run upon initial package submission. \nsrr_stats_pre_submit()\nfunction\ncan used locally confirm ,result srr_report()\nfunction\nmay accessed link given pkgcheck output, can \nviewed calling function directly.","code":"\nremotes::install_github(\"ropensci-review-tools/srr\")\npak::pkg_install(\"ropensci-review-tools/srr\")\nsrr_stats_roxygen (category = c (\"<category-1>\", \"<category-2>\"))\nRoxygen: list (markdown = TRUE, roclets = c (\"namespace\", \"rd\", \"srr::srr_stats_roclet\"))## ✔ All applicable standards have been documented in this package"},{"path":"pkgdev.html","id":"pkgdev-badges","chapter":"3 Guide for Authors","heading":"3.5 Gold, Silver, and Bronze Badges","text":"statistical software recommended acceptance reviewers \nentitled display rOpenSci badge. badge modified version \nbadge current peer-review\nsystem, additional\nsection far right indicating version standards \nsoftware assessed, coloured according “grade” badge. \nthree possible badges look like :\nbronze software sufficiently minimally compliant \nstandards pass review.\nsilver software complies minimal set \napplicable standards, extends beyond bronze least one notable way,\nexplained .\ngold software complies standards reviewers \ndeemed potentially applicable.submission template requires authors identify category wish \nattain review process. standards static, \nalways possible elevate badge higher grade subsequent review.\nBadge grades may also downgraded code continuously aligned\nongoing developments standards. following sub-sections provide\nclarification grade.","code":""},{"path":"pkgdev.html","id":"pkgdev-bronze","chapter":"3 Guide for Authors","heading":"3.5.1 Bronze ","text":"Software sufficiently minimally compliant standards \nreceive bronze badge. One common reason badge software \nauthors intend develop following review. commonly\narises software produced research projects completed,\nleaving funding develop software. Another reason might \nsoftware developed particular use case, authors\nunable align additional standards order expand general\nutility. bronze badge need signify weakness inadequacy \nsoftware, rather generally signify software developed\none particular use case, subject significant\ndevelopment.","code":""},{"path":"pkgdev.html","id":"pkgdev-silver","chapter":"3 Guide for Authors","heading":"3.5.2 Silver ","text":"Silver badges granted software extends beyond minimal\nrequirements bronze least one following four aspects:Compliance good number standards beyond identified \nminimally necessary. require reviewers authors agree \nidentification minimal subset necessary standards, full\nset potentially applicable standards. aspect may considered\nfulfilled least one quarter additional potentially applicable\nstandards met, definitely considered fulfilled \none half met.Demonstrating excellence compliance multiple standards least\ntwo broad sub-categories. Sub-categories distinguished Standards\nChapter three numbers, General\nStandards five sub-categories numbered 6.1.1 \n6.1.5. aspect require software extend notably beyond \nrequirements two standards least two sub-categories\n(regardless whether general category-specific standards). example,\nsoftware might otherwise assessed bronze grade, yet \nexcellently documented, outstanding test suite, may considered\nfulfil aspect.demonstrated generality usage beyond one single envisioned use\ncase. Software frequently developed one particular use case envisioned\nauthors . Generalising utility software \nreadily applicable use cases, satisfactorily documenting \ngenerality usage, represents another aspect may considered\nsufficient software attain silver grade.Internal aspects package structure design. Many aspects \ninternal structure design software variable effectively\naddressed standards. Packages judged reviewers reflect\nnotably excellent design choices, especially implementation core\nstatistical algorithms, may also considered worthy silver grade.","code":""},{"path":"pkgdev.html","id":"pkgdev-gold","chapter":"3 Guide for Authors","heading":"3.5.3 Gold ","text":"attain gold badge, software must comply applicable standards, \nmust also fulfil least three four aspects described \nsilver-grade badges. applicability standards, fulfilment \nthree aspects, ultimately determined reviewers. Moreover,\ncompliance grades assessed current standards, meaning \ngold badge must actively maintained standards revised\nupdated.","code":""},{"path":"pkgsubmission.html","id":"pkgsubmission","chapter":"4 Guide for Editors","heading":"4 Guide for Editors","text":"","code":""},{"path":"pkgsubmission.html","id":"automated-checks","chapter":"4 Guide for Editors","heading":"4.1 Automated Checks","text":"Upon initial submission, ropensci-review-bot performs suite tests\nchecks, paste report GitHub issue thread. report\nprimary source information used inform initial editorial\ndecisions. best way understand decisions made response\nreports provide concrete example. remainder \ninitial sub-section contains contents report, generated \nR package generated srr::srr_stats_pkg_skeleton()\nfunction,\nadditional statistical standards inserted \nsrr::srr_stats_roxygen()\nfunction.\n","code":"\nlibrary (srr)\nlibrary (pkgcheck)\npath <- srr_stats_pkg_skeleton ()\nsrr_stats_roxygen (category = \"regression\",\n                   filename = file.path (path, \"R\", \"srr-standards.R\"))\ncheck <- pkgcheck (path)\nmd <- checks_to_markdown (check, render = TRUE)"},{"path":"pkgsubmission.html","id":"editor-in-chief","chapter":"4 Guide for Editors","heading":"4.2 Editor-in-Chief","text":"rOpenSci’s current peer-review system, packages submitted directly\nropensci/software-review\nrepository GitHub, \nsubmissions handled initially rotating Editor--Chief (EiC).\nStatistical software nevertheless handled differently standard\n(non-statistical) packages first moment submission. Statistical\nsubmissions use different template, submission\nautomatically generates detailed report \nropensci-review-bot, described initial sub-section chapter,\nillustrated\n.EiC need purvey summary checks within initial section \nreport. submissions receive ticks items listed, \ncrosses, case initial checklist conclude statement ,package may submittedIn response statement, sole tasks EiC prior delegating\nhandling editor check following single item:\ncategories nominated submitting authors appropriate \npackageAnd choose one following two items:\npackage fit within additional categories statistical\nsoftware.\npackage potentially described following additional\ncategories statistical software:<list categories >\n<list categories >Additional effort EiC required “edge cases” \npackage may unable pass one checks, sample automated\ncheck,\nconcludes statement ,failing checks must addressed prior proceedingIn cases, submitting authors must explain checks may fail, \nEiC must determine whether failures acceptable.\ncases nevertheless rare, may expected majority\ncases sole tasks EiC confirm positive bot response,\ncomplete two checklist items given , allocate handling\neditor. latter step done calling @ropensci-review-bot assign <name> editor.","code":""},{"path":"pkgsubmission.html","id":"pkgsub-handling-editor","chapter":"4 Guide for Editors","heading":"4.3 Handling Editor","text":"Handling Editor can use summary report generated opening \nissue (exemplified\n)\nguide steps towards assigning reviewers. EiC need \nconsider initial summary checklist, handling editors consider \ndetails contained within automated report.first section describes checks conducted srr (Software\nReview Roclets) package.\ncheck confirms statistical standards documented within\ncode, packages must pass check. report linked \nsection primarily intended aid reviews, may ignored handling\neditors.second section describes “Statistical Properties” package\nsubmitted, considered handling editors. particular,\nsection contains information identifies statistically noteworthy\nproperties package. example report illustrates report\nimmediately identifies package little code, \nfunctions, tests. Handling editors consider \nstatistical details, particularly noteworthy aspects (defined \ndefault lying within upper lower fifth percentiles comparison \ncurrent CRAN packages). aspects seem concerning explicitly\nraised submitting authors prior proceeding. measures currently\nconsidered include various metrics :Size code base, overall sub-directoriesNumbers files various sub-directoriesNumbers functionsNumbers documentation lines per functionNumbers parameters per functionNumbers blank linesA final metric, fn_call_network_size, quantifies number \ninter-relationships different functions. R directories, \nfunction calls, relationships may complex within src inst\ndirectories. Small network sizes indicate packages either construct \nobjects (functions), internal objects direct relationships.third final section automated report contains details \ngoodpractice checks including:Code coverage estimates file (covr\npackage).Code style reports lintr\npackage.Cyclomatic complexity reports cyclocomp\npackage.errors, warnings, notes raised running R CMD check (\nrcmdcheck package.aspects \ngoodpractice reports \npass initial checklist (warnings errors R CMD check,\ntest coverage < 75%) clarified authors prior proceeding\nreview.Finally, initial Statistical Description includes details computer\nlanguages used package, used ensure reviewers \nappropriate experience abilities language(s) package \nwritten.","code":""},{"path":"pkgsubmission.html","id":"handling-editor-checklist","chapter":"4 Guide for Editors","heading":"4.3.1 Handling Editor Checklist","text":"thoroughly considered automated package report, addressed \nissues raised within report, Handling Editors paste following\nchecklist items issue, ensure items able \nchecked prior proceeding delegate reviewers.\nissues raised initial processing EiC resolved (\nnone).Either () issues raised goodpractice checks\nneed addressed prior review, (ii) issues \nappropriately addressed.\nRunning\nautotest_package()\nlocal version source code generates errors.Either () package aiming bronze badge, , (ii)\npackages aiming silver gold badges, authors clarified\nfour aspects listed “Guide Authors” section \nsilver badges intend fulfil.Either () package manifests statistical anomalies relation\nCRAN archive, (ii) statistical anomalies \nsatisfactorily explained.items must checked prior assigning reviewers. may\nrequire iteration submitting authors. stated \nDev Guide:authors believe changes might take time, apply holding\nlabel submission.package raises new issue rOpenSci policy, start conversation\nSlack open discussion rOpenSci\nforum discuss editors\n(example policy\ndiscussion).items checked, Handling Editors may assign reviewers using\ncommand @ropensci-review-bot assign reviewer <name>, generally\nfollowing procedure given Dev\nGuide.","code":""},{"path":"pkgreview.html","id":"pkgreview","chapter":"5 Guide for Reviewers","heading":"5 Guide for Reviewers","text":"current chapter considered extension corresponding\n“Guide Reviewers” \nrOpenSci’s “Dev Guide”. principles reviewing packages described \nalso apply statistical packages, chapter describing additional\nprocesses practices review packages submitted statistical\nsoftware peer review system. Reviews statistical software \nfirst assess compliance \nstandards,\nproceed general review, described following two\nsub-sections. template used reviews statistical software \nincluded final sub-section chapter. Prior describing \nreview process, following sub-section describes several tools can \nused aid review.","code":""},{"path":"pkgreview.html","id":"tools-for-reviewing-statistical-software","chapter":"5 Guide for Reviewers","heading":"5.1 Tools for Reviewing Statistical Software","text":"Upon initial submission, ropensci-review-bot generates automated\nreport summarising aspects package structure functionality intended \ninform review process, example can seen\n.elements reports described \nGuide Editors. aspects reported \nprimarily intended help editors initially identify potential\nissues best addressed prior review, nevertheless include number \ninsights package structure may usefully inform review process.Components reports intended aid reviews include complete report\nstandards compliance, generated \nsrr package, \ninteractive diagram inter-relationships package functions (\nobjects), generated \npkgstats package. \ncan recreated locally first installing two packages running\neither,,Within local clone package reviewed, report statistical\nstandards can generated running\nsrr::srr_report(),\nsample report linking version report may viewed\n,\ndetailed statistical properties package associated\ninteractive diagram package structure generated running,network, sample version may viewed\n,\nprovides immediate visual insight relationships objects\nconstructed within package languages used, R \nlanguages used src/ code C C++. following section describes\nsrr report \ndetail, intended use assessing compliance standards.","code":"\nremotes::install_github (\"ropensci-review-tools/pkgstats\")\nremotes::install_github (\"ropensci-review-tools/srr\")\npak::pkg_install (\"ropensci-review-tools/pkgstats\")\npak::pkg_install (\"ropensci-review-tools/srr\")\nlibrary (pkgstats)\nx <- pkgstats () # 'x' has lots of detail on package structure\nplot_network (x)"},{"path":"pkgreview.html","id":"assessment-against-standards","chapter":"5 Guide for Reviewers","heading":"5.2 Assessment Against Standards","text":"entire system peer review statistical software based sets \ngeneral category-specific standards given Chapter 6 \nbook. process assessing software standards \nfacilitated srr (software review roclets)\npackage authors \nreviewers need install shown .package primarily intended aid authors documenting \nsoftware complies relevant general \ncategory-specific standards. function package used aid reviewers\n\nsrr_report(),\noutput linked initial package report described ,\ncan also generated locally simply running function within\nlocal clone package reviewed. report contains hyperlinks \nplaces code standard addressed.Using report, reviewers must assess agreement every statement\neither compliance , non-applicability , standards reflected \nroclet\ntags\n:@srrstats standards software complies;@srrstatsNA standards authors deemed \napplicable software.\nsrr_report()\ndivided two main sections containing links locations code\ntwo types tags documented. action need taken \nstandards reviewers agree, whether software complies \ntag @srrstats, standard applicable tag \n@srrstatsNA. Reviewers asked note standards \ndisagree, primarily either :Disagreement standards compliance, authors used tag \n@srrstats reviewer judges either explanation associated code\ninsufficient compliance; orDisagreement non-applicability standard, authors \nused tag @srrstatsNA, reviewer believes standard \napply software.\nsrr_report()\nfunction returns content markdown format, may used \nreviewers initial checklist assess compliance. \nstandards reviewers agree authors statements compliance may\nsimply removed, hopefully reducing initially extensive checklists \nmanageable items reviews might disagree.following sub-section describes additional procedures required \nassessing standards compliance packages aiming either\nsilver gold badges. general srr\nprocedure described main package\nvignette,\nreviewers also encouraged read familiarise \nsrr package used \ndocument compliance standards. main srr\nvignette\nincludes code can stepped generate example report.","code":""},{"path":"pkgreview.html","id":"review-for-silver-and-gold-badges","chapter":"5 Guide for Reviewers","heading":"5.2.1 Review for Silver and Gold Badges","text":"system peer-review statistical software features badges three\ncategories bronze, silver, gold. described \ncorresponding Guide Authors, silver badge \ngranted software complies minimal set applicable\nstandards, extends beyond bronze least one notable\naspect gold badge granted software \ncomplies standards reviewers deemed potentially\napplicable, extends beyond bronze several notable aspects. \nnotable aspects software may fulfil requirements\nsilver gold badges :Compliance sufficient number additional standards beyond \nminimal number necessary bronze compliance;Demonstrated excellence compliance least two standards two\ndistinct sub-sections;demonstrated generality usage beyond single use case; orDemonstrated excellence internal aspects package design structure.authors identified initial submission \naspects intend fulfil. packages claim comply \nminimal number necessary standards, reviewers must additionally\nconsider standards software complies might \nconsidered minimally necessary, well whether standards authors\nidentified applicable (@ssrstatsNA tags) indeed \ndeemed applied. standards may able applied given piece \nsoftware. example, software designed accept sparse matrix inputs \nMatrix\npackage \nunable conform many standards general rectangular input\nforms.three categories necessary, currently, potentially applicable\nstandards can used reviewers roughly assess quantitative\ndegree compliance exceeds minimally required level. stated \nGuide Authors, first four items may \nconsidered fulfilled software meets least one quarter \npotentially applicable standards beyond minimally required. useful\nexample minimally required standards may often identified \nrequired software meet one specific use case. aspects\nsoftware generalise usage beyond single use case may \nconsidered second category potentially yet necessarily\napplicable. Judgement categorical distinction, precise amounts,\nleft discretion reviewers.Packages aiming gold badges end review need comply \npotentially applicable standards, also need fulfil least\nthree four aspects listed , described detail \nGuide Authors.","code":""},{"path":"pkgreview.html","id":"disagreement-with-authors-intentions","chapter":"5 Guide for Reviewers","heading":"5.2.2 Disagreement with Authors’ Intentions","text":"Authors must state submission grade badge aiming .\nReviewers may subsequently deem package compliant different\ngrade badge. review template includes following\ntwo items:\npackage complies sufficient number standards \n(bronze/silver/gold) badge\ngrade badge authors wanted achieveThe first item intended specify grade badge (bronze, silver, gold)\nreflects reviewer’s judgement, need necessarily reflect \nauthors intentions. second item may checked reviewer agrees \nauthors package indeed sufficient achieve desired badge.\nreviewers agree authors’ beliefs package package\ncompliance, second item left unchecked submitted review.\neditor ask authors response, inform whether\nadditional rounds development review necessary obtain grade\nbadge desired authors.","code":""},{"path":"pkgreview.html","id":"general-package-review","chapter":"5 Guide for Reviewers","heading":"5.3 General Package Review","text":"reviewer’s perspective, one primary aim standards-based\nsystem provide highly structured system addressing technical\naspects review, leaving general review process comparably free \ntechnical details, therefore able consider broader aspects \npackage design, functionality, usage.Following assessment compliance standards, reviewers accordingly\nproceed general descriptive review following processes\nestablished rOpenSci’s general software review system, best\nsource information provided reviews\n, along \nGuide Reviewers.\nformulating general review statistical software, ask reviewers \nexplicitly consider following aspects, loosely correspond \nsub-sections General Standards Statistical\nSoftware:Documentation: documentation sufficient enable general use \npackage beyond one specific use case? various components \ndocumentation support clarify one another?Algorithms well algorithms encoded? choice computer\nlanguage appropriate algorithm, /envisioned use package?\naspects algorithmic scaling sufficiently documented tested? \naspects algorithmic implementation improved?Testing Regardless actual coverage tests, \nfundamental software operations sufficiently expressed \ntests? need extended tests, extended tests exists, \nimplemented appropriate way, appropriately\ndocumented?Visualisation (appropriate) visualisations aid primary\npurposes statistical interpretation results? aspects \nvisualisations risk statistical misinterpretation?Package Design package well designed intended purpose? \nask reviewers consider follow two aspects package design:\nExternal Design: exported functions relationships \nenable general usage package? exported functions best\nserve inter-operability packages?\nInternal design: algorithms implemented appropriately terms \naspects efficiency, flexibility, generality, accuracy? \nranges admissible input structures, form(s) output structures,\nexpanded enhance inter-operability packages?\nExternal Design: exported functions relationships \nenable general usage package? exported functions best\nserve inter-operability packages?Internal design: algorithms implemented appropriately terms \naspects efficiency, flexibility, generality, accuracy? \nranges admissible input structures, form(s) output structures,\nexpanded enhance inter-operability packages?algorithms form core statistical software, ask reviewers pay\nparticular attention assessment algorithmic quality. \ncategory-specific standards include central “Algorithmic Standards”\ncomponent can used provide starting points general\nconsiderations algorithmic quality. General Standard\nG1.1 also requires similar algorithms \nimplementations documented within software, reviewers also\naccess list comparable implementations.considerations explicitly included reviewers’\ntemplate follows.","code":""},{"path":"pkgreview.html","id":"pkgrev-template","chapter":"5 Guide for Reviewers","heading":"5.4 Review Template","text":"following template used reviews statistical software. \ncheckbox items retained, checked appropriate, \nlines, notably including questions General Review section, may \nmodified removed appropriate.","code":"\n## Package Review\n\n*Please check off boxes as applicable, and elaborate in comments below.  Your review is not limited to these topics, as described in the reviewer guide*\n\n- Briefly describe any working relationship you may have (had) with the package authors (or otherwise remove this statement)\n\n- [ ] As the reviewer I confirm that there are no [conflicts of interest](https://devguide.ropensci.org/policies.html#coi) for me to review this work (If you are unsure whether you are in conflict, please speak to your editor _before_ starting your review).\n\n---\n\n### Compliance with Standards\n\n- [ ] This package complies with a sufficient number of standards for a (bronze/silver/gold) badge\n- [ ] This grade of badge is the same as what the authors wanted to achieve\n\nThe following standards currently deemed non-applicable (through tags of `@srrstatsNA`) could potentially be applied to future versions of this software: (Please specify)\n\nPlease also comment on any standards which you consider either particularly well, or insufficiently, documented.\n\nFor packages aiming for silver or gold badges:\n\n- [ ] This package extends beyond minimal compliance with standards in the following ways: (please describe)\n\n---\n\n### General Review\n\n#### Documentation\n\nThe package includes all the following forms of documentation:\n\n- [ ] **A statement of need** clearly stating problems the software is designed to solve and its target audience in README\n- [ ] **Installation instructions:** for the development version of package and any non-standard dependencies in README\n- [ ] **Community guidelines** including contribution guidelines in the README or CONTRIBUTING\n- [ ] The documentation is sufficient to enable general use of the package beyond one specific use case\n\nThe following sections of this template include questions intended to be used as guides to provide general, descriptive responses. Please remove this, and any subsequent lines that are not relevant or necessary for your final review.\n\n#### Algorithms\n\n- How well are algorithms encoded?\n- Is the choice of computer language appropriate for that algorithm, and/or envisioned use of package?\n- Are aspects of algorithmic scaling sufficiently documented and tested?\n- Are there any aspects of algorithmic implementation which could be improved?\n\n#### Testing\n\n- Regardless of actual coverage of tests, are there any fundamental software operations which are not sufficiently expressed in tests? \n- Is there a need for extended tests, or if extended tests exists, have they been implemented in an appropriate way, and are they appropriately documented?\n\n#### Visualisation (where appropriate)\n\n- Do visualisations aid the primary purposes of statistical interpretation of results?\n- Are there any aspects of visualisations which could risk statistical misinterpretation?\n\n#### Package Design\n\n- Is the package well designed for its intended purpose?\n- In relation to **External Design:** Do exported functions and the relationships between them enable general usage of the package? \n- In relation to **External Design:** Do exported functions best serve inter-operability with other packages?\n- In relation to **Internal Design:** Are algorithms implemented appropriately in terms of aspects such as efficiency, flexibility, generality, and accuracy? \n- In relation to **Internal Design:** Could ranges of admissible input structures, or form(s) of output structures, be expanded to enhance inter-operability with other packages?\n\n---\n\n- [ ] **Packaging guidelines**: The package conforms to the rOpenSci packaging guidelines\n\nEstimated hours spent reviewing:\n\n- [ ] Should the author(s) deem it appropriate, I agree to be acknowledged as a package reviewer (\"rev\" role) in the package DESCRIPTION file."},{"path":"standards.html","id":"standards","chapter":"6 Standards: Version 0.0.1","heading":"6 Standards: Version 0.0.1","text":"Chapter serves reference rOpenSci’s standards statistical\nsoftware. Software accepted peer-review must fit one \ncategories, thus packages must comply General Standards\nlisted first following sections, along one \ncategory-specific sets standards listed subsequent sections.Examples application standards may viewed separate\nhackmd.io files clicking following links:Application Bayesian Monte Carlo StandardsApplication Regression Supervised Learning StandardsApplication Dimensionality Reduction, Clustering, Unsupervised Learning StandardsApplication Exploratory Data Analysis StandardsApplication Machine Learning Software StandardsEach files compares general category-specific standards\nselected R packages within categories. comparisons \nintended illustrative purposes , way intended \nrepresent evaluations software. presented hope \ndemonstrating standards presented may applied software, \nresults application may look like.","code":""},{"path":"standards.html","id":"general-standards","chapter":"6 Standards: Version 0.0.1","heading":"6.1 General Standards for Statistical Software","text":"general standards, category-specific standards follow, \nintended serve recommendations best practices. Note particular\nmany standards written using word “” explicit\nacknowledgement adhering standards may always possible. \nstandards phrased terms intended interpreted applicable\nconditions “possible”, “applicable”.\nDevelopers requested note standards deem applicable\nsoftware via srr\npackage, described \nChapter 3.\nR language defines\nfollowing data types:LogicalIntegerContinuous (class = \"numeric\" / typeof = \"double\")ComplexString / characterThe base R system also includes considered direct\nextensions fundamental types include:FactorOrdered FactorDate/TimeThe continuous type typeof “double” represents \nstorage mode C representation objects, class \ndefined within R referred “numeric”. typeof \nclass, reference continuous variables, “numeric” may considered\nidentical “double” throughout.term “character” interpreted refer vector element \nindividual “character” object. term “string” relate \nofficial R nomenclature, used refer convenience \ncharacter vector length one; words, “string” sole\nelement single-length “character” vector.","code":""},{"path":"standards.html","id":"documentation","chapter":"6 Standards: Version 0.0.1","heading":"6.1.1 Documentation","text":"G1.0 Statistical Software list least one primary\nreference published academic literature.consider statistical software submitted system either\n() implement extend prior methods, case primary reference\nrelevant published version(s) prior methods; (ii) \nimplementation new method. second case, expected\nsoftware eventually form basis academic publication.\ntime, suitable reference equivalent algorithms \nimplementations provided.G1.1 Statistical Software document whether \nalgorithm(s) implements :\nfirst implementation novel algorithm; \nfirst implementation within R algorithm \npreviously implemented languages contexts; \nimprovement implementations similar algorithms R.\nfirst implementation novel algorithm; orThe first implementation within R algorithm \npreviously implemented languages contexts; orAn improvement implementations similar algorithms R.second third options additionally require references comparable\nalgorithms implementations documented somewhere within software,\nincluding references known implementations computer languages.\n(common location statement “Prior Art” similar \nend main README document.)G1.2 Statistical Software include Life Cycle\nStatement describing current anticipated future states development.encourage placed within repository’s CONTRIBUTING.md\nfile, \n\nexample.\nsimple Life Cycle Statement may formed selecting one following\nfour statements.","code":"This package is\n\n    - In a stable state of development, with minimal subsequent development\n      envisioned.\n    - In a stable state of development, with active subsequent development\n      primarily in response to user feedback.\n    - In a stable state of development, with some degree of active subsequent\n      development as envisioned by the primary authors.\n    - In an initially stable state of development, with a great deal of active\n      subsequent development envisioned."},{"path":"standards.html","id":"statistical-terminology","chapter":"6 Standards: Version 0.0.1","heading":"6.1.1.1 Statistical Terminology","text":"G1.3 statistical terminology clarified \nunambiguously defined.Developers presume anywhere documentation software \nspecific statistical terminology may “generally understood”, therefore\nneed explicit clarification. Even terms many may consider\nsufficiently generic require clarification, “null\nhypotheses” “confidence intervals”, generally need explicit\nclarification. example, estimation interpretation \nconfidence intervals dependent distributional properties associated\nassumptions. particular implementation procedures estimate report\nconfidence intervals accordingly reflect assumptions distributional\nproperties (among aspects), nature implications \nmust explicitly clarified.","code":""},{"path":"standards.html","id":"function-level-documentation","chapter":"6 Standards: Version 0.0.1","heading":"6.1.1.2 Function-level Documentation","text":"G1.4 Software use\nroxygen2 document functions.\nG1.4a internal (non-exported) functions also \ndocumented standard roxygen2 format,\nalong final @noRd tag suppress automatic generation .Rd\nfiles.\nG1.4a internal (non-exported) functions also \ndocumented standard roxygen2 format,\nalong final @noRd tag suppress automatic generation .Rd\nfiles.","code":""},{"path":"standards.html","id":"supplementary-documentation","chapter":"6 Standards: Version 0.0.1","heading":"6.1.1.3 Supplementary Documentation","text":"following standards describe several forms might considered\n“Supplementary Material”. many places within R package \nmaterial may included, common locations include vignettes, \nadditional directories (data-raw) listed .Rbuildignore \nprevent inclusion within installed packages.software supports publication, claims made publication \nregard software performance (example, claims algorithmic scaling \nefficiency; claims accuracy), following standard applies:G1.5 Software include code necessary reproduce\nresults form basis performance claims made associated\npublications.claims regarding aspects software performance made respect \nextant R packages, following standard applies:G1.6 Software include code necessary compare\nperformance claims alternative implementations R packages.","code":""},{"path":"standards.html","id":"input-structures","chapter":"6 Standards: Version 0.0.1","heading":"6.1.2 Input Structures","text":"section considers general standards Input Structures. \nstandards may often effectively addressed implementing class\nstructures, although general requirement. Developers \nnevertheless encouraged examine guide S3\nvectors\nvctrs package example kind \nassurances validation checks possible regard input data.\nSystems like demonstrated vignette provide effective way\nensure software remains robust diverse unexpected classes \ntypes input data. Packages \ncheckmate enable direct \nsimple ways check assert input structures.","code":""},{"path":"standards.html","id":"uni-variate-vector-input","chapter":"6 Standards: Version 0.0.1","heading":"6.1.2.1 Uni-variate (Vector) Input","text":"important note univariate data single values R vectors\nlength one, 1 exactly data type 1:n.\nGiven , inputs expected univariate :G2.0 Implement assertions lengths inputs, particularly\nasserting inputs expected single- multi-valued \nindeed .\nG2.0a Provide explicit secondary documentation \nexpectations lengths inputs\nG2.0a Provide explicit secondary documentation \nexpectations lengths inputsG2.1 Implement assertions types inputs (see initial\npoint nomenclature ).\nG2.1a Provide explicit secondary documentation \nexpectations data types vector inputs.\nG2.1a Provide explicit secondary documentation \nexpectations data types vector inputs.G2.2 Appropriately prohibit restrict submission \nmultivariate input parameters expected univariate.G2.3 univariate character input:\nG2.3a Use match.arg() equivalent applicable \npermit expected values.\nG2.3b Either: use tolower() equivalent ensure\ninput character parameters case dependent; explicitly\ndocument parameters strictly case-sensitive.\nG2.3a Use match.arg() equivalent applicable \npermit expected values.G2.3b Either: use tolower() equivalent ensure\ninput character parameters case dependent; explicitly\ndocument parameters strictly case-sensitive.G2.4 Provide appropriate mechanisms convert \ndifferent data types, potentially including:\nG2.4a explicit conversion integer via .integer()\nG2.4b explicit conversion continuous via\n.numeric()\nG2.4c explicit conversion character via\n.character() (paste paste0)\nG2.4d explicit conversion factor via .factor()\nG2.4e explicit conversion factor via ...()\nfunctions\nG2.4a explicit conversion integer via .integer()G2.4b explicit conversion continuous via\n.numeric()G2.4c explicit conversion character via\n.character() (paste paste0)G2.4d explicit conversion factor via .factor()G2.4e explicit conversion factor via ...()\nfunctionsG2.5 inputs expected factor type,\nsecondary documentation explicitly state whether \nordered , inputs provide appropriate error \nroutines ensure inputs follow expectations.packages implement R versions “static type” forms common \nlanguages, whereby type variable must explicitly specified prior \nassignment. Use approaches encouraged, including restricted\napproaches documented packages \nvctrs, experimental package\ntyped. One additional standard\nvector input :G2.6 Software accepts one-dimensional input ensure\nvalues appropriately pre-processed regardless class structures.units package provides good\nexample, creating objects may treated vectors, yet \nclass structure inherit vector class. Using \nobjects input often causes software fail. storage.mode \nunderlying objects may nevertheless examined, objects transformed \nprocessed accordingly ensure inputs lead errors.","code":""},{"path":"standards.html","id":"tabular-input","chapter":"6 Standards: Version 0.0.1","heading":"6.1.2.2 Tabular Input","text":"sub-section concerns input “tabular data” forms, meaning base\nR forms array, matrix, data.frame, forms classes\nderived . Tabular data generally two dimensions, although may\n(array objects). primary distinction within\nR array matrix representations, data.frame \nassociated representations. former restricted storing data \nsingle uniform type (example, integer character values),\nwhereas data.frame associated representations (generally) store \ncolumn list item, allowing different columns hold values different\ntypes. noting matrix may, R version\n4.0,\nconsidered strictly two-dimensional array, tabular inputs \npurposes standards considered imply data represented one \nfollowing forms:matrix form referring specifically two-dimensional data one\nuniform typearray form general expression, referring data \nnecessarily strictly two-dimensionaldata.frameExtensions \ntibble\ndata.table\ndomain-specific classes \ntsibble time series, \nsf spatial data.\ntibbledata.tabledomain-specific classes \ntsibble time series, \nsf spatial data.matrix array forms actually stored vectors single\nstorage.mode, preceding standards G2.0–G2.5 apply.\nrectangular forms stored vectors, necessarily\nsingle storage.mode columns. forms referred \nthroughout standards “data.frame-type tabular forms”, may \nassumed refer data represented either base::data.frame format,\n/classes listed final points.General Standards applicable software intended accept one \ndata.frame-type tabular inputs :G2.7 Software accept input many \nstandard tabular forms possible, including extension domain-specific\nforms.Software need necessarily test abilities accept different types \ninputs, may require adding packages Suggests field \npackage purpose alone. Nevertheless, software somehow uses\n(Depends Suggests) packages representing tabular data\nconfirm tests ability accept types input.G2.8 Software provide appropriate conversion dispatch\nroutines part initial pre-processing ensure \nsub-functions package receive inputs single defined class type.G2.9 Software issue diagnostic messages type\nconversion information lost (conversion variables \nfactor character; standardisation variable names; removal \nmeta-data associated \nsf-format data) added (\ninsertion variable column names none provided).Note, example, array may column names start \nnumeric values, data.frame may .array matrix class objects accepted input, G2.8\nimplies routines implemented check conversion \ncolumn names.next standard concerns following inconsistencies three common\ntabular classes regard column extraction operator, [.Extracting single column data.frame returns vector default,\ndata.frame drop = FALSE.Extracting single column tibble returns single-column tibble\ndefault, vector drop = TRUE.Extracting single column data.table always returns data.table,\ndrop argument effect.Given inconsistencies,G2.10 Software ensure extraction filtering \nsingle columns tabular inputs presume particular default\nbehaviour, ensure column-extraction operations behave\nconsistently regardless class tabular data used input.Adherence standard G2.8 ensure implicitly \nexplicitly assumed default behaviour yield consistent results regardless\ninput classes.Columns tabular inputsThe follow standards apply data.frame-like tabular objects (including \nderived otherwise compatible classes), apply matrix \narray objects.G2.11 Software ensure data.frame-like tabular\nobjects columns standard class\nattributes (typically, vector) appropriately processed, \nerror without reason. behaviour tested. , columns created\nunits package provide\ngood test case.G2.12 Software ensure data.frame-like tabular\nobjects list columns ensure columns \nappropriately pre-processed either removed, converted \nequivalent vector columns appropriate, appropriate\ntreatment informative error. behaviour tested.","code":"\nx <- array (1, dim = c(1, 1), dimnames = list(\"1\", \"2\")) # okay\nprint (x)##   2\n## 1 1\ndata.frame (x)##   X2\n## 1  1\nx <- iris # data.frame from the datasets package\nclass (x)\n#> [1] \"data.frame\"\nclass (x [, 1])\n#> [1] \"numeric\"\nclass (x [, 1, drop = TRUE]) # default\n#> [1] \"numeric\"\nclass (x [, 1, drop = FALSE])\n#> [1] \"data.frame\"\n\nx <- tibble::tibble (x)\nclass (x [, 1])\n#> [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\nclass (x [, 1, drop = TRUE])\n#> [1] \"numeric\"\nclass (x [, 1, drop = FALSE]) # default\n#> [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nx <- data.table::data.table (x)\nclass (x [, 1])\n#> [1] \"data.table\" \"data.frame\"\nclass (x [, 1, drop = TRUE]) # no effect\n#> [1] \"data.table\" \"data.frame\"\nclass (x [, 1, drop = FALSE]) # default\n#> [1] \"data.table\" \"data.frame\""},{"path":"standards.html","id":"missing-or-undefined-values","chapter":"6 Standards: Version 0.0.1","heading":"6.1.2.3 Missing or Undefined Values","text":"G2.13 Statistical Software implement appropriate checks\nmissing data part initial pre-processing prior passing data \nanalytic algorithms.G2.14 possible, functions provide options \nusers specify handle missing (NA) data, options minimally\nincluding:\nG2.14a error missing data\nG2.14b ignore missing data default warnings \nmessages issued\nG2.14c replace missing data appropriately imputed\nvalues\nG2.14a error missing dataG2.14b ignore missing data default warnings \nmessages issuedG2.14c replace missing data appropriately imputed\nvaluesG2.15 Functions never assume non-missingness, \nnever pass data potential missing values base routines\ndefault na.rm = FALSE-type parameters (\nmean(),\nsd() \ncor()).G2.16 functions also provide options handle\nundefined values (e.g., NaN, Inf -Inf), including potentially\nignoring removing values.","code":""},{"path":"standards.html","id":"algorithms","chapter":"6 Standards: Version 0.0.1","heading":"6.1.3 Algorithms","text":"G3.0 Statistical software never compare floating point\nnumbers equality. numeric equality comparisons either ensure\nmade integers, use appropriate tolerances \napproximate equality.standard applies computer languages included package. R,\nvalues can affirmed integers .integer(), asserting \nstorage.mode() object “integer”. One way compare numeric\nvalues tolerance .equal()\nfunction,\naccepts additional tolerance parameter default numeric\ncomparison sqrt(.Machine$double.eps), typically around e(-8–10).\nlanguages, including C C++, comparisons floating point numbers\ncommonly implemented conditions (abs(- b) < tol), \ntol specifies tolerance equality.Importantly, R functions \nduplicated()\n\nunique()\nrely equality comparisons, standard extends require \nsoftware apply functions rely equality\ncomparisons floating point numbers.G3.1 Statistical software relies covariance\ncalculations enable users choose different algorithms \ncalculating covariances, rely solely covariances \nstats::cov function.\nG3.1a ability use arbitrarily specified covariance\nmethods documented (typically examples vignettes).\nG3.1a ability use arbitrarily specified covariance\nmethods documented (typically examples vignettes).Estimates covariance can sensitive outliers, variety \nmethods developed “robust” estimates covariance, implemented\npackages rms,\nrobust, \nsandwich. Adhering \nstandard merely requires ability user specify particular\ncovariance function, additional parameter. stats::cov\nfunction can used default, additional packages three\nlisted need necessarily listed Imports package.","code":""},{"path":"standards.html","id":"output-structures","chapter":"6 Standards: Version 0.0.1","heading":"6.1.4 Output Structures","text":"G4.0 Statistical Software enables outputs written\nlocal files parse parameters specifying file names ensure\nappropriate file suffices automatically generated provided.","code":""},{"path":"standards.html","id":"testing","chapter":"6 Standards: Version 0.0.1","heading":"6.1.5 Testing","text":"packages follow rOpenSci standards \ntesting continuous\nintegration, including aiming high\ntest coverage. Extant R packages may useful testing include\ntestthat,\ntinytest,\nroxytest, \nxpectr.","code":""},{"path":"standards.html","id":"test-data-sets","chapter":"6 Standards: Version 0.0.1","heading":"6.1.5.1 Test Data Sets","text":"G5.0 applicable practicable, tests use standard\ndata sets known properties (example, NIST Standard Reference\nDatasets, data sets provided \nwidely-used R packages).G5.1 Data sets created within, used test, package\nexported (otherwise made generally available) users can\nconfirm tests run examples.","code":""},{"path":"standards.html","id":"responses-to-unexpected-input","chapter":"6 Standards: Version 0.0.1","heading":"6.1.5.2 Responses to Unexpected Input","text":"G5.2 Appropriate error warning behaviour functions\nexplicitly demonstrated tests. particular,\nG5.2a Every message produced within R code stop(),\nwarning(), message(), equivalent unique\nG5.2b Explicit tests demonstrate conditions \ntrigger every one messages, compare result \nexpected values.\nG5.2a Every message produced within R code stop(),\nwarning(), message(), equivalent uniqueG5.2b Explicit tests demonstrate conditions \ntrigger every one messages, compare result \nexpected values.G5.3 functions expected return objects\ncontaining missing (NA) undefined (NaN, Inf) values, absence\nvalues return objects explicitly tested.","code":""},{"path":"standards.html","id":"algorithm-tests","chapter":"6 Standards: Version 0.0.1","heading":"6.1.5.3 Algorithm Tests","text":"testing statistical algorithms, tests include tests \nfollowing types:G5.4 Correctness tests test statistical algorithms\nproduce expected results fixed test data sets (potentially \ncomparisons using binding frameworks \nRStata).\nG5.4a new methods, can difficult separate \ncorrectness method correctness implementation, \nmay reference comparison. case, testing may \nimplemented simple, trivial cases multiple\nimplementations initial R implementation compared results\nC/C++ implementation.\nG5.4b new implementations existing methods,\ncorrectness tests include tests previous implementations.\ntesting may explicitly call implementations testing,\npreferably fixed-versions software, use stored outputs\npossible.\nG5.4c applicable, stored values may drawn \npublished paper outputs applicable code original\nimplementations available\nG5.4a new methods, can difficult separate \ncorrectness method correctness implementation, \nmay reference comparison. case, testing may \nimplemented simple, trivial cases multiple\nimplementations initial R implementation compared results\nC/C++ implementation.G5.4b new implementations existing methods,\ncorrectness tests include tests previous implementations.\ntesting may explicitly call implementations testing,\npreferably fixed-versions software, use stored outputs\npossible.G5.4c applicable, stored values may drawn \npublished paper outputs applicable code original\nimplementations availableG5.5 Correctness tests run fixed random seedG5.6 Parameter recovery tests test \nimplementation produce expected results given data known properties.\ninstance, linear regression algorithm return expected\ncoefficient values simulated data set generated linear model.\nG5.6a Parameter recovery tests generally \nexpected succeed within defined tolerance rather recovering\nexact values.\nG5.6b Parameter recovery tests run multiple\nrandom seeds either data simulation algorithm contains\nrandom component. (long-running, tests may part \nextended, rather regular, test suite; see G4.10-4.12, ).\nG5.6a Parameter recovery tests generally \nexpected succeed within defined tolerance rather recovering\nexact values.G5.6b Parameter recovery tests run multiple\nrandom seeds either data simulation algorithm contains\nrandom component. (long-running, tests may part \nextended, rather regular, test suite; see G4.10-4.12, ).G5.7 Algorithm performance tests test \nimplementation performs expected properties data change. \ninstance, test may show parameters approach correct estimates within\ntolerance data size increases, convergence times decrease \nhigher convergence thresholds.G5.8 Edge condition tests test conditions\nproduce expected behaviour clear warnings errors confronted\ndata extreme properties including limited :\nG5.8a Zero-length data\nG5.8b Data unsupported types (e.g., character \ncomplex numbers functions designed numeric data)\nG5.8c Data -NA fields columns \nidentical fields columns\nG5.8d Data outside scope algorithm (\nexample, data fields (columns) observations (rows) \nregression algorithms)\nG5.8a Zero-length dataG5.8b Data unsupported types (e.g., character \ncomplex numbers functions designed numeric data)G5.8c Data -NA fields columns \nidentical fields columnsG5.8d Data outside scope algorithm (\nexample, data fields (columns) observations (rows) \nregression algorithms)G5.9 Noise susceptibility tests Packages test \nexpected stochastic behaviour, following conditions:\nG5.9a Adding trivial noise (example, scale \n.Machine$double.eps) data meaningfully change results\nG5.9b Running different random seeds initial\nconditions meaningfully change results\nG5.9a Adding trivial noise (example, scale \n.Machine$double.eps) data meaningfully change resultsG5.9b Running different random seeds initial\nconditions meaningfully change results","code":""},{"path":"standards.html","id":"extended-tests","chapter":"6 Standards: Version 0.0.1","heading":"6.1.5.4 Extended tests","text":"Thorough testing statistical software may require tests large data sets,\ntests many permutations, conditions leading long-running\ntests. cases may neither possible advisable execute tests\ncontinuously, every code change. Software nevertheless test \nconditions regardless long tests may take, \nadhere following standards:G5.10 Extended tests included run common\nframework tests switched flags \n<MYPKG>_EXTENDED_TESTS=1 environment variable.G5.11 extended tests require large data sets \nassets, provided downloading fetched part \ntesting workflow.\nG5.11a downloads additional data necessary\nextended tests fail, tests fail, rather \nskipped implicitly succeed appropriate diagnostic message.\nG5.11a downloads additional data necessary\nextended tests fail, tests fail, rather \nskipped implicitly succeed appropriate diagnostic message.G5.12 conditions necessary run extended tests \nplatform requirements, memory, expected runtime, artefacts produced \nmay need manual inspection, described developer documentation\nCONTRIBUTING.md tests/README.md file.","code":""},{"path":"standards.html","id":"standards-bayesian","chapter":"6 Standards: Version 0.0.1","heading":"6.2 Bayesian and Monte Carlo Software","text":"Bayesian Monte Carlo software centres quantitative estimation \ncomponents Baye’s theorem,\nparticularly estimation application prior /posterior probability\ndistributions. procedures implemented estimate properties \ndistributions commonly based random sampling procedures, hence referred\n“Monte Carlo” routines reference random yet quantifiable\nnature casino games. scope category also includes algorithms\nfocus sampling routines , Markov-Chain Monte Carlo (MCMC)\nprocedures, independent application Bayesian analyses.term “model” understood reference Bayesian software \nrefer encoded description parameters specifying aspects one \nprior distributions transformed (properties ) one \nposterior distributions.examples Bayesian Monte Carlo software include:bayestestR\npackage “provides\ntools describe … posterior distributions”ArviZ package\npython package exploratory analyses Bayesian models, particularly\nposterior distributions.GammaGompertzCR\npackage, features\nexplicit diagnostics MCMC convergence statistics.BayesianNetwork\npackage, \nmany ways wrapper package primarily serving shiny app, also\naccordingly package EDA category.fmcmc package,\n“classic” MCMC package directly provides \nimplementation, generates convergence statistics.rsimsum package\n“summarise[s] results Monte Carlo simulation studies”.\nMany statistics generated package useful assessing\ncomparing Bayesian Monte Carlo software general. (See also \nMCMCvis package, \nfocus visualisation.)walkr package \n“MCMC Sampling Non-Negative Convex Polytopes”. package also\nindicative difficulties deriving generally applicable assessments\nsoftware category, MCMC sampling relies \nfundamentally different inputs outputs many MCMC routines.Click following link view demonstration Application Bayesian\nMonte Carlo Standards.Bayesian Monte Carlo Software (hereafter referred simplicity \n“Bayesian Software”) presumed perform one following steps:Document specify inputs including:\n1.1 Data\n1.2 Parameters determining prior distributions\n1.3 Parameters determining computational processes\n1.1 Data1.2 Parameters determining prior distributions1.3 Parameters determining computational processesAccept validate forms inputApply data transformation pre-processing stepsApply one analytic algorithms, generally sampling algorithms used \ngenerate estimates posterior distributionsReturn result algorithmic applicationOffer additional functionality printing summarising return resultsThis chapter details standards steps, prefixed “BS”.","code":""},{"path":"standards.html","id":"documentation-of-inputs","chapter":"6 Standards: Version 0.0.1","heading":"6.2.1 Documentation of Inputs","text":"Prior actual standards documentation inputs, note one\nterminological standard Bayesian software uses term\n“hyperparameter”:BS1.0 Bayesian software uses term “hyperparameter”\nexplicitly clarify meaning term context \nsoftware.standard reflects dual facts term frequently used \nBayesian software, yet unambiguous definition interpretation. \nterm “hyperparameter” also used statistical contexts ways \noften distinctly different common use Bayesian analyses. Examples kinds clarifications required adhere standard include,Hyperparameters refer parameters determining form prior\ndistributions conditionally depend parameters.clarification require explicit distinction \n“parameters” “hyperparameters”. remainder standards \nrefer “hyperparameters”, rather attempts make explicit distinctions\ndifferent kinds parameters, distributional algorithmic\ncontrol parameters. Beyond standard, Bayesian Software provide \nfollowing documentation specify inputs:BS1.1 Descriptions enter data, textual form\nvia code examples. consider simplest cases \nsingle objects representing independent dependent data, potentially\ncomplicated cases multiple independent data inputs.BS1.2 Description specify prior distributions, \ntextual form\ndescribing general principles specifying prior distributions, along\napplied descriptions examples, within:\nB31.2a main package README, either textual\ndescription example code B31.2b least one package\nvignette, general applied textual descriptions, example\ncode B31.2c Function-level documentation, preferably\ncode included examples BS1.3 Description \nparameters control computational process (typically \ndetermining aspects numbers lengths sampling processes,\nseeds used start , thinning parameters determining post-hoc\nsampling simulated values, convergence criteria). \nparticular:\nBS1.3a Bayesian Software document, text\nexamples, use output previous simulations starting\npoints subsequent simulations. BS1.3b \napplicable, Bayesian software document, text examples,\nuse different sampling algorithms given model.\nBS1.4 Bayesian Software implements otherwise\nenables convergence checkers, documentation explicitly describe\nprovide examples use without convergence checkers.\nB31.2a main package README, either textual\ndescription example code B31.2b least one package\nvignette, general applied textual descriptions, example\ncode B31.2c Function-level documentation, preferably\ncode included examples BS1.3 Description \nparameters control computational process (typically \ndetermining aspects numbers lengths sampling processes,\nseeds used start , thinning parameters determining post-hoc\nsampling simulated values, convergence criteria). \nparticular:BS1.3a Bayesian Software document, text\nexamples, use output previous simulations starting\npoints subsequent simulations. BS1.3b \napplicable, Bayesian software document, text examples,\nuse different sampling algorithms given model.\nBS1.4 Bayesian Software implements otherwise\nenables convergence checkers, documentation explicitly describe\nprovide examples use without convergence checkers.BS1.5 Bayesian Software implements otherwise\nenables multiple\nconvergence checkers, differences explicitly tested.","code":""},{"path":"standards.html","id":"input-data-structures-and-validation","chapter":"6 Standards: Version 0.0.1","heading":"6.2.2 Input Data Structures and Validation","text":"section contains standards primarily intended ensure input data,\nincluding model specifications, validated prior passing \nmain computational algorithms.","code":""},{"path":"standards.html","id":"input-data","chapter":"6 Standards: Version 0.0.1","heading":"6.2.2.1 Input Data","text":"Bayesian Software commonly designed accept generic one- \ntwo-dimensional forms vector, matrix, data.frame objects, \nfollowing standard applies.BS2.1 Bayesian Software implement pre-processing\nroutines ensure input data dimensionally commensurate, example\nensuring commensurate lengths vectors numbers rows tabular\ninputs.\nBS2.1a effects routines tested.\nBS2.1a effects routines tested.","code":""},{"path":"standards.html","id":"prior-distributions-model-specifications-and-distributional-parameters","chapter":"6 Standards: Version 0.0.1","heading":"6.2.2.2 Prior Distributions, Model Specifications, and Distributional Parameters","text":"second set standards section concern specification prior\ndistributions, model structures, equivalent ways specifying\nhypothesised relationships among input data structures. R already diverse\nrange Bayesian Software distinct approaches task, commonly\neither specifying model character vector representing R\nfunction, external file either R code, encoded according \nalternative system (rstan).Bayesian Software :BS2.2 Ensure appropriate validation \npre-processing distributional parameters implemented distinct\npre-processing steps prior submitting analytic routines, especially\nprior submitting multiple parallel computational chains.BS2.3 Ensure lengths vectors distributional\nparameters \nchecked, excess values silently discarded (unless output \nexplicitly suppressed, detailed ).BS2.4 Ensure lengths vectors distributional\nparameters \ncommensurate expected model input (see example immediately )BS2.5 possible, implement pre-processing checks \nvalidate\nappropriateness numeric values submitted distributional parameters;\nexample, ensuring distributional parameters defining second-order\nmoments distributional variance shape parameters, \nparameters logarithmically transformed, non-negative.following example demonstrates standards like (BS2.4-2.5)\nmight addressed. Consider following function defines \nlog-likelihood estimator linear regression, controlled via vector \nthree distributional parameters, p:Pre-processing stages used determine:dimensions input data, x y, commensurate (BS2.1);\nnon-commensurate inputs error default.length vector p (BS2.3)latter task necessarily straightforward, definition \nfunction, ll(), generally part input actual\nBayesian Software function. functional input thus needs examined \ndetermine expected lengths hyperparameter vectors. following code\nillustrates one way achieve , relying utilities parsing function\ncalls R, primarily \ngetParseData\nfunction utils package. parse data function can \nextracted following line:object x data.frame every R token (expression,\nsymbol, operator) parsed function ll. following section\nillustrates data can used determine expected lengths \nvector inputs function, ll().\nInput arguments used define parameter vectors R software accessed\nR’s standard vector access syntax vec[], element \nvector vec. parse data begins SYMBOL vec, \n[, NUM_CONST value , closing ]. following code\ncan used extract elements parse data match pattern, \nultimately extract various values used access members \nvec.function can used determine length inputs \nused hyperparameter vectors:vector p used hyperparameter vector containing three\nparameters. initial value vectors can examined ensure \nlength.Bayesian Software designed accept model inputs expressed \nR code. rstan package, example,\nimplements model specification language, allows distributional\nparameters named, addressed index. largely avoids\nproblems mismatched lengths parameter vectors, software (v2.21.1)\nensure existence named parameters prior starting \ncomputational chains. ultimately results chain generating error\nmodel specification refers non-existent undefined\ndistributional parameter. controls part single\npre-processing stage, generate single error.","code":"\nll <- function (x, y, p) dnorm (y - (p[1] + x * p[2]), sd = p[3], log = TRUE)\nx <- getParseData (parse (text = deparse (ll)))\nvector_length <- function (x, i) {\n    xn <- x [which (x$token %in% c (\"SYMBOL\", \"NUM_CONST\", \"'['\", \"']'\")), ]\n    # split resultant data.frame at first \"SYMBOL\" entry\n    xn <- split (xn, cumsum (xn$token == \"SYMBOL\"))\n    # reduce to only those matching the above pattern\n    xn <- xn [which (vapply (xn, function (j)\n                             j$text [1] == i & nrow (j) > 3,\n                             logical (1)))]\n    ret <- NA_integer_ # default return value\n    if (length (xn) > 0) {\n        # get all values of NUM_CONST as integers\n        n <- vapply (xn, function (j)\n                         as.integer (j$text [j$token == \"NUM_CONST\"] [1]),\n                         integer (1), USE.NAMES = FALSE)\n        # and return max of these\n        ret <- max (n)\n    }\n    return (ret)\n}\nll <- function (p, x, y) dnorm (y - (p[1] + x * p[2]), sd = p[3], log = TRUE)\np <- parse (text = deparse (ll))\nx <- utils::getParseData (p)\n\n# extract the names of the parameters:\nparams <- unique (x$text [x$token == \"SYMBOL\"])\nlens <- vapply (params, function (i) vector_length (x, i), integer (1))\nlens\n#>  y  p  x \n#> NA  3 NA"},{"path":"standards.html","id":"computational-parameters","chapter":"6 Standards: Version 0.0.1","heading":"6.2.2.3 Computational Parameters","text":"Computational parameters considered distinct distributional\nparameters, commonly passed Bayesian functions directly control\ncomputational processes. typically include parameters controlling lengths\nruns, lengths burn-periods, numbers parallel computations, \nparameters controlling samples generated, convergence\ncriteria. Computational Parameters checked general “sanity”\nprior calling primary computational algorithms. standards \nsanity checks include Bayesian Software :BS2.6 Check values computational parameters lie\nwithin plausible ranges.admittedly always possible define, plausible ranges may \nsimple ensuring values greater zero. possible, checks \nnevertheless ensure appropriate responses extremely large values, \nexample issuing diagnostic messages likely long computational times.\nfollowing two sub-sections consider particular cases computational\nparameters.","code":""},{"path":"standards.html","id":"parameters-controlling-start-values","chapter":"6 Standards: Version 0.0.1","heading":"6.2.2.4 Parameters Controlling Start Values","text":"Bayesian software generally relies sequential random sampling procedures,\nsequence uniquely determined (among aspects) value \nstarted. Given , Bayesian software :BS2.7 Enable starting values explicitly controlled via\none input parameters, including multiple values software \nimplements enables multiple computational “chains.”BS2.8 Enable results previous runs used starting\npoints \nsubsequent runs.Bayesian Software implements enables multiple computational chains\n:BS2.9 Ensure chain started different seed \ndefault.BS2.10 Issue diagnostic messages identical seeds \npassed distinct\ncomputational chains.BS2.11 Software accepts starting values vector\nprovide\nparameter plural name: example, “starting_values” \n“starting_value”.avoid potential confusion separate parameters control random\nseeds starting values, recommended single “starting values” rather\n“seeds” argument, appropriate translation parameters \nseeds necessary.","code":""},{"path":"standards.html","id":"output-verbosity","chapter":"6 Standards: Version 0.0.1","heading":"6.2.2.5 Output Verbosity","text":"Bayesian Software implement computational parameters control\noutput verbosity. Bayesian computations often time-consuming, often\nperformed batch computations. following standards adhered \nregard output verbosity:BS2.12 Bayesian Software implement least one\nparameter controlling verbosity output, defaulting verbose output\nappropriate messages, warnings, errors, progress indicators.BS2.13 Bayesian Software enable suppression \nmessages progress\nindicators, retaining verbosity warnings errors. \ntested.BS2.14 Bayesian Software enable suppression \nwarnings \nappropriate. tested.BS2.15 Bayesian Software explicitly enable errors \ncaught, \nappropriately processed either conversion warnings, otherwise\ncaptured return values. tested.","code":""},{"path":"standards.html","id":"pre-processing-and-data-transformation","chapter":"6 Standards: Version 0.0.1","heading":"6.2.3 Pre-processing and Data Transformation","text":"","code":""},{"path":"standards.html","id":"missing-values","chapter":"6 Standards: Version 0.0.1","heading":"6.2.3.1 Missing Values","text":"additional General Standards missing values\n(G2.13–2.16), particular G2.13, Bayesian Software :BS3.0 Explicitly document assumptions made regard \nmissing values; example data assumed contain missing (NA,\nInf) values, values, entire rows including \nvalues, automatically removed input data.","code":""},{"path":"standards.html","id":"perfect-collinearity","chapter":"6 Standards: Version 0.0.1","heading":"6.2.3.2 Perfect Collinearity","text":"appropriate, Bayesian Software :BS3.1 Implement pre-processing routines diagnose perfect\ncollinearity, provide appropriate diagnostic messages warningsBS3.2 Provide distinct routines processing perfectly\ncollinear data, potentially bypassing sampling algorithmsAn appropriate test BS3.2 confirm system.time() \nequivalent timing expressions perfectly collinear data less\nequivalent routines called non-collinear data. Alternatively, test\nensure perfectly collinear data passed function stopping\ncriteria generated results, specifying fixed number iterations\nmay generate results.","code":""},{"path":"standards.html","id":"analytic-algorithms","chapter":"6 Standards: Version 0.0.1","heading":"6.2.4 Analytic Algorithms","text":"mentioned, analytic algorithms Bayesian Software commonly algorithms\nsimulate posterior distributions, draw samples \nsimulations. Numerous extant R packages implement offer sampling\nalgorithms, Bayesian Software internally implement sampling\nalgorithms. following standards apply packages implement\ninternal sampling algorithms:BS4.0 Packages document sampling algorithms (generally\nvia literary citation, reference software)BS4.1 Packages provide explicit comparisons \nexternal samplers\ndemonstrate intended advantage implementation (generally via tests,\nvignettes, ).Regardless whether Bayesian Software implements internal sampling\nalgorithms, :BS4.2 Implement least one means validate posterior estimates.example posterior validation Simulation Based\nCalibration approach implemented \nrstan function\nsbc). (Note also \nBayesValidate package \nupdated almost 15 years, directly used, although\nideas package may adapted validation purposes.) Beyond ,\npossible applicable, Bayesian Software :BS4.3 Implement otherwise offer least one type \nconvergence checker, provide documented reference \nimplementation.BS4.4 Enable computations stopped convergence\n(although \nnecessarily default).BS4.5 Ensure appropriate mechanisms provided \nmodels \nconverge.often achieved default behaviour stop specified\nnumbers iterations regardless convergence.BS4.6 Implement tests confirm results convergence\nchecker statistically equivalent results equivalent fixed number\nsamples without convergence checking.BS4.7 convergence checkers parametrised,\neffects \nparameters also tested. threshold parameters, example,\nlower values result longer sequence lengths.","code":""},{"path":"standards.html","id":"return-values","chapter":"6 Standards: Version 0.0.1","heading":"6.2.5 Return Values","text":"Unlike software many categories, Bayesian Software generally\nreturn several kinds distinct data, raw data derived \nstatistical algorithms, associated metadata. distinct generally\ndisparate forms data generally best combined single object\nimplementing defined class structure, although options \npossible, including (re-)using extant class structures (see CRAN Task view\nBayesian Inference \nreference packages class systems). Regardless precise form\nreturn object, whether defined class structures used \nimplemented, following standards apply:BS5.0 Return values include starting value(s) \nseed(s), including values sequence multiple sequences \nincludedBS5.1 Return values include appropriate metadata \ntypes (\nclasses) dimensions input dataThe latter standard may also include returning unique hash computed \ninput data, enable results uniquely associated input data.\nregard input function, alternative means specifying prior\ndistributions:BS5.2 Bayesian Software either return input\nfunction prior distributional specification return object; \nenable direct access via additional functions accept return\nobject single argument.convergence checkers implemented provided:BS5.3 Bayesian Software return convergence statistics\nequivalentBS5.4 multiple checkers enabled, Bayesian Software\nreturn details convergence checker usedBS5.5 Appropriate diagnostic statistics indicate absence \nconvergence either returned immediately able accessed.","code":""},{"path":"standards.html","id":"additional-functionality","chapter":"6 Standards: Version 0.0.1","heading":"6.2.6 Additional Functionality","text":"regard additional methods implemented , dispatched , return\nobjects:BS6.0 Software implement default print method \nreturn objectsBS6.1 Software implement default plot method \nreturn\nobjectsBS6.2 Software provide document straightforward\nabilities \nplot sequences posterior samples, burn-periods clearly\ndistinguishedBS6.3 Software provide document straightforward\nabilities plot posterior distributional estimatesBeyond points:BS6.4 Software may provide summary methods return objectsBS6.5 Software may provide abilities plot sequences \nposterior samples distributional estimates together single graphic","code":""},{"path":"standards.html","id":"tests","chapter":"6 Standards: Version 0.0.1","heading":"6.2.7 Tests","text":"","code":""},{"path":"standards.html","id":"parameter-recovery-tests","chapter":"6 Standards: Version 0.0.1","heading":"6.2.7.1 Parameter Recovery Tests","text":"Bayesian software implement following parameter recovery tests:BS7.0 Software demonstrate confirm recovery \nparametric estimates prior distributionBS7.1 Software demonstrate confirm recovery \nprior\ndistribution absence additional data informationBS7.2 Software demonstrate confirm recovery \nexpected posterior distribution given specified prior input data","code":""},{"path":"standards.html","id":"algorithmic-scaling-tests","chapter":"6 Standards: Version 0.0.1","heading":"6.2.7.2 Algorithmic Scaling Tests","text":"BS7.3 Bayesian software include tests demonstrate\nconfirm scaling algorithmic efficiency sizes input data.example adhering standard documentation tests \ndemonstrate confirm computation times increase approximately\nlogarithmically increasing sizes input data.","code":""},{"path":"standards.html","id":"scaling-of-input-to-output-data","chapter":"6 Standards: Version 0.0.1","heading":"6.2.7.3 Scaling of Input to Output Data","text":"BS7.4 Bayesian software implement tests confirm\npredicted fitted values (approximately) scale \ninput values.\nBS7.4a implications assumptions scales \ninput objects explicitly tested context; example\nscales inputs means zero \nable recovered.\nBS7.4a implications assumptions scales \ninput objects explicitly tested context; example\nscales inputs means zero \nable recovered.","code":""},{"path":"standards.html","id":"exploratory-data-analysis","chapter":"6 Standards: Version 0.0.1","heading":"6.3 Exploratory Data Analysis","text":"Exploration part data analyses, Exploratory Data Analysis (EDA)\nsomething entered exited point prior \n“real” analysis. Exploratory Analyses also strictly limited Data,\nmay extend exploration Models data. category \nthus equally termed, “Exploratory Data Model Analysis”, yet opt \nutilise standard acronym EDA document.EDA nevertheless somewhat different many categories included within\nrOpenSci’s program peer-reviewing statistical software. Primary differences include:EDA software often strong focus upon visualization, category\notherwise explicitly excluded scope project \npresent stage.assessment EDA software requires addressing general questions\nsoftware categories, notably including important\nquestion intended audience(s).Examples EDA software include:package rejected rOpenSci --scope,\ngtsummary, provides,\n“Presentation-ready data summary analytic result tables.” \nexamples include:smartEDA package (\naccompanying JOSS\npaper) “automated\nexploratory data analysis”. package, “automatically selects \nvariables performs related descriptive statistics. Moreover, also\nanalyzes information value, weight evidence, custom tables,\nsummary statistics, performs graphical techniques numeric \ncategorical variables.” package potentially much workflow\npackage statistical reporting package, illustrates \nambiguity two categories.modeLLtest package (\naccompanying JOSS\npaper) “R Package\nUnbiased Model Comparison using Cross Validation.” main\nfunctionality allows different statistical models compared, likely\nimplying represents kind meta package.insight package (\naccompanying JOSS paper\nprovides “unified interface access information model objects \nR,” strong focus unified consistent reporting statistical\nresults.arviz software python (\naccompanying JOSS paper\nprovides “unified library exploratory analysis Bayesian models \nPython.”iRF package (accompanying JOSS\npaper enables\n“extracting interactions random forests”, yet also focusses primarily\nenabling interpretation random forests reporting \ninteraction terms.Click following link view demonstration Application Exploratory\nData Analysis Standards.Reflecting considerations, following standards somewhat\ndifferently structured equivalent standards developed date \ncategories, particularly qualitative abstract. \nparticular, documentation important component standards \ncategories, clear instructive documentation paramount importance \nEDA Software, warrants sub-section within document.","code":""},{"path":"standards.html","id":"documentation-standards","chapter":"6 Standards: Version 0.0.1","heading":"6.3.1 Documentation Standards","text":"following refer Primary Documentation, implying main package\nREADME vignette(s), Secondary Documentation, implying function-level\ndocumentation.Primary Documentation (README /vignette(s)) EDA software\n:EA1.0 Identify one target audiences \nsoftware intendedEA1.1 Identify kinds data software capable \nanalysing (see Kinds Data* ).*EA1.2 Identify kinds questions software intended\nhelp explore.Important distinctions kinds questions include whether \ninferential, predictive, associative, causal, representative modes\nstatistical enquiry. Secondary Documentation (within individual\nfunctions) EDA software :EA1.3 Identify kinds data function intended \naccept input","code":""},{"path":"standards.html","id":"input-data-1","chapter":"6 Standards: Version 0.0.1","heading":"6.3.2 Input Data","text":"primary difference EDA software categories\ninput data statistical software may generally presumed one \nspecific types, whereas EDA software often accepts data general\nvaried types. EDA software aim accept appropriately transform\nmany diverse kinds input data possible, addressing \nfollowing standards, considered terms two cases input data uni-\nmulti-variate form. general standards kinds input (G2.0 -\nG2.12) apply input data EDA Software.","code":""},{"path":"standards.html","id":"index-columns","chapter":"6 Standards: Version 0.0.1","heading":"6.3.2.1 Index Columns","text":"following standards refer index column, understood \nimply explicitly named identified column can used provide \nunique index index rows table. Index columns ensure\nuniversal applicability standard table join operations, \nimplemented via dplyr package.EA2.0 EDA Software accepts standard tabular data \nimplements relies upon extensive table filter join operations \nutilise index column systemEA2.1 values index column must unique, \nuniqueness affirmed pre-processing step input data.EA2.2 Index columns explicitly identified, either:\nEA2.2a using appropriate class system, \nEA2.2b setting attribute table, x, \nattr(x, \"index\") <- <index_col_name>.\nEA2.2a using appropriate class system, orEA2.2b setting attribute table, x, \nattr(x, \"index\") <- <index_col_name>.EDA software either implements custom classes explicitly sets\nattributes specifying index columns, attributes used \nbasis table join operations, particular:EA2.3 Table join operations based assumed\nvariable column names","code":""},{"path":"standards.html","id":"multi-tabular-input","chapter":"6 Standards: Version 0.0.1","heading":"6.3.2.2 Multi-tabular input","text":"EDA software designed accept multi-tabular input :EA2.4 Use demand explicit class system input\n(example, via DM package).EA2.5 Ensure individual tables follow standards\nIndex Columns","code":""},{"path":"standards.html","id":"classes-and-sub-classes","chapter":"6 Standards: Version 0.0.1","heading":"6.3.2.3 Classes and Sub-Classes","text":"Classes understood classes define single input objects,\nSub-Classes refer class definitions components input\nobjects (example, columns input data.frame). EDA software \nintended receive input general vector formats (see Uni-variate Input\nsection General Standards) ensure \ncomplies G2., vector input appropriately processed\nregardless input class. additional standard EDA software ,EA2.6 Routines appropriately process vector data\nregardless additional attributesThe following code illustrates ways “metadata” defining classes\nadditional attributes associated standard vector object may \nmodified.statistical software appropriately deal input\ndata, exemplified storage.mode(), length(), sum() functions\nbase package, return appropriate values regardless \nredefinition class additional attributes.Tabular inputs data.frame class may contain columns \ndefined custom classes, possess additional attributes. ability\nsoftware accept inputs covered Tabular Input section \nGeneral Standards.","code":"\nx <- 1:10\nclass (x) <- \"notvector\"\nattr (x, \"extra_attribute\") <- \"another attribute\"\nattr (x, \"vector attribute\") <- runif (5)\nattributes (x)\n#> $class\n#> [1] \"notvector\"\n#> \n#> $extra_attribute\n#> [1] \"another attribute\"\n#> \n#> $`vector attribute`\n#> [1] 0.03521663 0.49418081 0.60129563 0.75804346 0.16073301\nstorage.mode (x)\n#> [1] \"integer\"\nlength (x)\n#> [1] 10\nsum (x)\n#> [1] 55\nstorage.mode (sum (x))\n#> [1] \"integer\""},{"path":"standards.html","id":"analytic-algorithms-1","chapter":"6 Standards: Version 0.0.1","heading":"6.3.3 Analytic Algorithms","text":"EDA software generally directly implement might considered \nstatistical algorithms right. algorithms implemented,\nfollowing standards apply.EA3.0 algorithmic components EDA Software enable\nautomated extraction /reporting statistics sufficiently\n“meta” level (variable model selection), previous \nreference implementations require manual intervention.EA3.1 EDA software enable standardised comparison \ninputs, processes, models, outputs previous reference\nimplementations otherwise enable comparably unstandardised\nform.standards also relate following standards output\nvalues, visualisation, summary output.","code":""},{"path":"standards.html","id":"return-results-output-data","chapter":"6 Standards: Version 0.0.1","heading":"6.3.4 Return Results / Output Data","text":"EA4.0 EDA Software ensure return results types\nconsistent input types.Examples compliance include ensuring sum, min, max values\napplied integer-type vectors return integer values.EA4.1 EDA Software implement parameters enable\nexplicit control numeric precisionEA4.2 primary routines EDA Software return\nobjects default print plot methods give sensible results.\nDefault summary methods may also implemented.","code":""},{"path":"standards.html","id":"visualization-and-summary-output","chapter":"6 Standards: Version 0.0.1","heading":"6.3.5 Visualization and Summary Output","text":"Visualization commonly represents one primary functions EDA Software,\nthus visualization output given greater consideration category\ncategories visualization may nevertheless play \nimportant role. particular, one component sub-category Summary\nOutput, taken refer forms screen-based output beyond conventional\ngraphical output, including tabular text-based forms. Standards \nvisualization considered two primary sub-categories static\ndynamic visualization, latter includes interactive visualization.Prior individual sub-categories, consider standards\napplicable visualization general, whether static dynamic.EA5.0 Graphical presentation EDA software \naccessible possible practicable. particular, EDA software \nconsider accessibility terms :\nEA5.0a Typeface sizes, default sizes\nexplicitly enhance accessibility\nEA5.0b Default colour schemes, carefully\nconstructed ensure accessibility.\nEA5.0a Typeface sizes, default sizes\nexplicitly enhance accessibilityEA5.0b Default colour schemes, carefully\nconstructed ensure accessibility.EA5.1 explicit specifications typefaces override\ndefault values provided packages (including graphics\npackage) consider accessibility","code":""},{"path":"standards.html","id":"summary-and-screen-based-output","chapter":"6 Standards: Version 0.0.1","heading":"6.3.5.1 Summary and Screen-based Output","text":"EA5.2 Screen-based output never rely default print\nformatting numeric types, rather also use version \nround(., digits), formatC, sprintf, similar functions numeric\nformatting according parameter described EA4.1.EA5.3 Column-based summary statistics always indicate\nstorage.mode, class, equivalent defining attribute \ncolumn.example compliance latter standard print.tibble method\ntibble package.","code":""},{"path":"standards.html","id":"general-standards-for-visualization-static-and-dynamic","chapter":"6 Standards: Version 0.0.1","heading":"6.3.5.2 General Standards for Visualization (Static and Dynamic)","text":"EA5.4 visualisations ensure values rounded\nsensibly (example, via pretty() function).EA5.5 visualisations include units axes\nspecified otherwise obtainable input data \nroutines.","code":""},{"path":"standards.html","id":"dynamic-visualization","chapter":"6 Standards: Version 0.0.1","heading":"6.3.5.3 Dynamic Visualization","text":"Dynamic visualization routines commonly implemented interfaces \njavascript routines. Unless routines explicitly developed \ninternal part R package, standards shall considered apply \ncode , rather decisions present user-controlled parameters\nexposed within R environment. said, one standard may nevertheless \napplied, aims maximise inter-operability packages.EA5.6 packages internally bundle libraries used \ndynamic visualization also bundled , pre-existing\nR packages, explain necessity advantage re-bundling \nlibrary.","code":""},{"path":"standards.html","id":"testing-1","chapter":"6 Standards: Version 0.0.1","heading":"6.3.6 Testing","text":"","code":""},{"path":"standards.html","id":"return-values-1","chapter":"6 Standards: Version 0.0.1","heading":"6.3.6.1 Return Values","text":"EA6.0 Return values functions tested,\nincluding tests following characteristics:\nEA6.0a Classes types objects\nEA6.0b Dimensions tabular objects\nEA6.0c Column names (equivalent) tabular objects\nEA6.0d Classes types columns contained within\ndata.frame-type tabular objects \nEA6.0e Values single-valued objects; numeric\nvalues either using testthat::expect_equal() equivalent \ndefined value tolerance parameter, using round(..., digits = x) defined value x prior testing equality.\nEA6.0a Classes types objectsEA6.0b Dimensions tabular objectsEA6.0c Column names (equivalent) tabular objectsEA6.0d Classes types columns contained within\ndata.frame-type tabular objects EA6.0e Values single-valued objects; numeric\nvalues either using testthat::expect_equal() equivalent \ndefined value tolerance parameter, using round(..., digits = x) defined value x prior testing equality.","code":""},{"path":"standards.html","id":"graphical-output","chapter":"6 Standards: Version 0.0.1","heading":"6.3.6.2 Graphical Output","text":"EA6.1 properties graphical output EDA software\nexplicitly tested, example via vdiffr\npackage equivalent.Tests graphical output frequently run part extended test\nsuite.","code":""},{"path":"standards.html","id":"ml-standards","chapter":"6 Standards: Version 0.0.1","heading":"6.4 Machine Learning Software","text":"R extensive diverse ecosystem Machine Learning (ML) software\nwell described corresponding CRAN Task\nView. Unlike \ncategories statistical software considered , primary\ndistinguishing feature ML software (necessarily directly)\nalgorithmic, rather pertains workflow typical machine learning tasks.\nparticular, consider ML software approach data analysis via two\nprimary steps :Passing set training data algorithm order generate \ncandidate mapping data form pre-specified output\nresponse variable. mappings referred “models”,\nsingle analysis single set training data generating one\nmodel.Passing set test data model(s) generated first step \norder derive measure predictive accuracy model.single ML task generally yields two distinct outputs:model derived first previous steps; andAssociated statistics model performance, evaluated within context\ntest data used assess performance.Click following link view demonstration Application Machine\nLearning Software Standards.Machine Learning WorkflowGiven initial considerations, now attempt difficult task \nenvisioning typical standard workflow inherently diverse ML software. \nfollowing workflow considered “extensive” workflow, shorter\nversions, correspondingly restricted sets standards, possible\ndependent upon envisioned areas application. example, workflow\npresumes input data large stored single entity local\nmemory. Adaptation situations training data can loaded \nmemory may mean following workflow stages, therefore\ncorresponding standards, may apply.Just typical workflows potentially diverse, outputs ML\nsoftware, depend areas application intended purpose \nsoftware. following refers “desired output” ML software,\nphrase intentionally left non-specific, intended \nconnote forms “response variable” “pre-specified\noutputs” categorical labels validation data, along outputs\nmay necessarily able pre-specified simple uni- \nmulti-variate form, measures distance sets training \nvalidation data.“desired outputs” presumed quantified terms “loss” \n“cost” function (hereafter, simply “loss function”) quantifying measure \ndistance model estimate (resulting applying model one \ncomponents training data set) pre-defined “valid” output\n(training), test data set (following training).Given foregoing considerations, consider typical ML workflow \nprogress (least ) following steps:Input Data Specification Obtain local copy input data, often \nmultiple objects (either -disk memory) suitably structured\nform series sub-directories accompanied additional\ndata defining structural properties input objects. Regardless \nform, multiple objects commonly given generic labels distinguish\ntraining test data, along optional additional\ncategories labels validation data used, example, \ndetermine accuracy models applied training data yet prior testing.Pre-Processing Define transformations input data, including \nrestricted , broadcasting dimensions (defined ) standardising\ndata ranges (typically defined values mean standard deviation).Model Algorithm Specification Specify model associated\nprocesses applied map input data desired\noutput. step minimally includes following distinct stages\n(generally particular order):\nSpecify kind model applied training data. ML\nsoftware often allows use pre-trained models, case \nstep includes downloading otherwise obtaining pre-trained\nmodel, along specification aspects models \nmodified application particular set training \nvalidation data.\nSpecify kind algorithm used explore search\nspace (example kind gradient descent algorithm), along \nparameters controlling algorithm applied (example\nlearning rate, defined ).\nSpecify kind loss function used quantify distance\nmodel estimates desired output.\nSpecify kind model applied training data. ML\nsoftware often allows use pre-trained models, case \nstep includes downloading otherwise obtaining pre-trained\nmodel, along specification aspects models \nmodified application particular set training \nvalidation data.Specify kind algorithm used explore search\nspace (example kind gradient descent algorithm), along \nparameters controlling algorithm applied (example\nlearning rate, defined ).Specify kind loss function used quantify distance\nmodel estimates desired output.Model Training Apply specified model training data \ngenerate series estimates specified loss function. stage\nmay also include specifying parameters stopping exit criteria,\nparameters controlling batch processing input data. Moreover, \nstage may involve retaining following additional data:\nPotential “pre-processing” stages initial estimates optimal\nlearning rates (see ).\nDetails summaries actual paths taken search space\ntowards convergence local global minimum.\nPotential “pre-processing” stages initial estimates optimal\nlearning rates (see ).Details summaries actual paths taken search space\ntowards convergence local global minimum.Model Output Performance Measure performance trained\nmodel applied test data set, generally requiring \nspecification metric model performance accuracy.Importantly, ML workflows may partly iterative. may turn potentially\nconfound distinctions training test data, accordingly confound\nexpectations commonly placed upon statistical analyses statistical\nindependence response variables. ML routines cross-validation\nrepeatedly (re-)partition data training test sets. Resultant models\ncan considered developed application \nsingle set truly “independent” data. context standards \nfollow, considerations admit potential lack clarity notional\ncategorical distinction training test data, model\nspecification training.preceding workflow mentioned couple concepts interpretations \ncontext standards may seen clicking \ncorresponding items . Following , proceed standards ML\nsoftware, enumerated developed reference preceding workflow\nsteps. order following standards initially adhere \nenumeration workflow steps given , general standards pertaining \naspects documentation testing given following initial five\n“workflow” standards.\nfollowing definition comes vignette rray\npackage named\nBroadcasting.Broadcasting , “repeating dimensions one object match \ndimensions another.”concept runs counter aspects standards categories, \noften suggest functions error passed input objects \ncommensurate dimensions. Broadcasting pre-processing step \nenables objects incommensurate dimensions dimensionally reconciled.following demonstration taken directly rray\npackage (currently CRAN).Broadcasting commonly employed ML software enables ML\noperations implemented objects incommensurate dimensions.\nOne example image analysis, training data may dimensionally\ncommensurate, yet test images may different dimensions. Broadcasting\nallows data submitted ML routines regardless potentially\nincommensurate dimensions.\nLearning Rate (generally) determines step size used search \nlocal optima fraction local gradient.parameter particularly important training ML algorithms like\nneural networks, results can sensitive \nvariations learning rates. useful overview importance \nlearning rates, useful approach automatically determining\nappropriate values, given blog\npost.Partly widespread current relevance, category Machine\nLearning software one notable attempts \ndevelop standards. particularly useful reference MLPerf\norganization , among activities, hosts\nseveral github repositories providing reference\ndatasets benchmark conditions comparing performance aspects ML\nsoftware. reference benchmark standards explicitly\nreferred current version following standards, expect \ngradually adapted incorporated start apply refine \nstandards application software submitted review system.","code":"\nlibrary (rray)\na <- array(c(1, 2), dim = c(2, 1))\nb <- array(c(3, 4), dim = c(1, 2))\n# rbind (a, b) # error!\nrray_bind (a, b, .axis = 1)\n#>      [,1] [,2]\n#> [1,]    1    1\n#> [2,]    2    2\n#> [3,]    3    4\nrray_bind (a, b, .axis = 2)\n#>      [,1] [,2] [,3]\n#> [1,]    1    3    4\n#> [2,]    2    3    4"},{"path":"standards.html","id":"input-data-specification","chapter":"6 Standards: Version 0.0.1","heading":"6.4.1 Input Data Specification","text":"Many following standards refer labelling input data \n“testing” “training” data, along potentially additional labels \n“validation” data. regard labelling, following two standards apply,ML1.0 Documentation make clear conceptual distinction\ntraining test data (even may ultimately confounded\ndescribed .)\nML1.0a terms ultimately eschewed, \nnevertheless used initial documentation, along clear\nexplanation , justification , alternative terminology.\nML1.0a terms ultimately eschewed, \nnevertheless used initial documentation, along clear\nexplanation , justification , alternative terminology.ML1.1 Absent clear justification alternative design\ndecisions, input data expected labelled “test”, “training”,\n, applicable, “validation” data.\nML1.1a presence use labels \nexplicitly confirmed via pre-processing steps (tested accordance\nML7.0, ).\nML1.1b Matches expected labels \ncase-insensitive based partial matching , example,\n“Test”, “test”, “testing” suffice.\nML1.1a presence use labels \nexplicitly confirmed via pre-processing steps (tested accordance\nML7.0, ).ML1.1b Matches expected labels \ncase-insensitive based partial matching , example,\n“Test”, “test”, “testing” suffice.following three standards (ML1.2–ML1.4) represent three possible\ndesign intentions ML software. one three generally \napplicable one piece software, although nevertheless possible\none standards may apply. first three\nstandards applies ML software intended process, capable \nprocessing, input data single (generally tabular) object.ML1.2 Training test data sets ML software \nable input single, generally tabular, data object, \ntraining test data distinguished either \nspecified variable containing, example, TRUE/FALSE 0/1\nvalues, uses system missing (NA) values \ndenote test data); /\nadditional parameter designating case row numbers, labels \ntest data.\nspecified variable containing, example, TRUE/FALSE 0/1\nvalues, uses system missing (NA) values \ndenote test data); /orAn additional parameter designating case row numbers, labels \ntest data.second three standards applies ML software intended \nprocess, capable processing, input data represented multiple objects\nexist local memory.ML1.3 Input data clearly partitioned \ntraining test data (example, passed distinct\nlist item), enable additional means categorically\ndistinguishing training test data (via additional parameter\nprovides explicit labels). applicable, distinction validation\ndata also accord standard.third three standards data input applies ML software \ndata expected input references multiple external objects,\ngenerally expected read either local remote connections.ML1.4 Training test data sets, along necessary\ncomponents validation data sets, stored \ndistinctly labelled sub-directories (distinct files), according \nexplicit distinct labelling scheme (example, database\nconnections). Labelling cases adhere ML1.1, .following standard applies ML software regardless \napplicability otherwise preceding three standards.ML1.5 ML software implement single function \nsummarises contents test training () data sets, minimally\nincluding counts numbers cases, records, files, potentially\nextending tables summaries file data types, sizes, \ninformation (unique hashes component).","code":""},{"path":"standards.html","id":"missing-values-1","chapter":"6 Standards: Version 0.0.1","heading":"6.4.1.1 Missing Values","text":"Missing data handled differently different ML routines, also\ndifficult suggest generally applicable standards pre-processing missing\nvalues ML software. General Standards \nmissing values (G2.13–G2.16) apply Machine Learning\nsoftware, place following standards attempt cover\npractical range typical approaches applications.ML1.6 ML software admit missing values, \nexpects missing values, implement explicit pre-processing\nroutines identify whether data missing values, \ngenerally error appropriately informatively passed data missing\nvalues. addition, ML software admit missing values :\nML1.6a Explain missing values admitted.\nML1.6b Provide explicit examples (function\ndocumentation, vignettes, ) missing values may imputed,\nrather simply discarded.\nML1.6a Explain missing values admitted.ML1.6b Provide explicit examples (function\ndocumentation, vignettes, ) missing values may imputed,\nrather simply discarded.ML1.7 ML software admits missing values clearly\ndocument values processed.\nML1.7a missing values imputed, software \noffer multiple user-defined ways impute missing data.\nML1.7b missing values imputed, precise\nimputation steps also explicitly documented, either tests\n(see ML7.2 ), function documentation, vignettes.\nML1.7a missing values imputed, software \noffer multiple user-defined ways impute missing data.ML1.7b missing values imputed, precise\nimputation steps also explicitly documented, either tests\n(see ML7.2 ), function documentation, vignettes.ML1.8 ML software enable equal treatment missing\nvalues training test data, optional user ability control\napplication either one .","code":""},{"path":"standards.html","id":"pre-processing","chapter":"6 Standards: Version 0.0.1","heading":"6.4.2 Pre-processing","text":"reflected workflow envisioned outset, ML software operates\nsomewhat differently statistical software many categories. \nparticular, ML software often requires explicit specification workflow,\nincluding specification input data (per standards preceding\nsub-section), transformations statistical models applied\ndata. section standards refers exclusively \ntransformation input data pre-processing step prior \nspecification , submission , actual models.ML2.0 dedicated function enable pre-processing steps\ndefined parametrized.\nML2.0a function return object can \ndirectly submitted specified model (see section 3, ).\nML2.0b Absent explicit justification otherwise, \nreturn object defined class minimally intended implement\ndefault print method summarizes input data set (per\nML1.5 ) associated transformations (see following\nstandard).\nML2.0a function return object can \ndirectly submitted specified model (see section 3, ).ML2.0b Absent explicit justification otherwise, \nreturn object defined class minimally intended implement\ndefault print method summarizes input data set (per\nML1.5 ) associated transformations (see following\nstandard).Standards categories statistical software suggest \npre-processing routines ensure input data sets commensurate,\nexample, equal numbers cases rows. contrast, ML\nsoftware commonly intended accept input data can guaranteed\ndimensionally commensurate, software intended process\nrectangular image files may different sizes.ML2.1 ML software uses broadcasting reconcile\ndimensionally incommensurate input data offer ability least\noptionally record transformations applied input file.Beyond broadcasting dimensional transformations, following standards\napply pre-processing stages ML software.ML2.2 ML software requires relies upon numeric\ntransformations input data (change mean values variances)\nallow optimal explicit specification target values, rather \nrestricting transformations default generic values (\ntransformations z-scores).\nML2.2a parameters default values, reasons\nparticular defaults explicitly described.\nML2.2b extended documentation (vignettes)\ndemonstrates use explicit values numeric transformations\nexplicitly describe particular values used.\nML2.2a parameters default values, reasons\nparticular defaults explicitly described.ML2.2b extended documentation (vignettes)\ndemonstrates use explicit values numeric transformations\nexplicitly describe particular values used.transformations applied input data, whether dimension (ML2.1)\nscale (ML2.2),ML2.3 values associated transformations \nrecorded object returned function described preceding\nstandard (ML2.0).ML2.4 Default values transformations \nexplicitly documented, documentation parameters appropriate\n(numeric transformations), extended documentation \nvignettes.ML2.5 ML software provide options bypass \notherwise switch default transformations.ML2.6 transformations implemented via distinct\nfunctions, exported package’s namespace can \napplied contexts.ML2.7 possible, documentation provided \ntransformations may reversed. example, documentation may demonstrate\nvalues retained via ML2.3, , can used along \ntransformations either exported via ML2.6 otherwise exemplified \ndemonstration code independently transform data, reverse \ntransformations.","code":""},{"path":"standards.html","id":"model-and-algorithm-specification","chapter":"6 Standards: Version 0.0.1","heading":"6.4.3 Model and Algorithm Specification","text":"“model” context ML software understood means \nspecifying mapping input output data, generally applied \ntraining validation data. Model specification step specifying\nmapping constructed. specification \nvalues model actually occurs training model, \ndescribed following sub-section. standards also refer control\nparameters specify models trained. parameters commonly\ninclude values specifying numbers iterations, training rates, parameters\ncontrolling algorithmic processes re-sampling cross-validation.ML3.0 Model specification implemented distinct\nstage subsequent specification pre-processing routines (see Section 2,\n) prior actual model fitting training (see Section 4, ).\nparticular,\nML3.0a dedicated function enable models \nspecified without actually fitting training , (ML3)\nfollowing (ML4) stages controlled single function,\nfunction parameter enabling models specified yet\nfitted (example, nofit = FALSE).\nML3.0b function accept input objects\nproduced previous Input Data Specification stage, defined\naccording ML2.0, .\nML3.0c function described (ML3.0a) \nreturn object can directly trained described \nfollowing sub-section (ML4).\nML3.0d return object defined class\nminimally intended implement default print method summarises\nmodel specification, including values relevant parameters.\nML3.0a dedicated function enable models \nspecified without actually fitting training , (ML3)\nfollowing (ML4) stages controlled single function,\nfunction parameter enabling models specified yet\nfitted (example, nofit = FALSE).ML3.0b function accept input objects\nproduced previous Input Data Specification stage, defined\naccording ML2.0, .ML3.0c function described (ML3.0a) \nreturn object can directly trained described \nfollowing sub-section (ML4).ML3.0d return object defined class\nminimally intended implement default print method summarises\nmodel specification, including values relevant parameters.ML3.1 ML software allow use untrained\nmodels, specified model parameters , well pre-trained\nmodels. Use latter commonly entails ability submit\npreviously-trained model object function defined according \nML3.0a, .ML3.2 ML software enable different models applied\nobject specifying data inputs transformations (see sub-sections\n1–2, ) without needing re-define preceding steps.function fulfilling ML3.0–3.2 might, example, permit following\narguments:data: Input data specification constructed according ML1model: optional previously-trained modelcontrol: list parameters controlling model algorithm \napplied subsequent training phase (ML4).function arguments defined fulfil preceding three\nstandards, data stage represent output ML1,\nmodel stage allow different pre-trained models \nsubmitted using data associated specifications (ML3.1). \nprovision separate .data argument fulfil ML3.2 allowing one\nmodel control parameters re-defined submitting \ndata object.ML3.3 ML software implements distinct classes \nmodel objects, properties behaviours specific classes \nobjects explicitly compared objects produced ML\nsoftware. particular, possible, ML software provide extended\ndocumentation (vignettes equivalent) comparing model objects \nML software, noting unique abilities restrictions \nimplemented classes.ML3.4 training rates used, ML software \nprovide explicit documentation functions use training\nrates, extended form vignettes, importance , /\nsensitivity , different values training rates. particular,\nML3.4a Unless explicitly justified otherwise, ML software\noffer abilities automatically determine appropriate optimal\ntraining rates, either distinct pre-processing stages, implicit\nstages model training.\nML3.4b ML software provides default values \ntraining rates clearly document anticipated restrictions \nvalidity default values; example clear suggestions\nuser-determined -specified values may generally necessary \npreferable.\nML3.4a Unless explicitly justified otherwise, ML software\noffer abilities automatically determine appropriate optimal\ntraining rates, either distinct pre-processing stages, implicit\nstages model training.ML3.4b ML software provides default values \ntraining rates clearly document anticipated restrictions \nvalidity default values; example clear suggestions\nuser-determined -specified values may generally necessary \npreferable.","code":""},{"path":"standards.html","id":"control-parameters","chapter":"6 Standards: Version 0.0.1","heading":"6.4.3.1 Control Parameters","text":"Control parameters considered specify model applied\nset training data. generally distinct parameters\nspecifying actual model (model architecture). recommend\ncontrol parameters submitted items single named list, \nneither firm expectation explicit part current standards.ML3.5 Parameters controlling optimization algorithms \nminimally include:\nML3.5a Specification type algorithm used \nexplore search space (commonly, example, kind gradient\ndescent algorithm)\nML3.5b kind loss function used assess distance\nmodel estimates desired output.\nML3.5a Specification type algorithm used \nexplore search space (commonly, example, kind gradient\ndescent algorithm)ML3.5b kind loss function used assess distance\nmodel estimates desired output.ML3.6 Unless explicitly justified otherwise (example\nML software consideration implementation one specific\nalgorithm), ML software :\nML3.6a Implement otherwise permit usage multiple\nways exploring search space\nML3.6b Implement otherwise permit usage multiple\nloss functions.\nML3.6a Implement otherwise permit usage multiple\nways exploring search spaceML3.6b Implement otherwise permit usage multiple\nloss functions.","code":""},{"path":"standards.html","id":"cpu-and-gpu-processing","chapter":"6 Standards: Version 0.0.1","heading":"6.4.3.2 CPU and GPU processing","text":"ML software often involves manipulation large numbers rectangular arrays\ngraphics processing units (GPUs) often efficient \ncentral processing units (CPUs). ML software thus commonly offers options \ntrain models using either CPUs GPUs. standards currently\nsuggest particular design choice regard, note following:ML3.7 ML software algorithms coded C++,\nuser-controlled use either CPUs GPUs (NVIDIA processors least)\nimplemented direct use \nlibcudacxx.library can “switched ” activating single C++ header file\nswitch CPU GPU.","code":""},{"path":"standards.html","id":"model-training","chapter":"6 Standards: Version 0.0.1","heading":"6.4.4 Model Training","text":"Model training stage ML workflow envisioned \nactual computation performed applying model specified according \nML3 data specified according ML1 ML2.ML4.0 ML software generally implement unified\nsingle-function interface model training, able receive input model\nspecified according preceding standards. particular, models \ncategorically different specifications, different model architectures\noptimization algorithms, able submitted model\ntraining function.ML4.1 ML software least optionally retain explicit\ninformation paths taken optimizer advances towards minimal loss.\ninformation minimally include:\nML4.1a Specification model-internal parameters, \nequivalent hashed representation.\nML4.1b value loss function point\nML4.1c Information used advance next point, \nexample quantification local gradient.\nML4.1a Specification model-internal parameters, \nequivalent hashed representation.ML4.1b value loss function pointML4.1c Information used advance next point, \nexample quantification local gradient.ML4.2 subsequent extraction information retained\naccording preceding standard explicitly documented,\nincluding example code.","code":""},{"path":"standards.html","id":"batch-processing","chapter":"6 Standards: Version 0.0.1","heading":"6.4.4.1 Batch Processing","text":"following standards apply ML software implements batch processing,\ncommonly train models data sets large loaded entirety\nmemory.ML4.3 parameters controlling batch processing \nassociated terminology explicitly documented, ,\nexample, presumed users understand definition “epoch”\nimplemented particular ML software.According standard, example inappropriate \nparameter, nepochs, described “Number epochs used model training”.\nRather, definition particular implementation “epoch” must \nexplicitly defined.ML4.4 Explicit guidance provided selection \nappropriate values parameter controlling batch processing, example,\ntrade-offs batch sizes numbers epochs (terms\nprovided Control Parameters accordance preceding standard,\nML3).ML4.5 ML software may optionally include function \nestimate likely time train specified model, estimating initial\ntimings small sample full batch.ML4.6 ML software default provide explicit\ninformation progress batch jobs (even jobs may \nimplemented parallel GPUs). information may optionally\nsuppressed additional parameters.","code":""},{"path":"standards.html","id":"re-sampling","chapter":"6 Standards: Version 0.0.1","heading":"6.4.4.2 Re-sampling","text":"described outset, ML software always rely pre-specified\ncategorical distinctions training test data. example,\nmodels may fit effectively one single data set specified\ncases rows used training data, remainder test data.\nRe-sampling generally refers practice re-defining categorical\ndistinctions training test data. One training run accordingly\nconnotes training model one particular set training data \napplying model specified set test data. Re-sampling starts \nprocess anew, constructing alternative categorical partition \ntest training data.Even test training data distinguished simple\ndata-internal category (labelling column), example,\nstored distinctly-named sub-directories, re-sampling may \nimplemented effectively shuffling data training test\nsub-directories.ML4.7 ML software provide ability combine results\nmultiple re-sampling iterations using single parameter specifying\nnumbers iterations.ML4.8 Absent additional specification, re-sampling\nalgorithms default partition data according proportions \noriginal test training data.\nML4.8a Re-sampling routines ML software \nnevertheless offer ability explicitly control override \ndefault proportions test training data.\nML4.8a Re-sampling routines ML software \nnevertheless offer ability explicitly control override \ndefault proportions test training data.","code":""},{"path":"standards.html","id":"model-output-and-performance","chapter":"6 Standards: Version 0.0.1","heading":"6.4.5 Model Output and Performance","text":"Model output considered stage distinct model performance.\nModel output refers end result model training (ML4), model\nperformance involves assessment trained model test data set.\npresent section first describes standards model output, \nstandards guiding form model trained according preceding\nstandards (ML4). Model Performance considered separate stage.","code":""},{"path":"standards.html","id":"model-output","chapter":"6 Standards: Version 0.0.1","heading":"6.4.5.1 Model Output","text":"ML5.0 result applying training processes described\ncontained within single model object returned \nfunction defined according ML4.0, . Even output\nreflects application test data set, resultant object need \ninclude information model performance (see ML5.3–ML5.4,\n).\nML5.0a object either class, \nextend previously-defined class.\nML5.0b class defined print method\nsummarises important aspects model object, including \nlimited summaries input data algorithmic control parameters.\nML5.0a object either class, \nextend previously-defined class.ML5.0b class defined print method\nsummarises important aspects model object, including \nlimited summaries input data algorithmic control parameters.ML5.1 untrained model objects produced according \nstandards, particular direct extension ML3.3,\nproperties behaviours trained models produced ML software\nexplicitly compared equivalent objects produced ML\nsoftware. (comparison generally done terms comparing model\nperformance, described following standard ML5.3–ML5.4).ML5.2 structure functionality objects representing\ntrained ML models thoroughly documented. particular,\nML5.2a Either functionality extending class\nmodel object explicitly documented, method listing\notherwise accessing associated functionality explicitly documented\ndemonstrated example code.\nML5.2b Documentation include examples \nsave re-load trained model objects re-use accordance\nML3.1, .\nML5.2c general functions saving serializing\nobjects, \nsaveRDS\nappropriate storing local copies trained models, \nexplicit function provided purpose, \ndemonstrated example code.\nML5.2a Either functionality extending class\nmodel object explicitly documented, method listing\notherwise accessing associated functionality explicitly documented\ndemonstrated example code.ML5.2b Documentation include examples \nsave re-load trained model objects re-use accordance\nML3.1, .ML5.2c general functions saving serializing\nobjects, \nsaveRDS\nappropriate storing local copies trained models, \nexplicit function provided purpose, \ndemonstrated example code.R6 system representing classes R \nexample system explicit functionality, components \naccessible simple\nls() call.\nAdherence ML5.2a nevertheless\nrequire explicit description ability \nls() \nsupply list functions associated object. mlr\npackage, example, uses R6\nclasses, yet neither explicitly describes use \nls() \nlist associated functions, explicitly lists functions.","code":""},{"path":"standards.html","id":"model-performance","chapter":"6 Standards: Version 0.0.1","heading":"6.4.5.2 Model Performance","text":"Model performance refers quantitative assessment trained model \napplied set test data.ML5.3 Assessment model performance implemented \none functions distinct model training.ML5.4 Model performance able assessed\naccording variety metrics.\nML5.4a model performance metrics represented \nfunctions internal package must clearly distinctly\ndocumented.\nML5.4b possible submit custom metrics \nmodel assessment function, ability clearly\ndocumented including example code.\nML5.4a model performance metrics represented \nfunctions internal package must clearly distinctly\ndocumented.ML5.4b possible submit custom metrics \nmodel assessment function, ability clearly\ndocumented including example code.remaining sub-sections specify general standards beyond preceding\nworkflow-specific ones.","code":""},{"path":"standards.html","id":"documentation-1","chapter":"6 Standards: Version 0.0.1","heading":"6.4.6 Documentation","text":"ML6.0 Descriptions ML software make explicit reference \nworkflow separates training testing stages, clearly\nindicates need distinct training test data sets.following standard applies packages intended able \nencompass restricted subset six primary workflow steps enumerated\noutset. Envisioned packages explicitly intended aid one\nparticular aspect general workflow envisioned , \nimplementations ML optimization functions, specific loss measures.ML6.1 ML software intentionally designed address \nrestricted subset workflow described clearly document\ncan embedded within typical full ML workflow sense\nconsidered .\nML6.1a demonstrations include contrast\nembedding within full workflow using least two packages \nimplement workflow.\nML6.1a demonstrations include contrast\nembedding within full workflow using least two packages \nimplement workflow.","code":""},{"path":"standards.html","id":"testing-2","chapter":"6 Standards: Version 0.0.1","heading":"6.4.7 Testing","text":"","code":""},{"path":"standards.html","id":"input-data-2","chapter":"6 Standards: Version 0.0.1","heading":"6.4.7.1 Input Data","text":"ML7.0 Test explicitly confirm partial \ncase-insensitive matching “test”, “train”, , applicable,\n“validation” data.ML7.1 Tests demonstrate effects different numeric\nscaling input data (see ML2.2).ML7.2 software imputes missing data, tests \ncompare internal imputation explicit code directly implements\nimputation steps (even imputation single-step implemented via\nexternal package). tests serve explicit reference \nimputation performed.","code":""},{"path":"standards.html","id":"model-classes","chapter":"6 Standards: Version 0.0.1","heading":"6.4.7.2 Model Classes","text":"following standard applies models untrained trained forms,\nconsidered respective outputs preceding standards ML3 \nML4.ML7.3 model objects implemented distinct classes,\ntests explicitly compare functionality classes \nfunctionality equivalent classes ML model objects \npackages.\nML7.3a tests explicitly identify\nrestrictions functionality model objects comparison \npackages.\nML7.3b tests explicitly identify functional\nadvantages unique abilities model objects comparison \npackages.\nML7.3a tests explicitly identify\nrestrictions functionality model objects comparison \npackages.ML7.3b tests explicitly identify functional\nadvantages unique abilities model objects comparison \npackages.","code":""},{"path":"standards.html","id":"model-training-1","chapter":"6 Standards: Version 0.0.1","heading":"6.4.7.3 Model Training","text":"ML7.4 ML software explicit document effects \ndifferent training rates, particular demonstrate divergence\noptima inappropriate training rates.ML7.5 ML software implements routines determine\noptimal training rates (see ML3.4, ) implement tests \nconfirm optimality resultant values.ML7.6 ML software implement independent training\n“epochs” demonstrate tests effects lesser versus greater\nnumbers epochs.ML7.7 ML software explicitly test different\noptimization algorithms, even software intended implement one\nspecific algorithm.ML7.8 ML software explicitly test different loss\nfunctions, even software intended implement one specific measure\nloss.ML7.9 Tests explicitly compare possible\ncombinations categorical differences model architecture, \ndifferent model architectures optimization algorithms, model\narchitectures different optimization algorithms, differences \n.\nML7.9a combinations generally formed \nmultiple categorical factors, explicit use functions \nexpand.grid()\nrecommended.\nML7.9a combinations generally formed \nmultiple categorical factors, explicit use functions \nexpand.grid()\nrecommended.following example illustrates:possible combinations categorical parameters tested\niterating rows output.ML7.10 successful extraction information paths\ntaken optimizers (see ML5.1, ), tested, including\ntesting general properties, necessarily actual values , \ndata.","code":"\narchitechture <- c (\"archA\", \"archB\")\noptimizers <- c (\"optA\", \"optB\", \"optC\")\ncost_fns <- c (\"costA\", \"costB\", \"costC\")\nexpand.grid (architechture, optimizers, cost_fns)##     Var1 Var2  Var3\n## 1  archA optA costA\n## 2  archB optA costA\n## 3  archA optB costA\n## 4  archB optB costA\n## 5  archA optC costA\n## 6  archB optC costA\n## 7  archA optA costB\n## 8  archB optA costB\n## 9  archA optB costB\n## 10 archB optB costB\n## 11 archA optC costB\n## 12 archB optC costB\n## 13 archA optA costC\n## 14 archB optA costC\n## 15 archA optB costC\n## 16 archB optB costC\n## 17 archA optC costC\n## 18 archB optC costC"},{"path":"standards.html","id":"model-performance-1","chapter":"6 Standards: Version 0.0.1","heading":"6.4.7.4 Model Performance","text":"ML7.11 performance metrics available given class \ntrained model thoroughly tested compared.\nML7.11a Tests compare metrics \nrange inputs (generally implying differently trained models) \ndemonstrate relative advantages disadvantages different metrics.\nML7.11a Tests compare metrics \nrange inputs (generally implying differently trained models) \ndemonstrate relative advantages disadvantages different metrics.","code":""},{"path":"standards.html","id":"standards-regression","chapter":"6 Standards: Version 0.0.1","heading":"6.5 Regression and Supervised Learning","text":"sub-section details standards Regression Supervised Learning\nSoftware – referred simplicity “Regression Software”.\nRegression Software implements algorithms aim construct analyse one\nmappings two defined data sets (example, set \n“independent” data, \\(X\\), set “dependent” data, \\(Y\\)). contrast, \nanalogous category Unsupervised Learning Software aims construct \nanalyse one mappings defined set input independent\ndata, second set “output” data necessarily known \ngiven prior analysis.Common purposes Regression Software fit models estimate\nrelationships make predictions specified inputs outputs.\nRegression Software includes tools inferential predictive foci,\nBayesian, frequentist, probability-free Machine Learning (ML) approaches,\nparametric non-parametric approaches, discrete outputs (\nclassification tasks) continuous outputs, models algorithms specific\napplications data time series spatial data. many cases\nstandards specific subcategories may apply.Examples diversity Regression Unsupervised Learning software\ninclude following.xrnet perform\n“hierarchical regularized regression incorporate external data”, \n“external data” case refers structured meta-data applied \ngenomic features.survPen , “\nR package hazard excess hazard modelling multidimensional\npenalized splines”areal , “\nR package areal weighted interpolation”.ChiRP package\n“Chinese Restaurant Process mixtures regression clustering”,\nimplements class non-parametric Bayesian Monte Carlo models.klrfome package\n, “kernel logistic regression focal mean embeddings,” specific\nexclusive application prediction likely archaeological sites.gravity package\n“estimation methods gravity models R,” “gravity models”\nrefers models spatial interactions point locations based \nproperties locations.compboost \nexample R package gradient boosting, inherently\nregression-based technique, standards regression software\nconsider applications.ungroup , “\nR package efficient estimation smooth distributions coarsely\nbinned data.” , package example regression-based\nsoftware input data (effectively) categorical. \npackage primarily intended implement particular method \n“unbinning” data, represents particular class \ninterpolation methods.registr \npackage “registration exponential family functional data,” \nregistration context effectively interpolation method\napplied within functional data analysis context.ggeffects “tidy\ndata frames marginal effects regression models.” package aims\nmake statistics quantifying marginal effects readily understandable, \nimplements standard (tidyverse-based) methodology representing \nvisualising statistics relating marginal effects.Click following link view demonstration Application Regression\nSupervised Learning Standards.following standards divided among several sub-categories, \nstandard prefixed “RE”.","code":""},{"path":"standards.html","id":"input-data-structures-and-validation-1","chapter":"6 Standards: Version 0.0.1","heading":"6.5.1 Input data structures and validation","text":"RE1.0 Regression Software enable models specified\nvia formula interface, unless reasons explicitly\ndocumented.RE1.1 Regression Software document formula\ninterfaces converted matrix representations input data.See Max Kuhn’s RStudio blog\npost\nexamples implement describe conversions.RE1.2 Regression Software document expected format\n(types classes) inputting predictor variables, including descriptions\ntypes classes accepted.Examples documentation addressing standard include clarifying \nsoftware accepts numeric inputs vector matrix form, \ninputs must data.frame form column row names.RE1.3 Regression Software passes otherwise transforms\naspects input data onto output structures ensure output\nstructures retain relevant aspects input data, notably including row\ncolumn names, potentially information attributes().\nRE1.3a otherwise relevant information \ntransferred, explicitly documented.\nRE1.3a otherwise relevant information \ntransferred, explicitly documented.standard reflects common process regression software \ntransforming rectangular input structure modified version \nincludes additional columns model fits predictions. Software \nconstructs modified versions anew often copies numeric values input\ncolumns, may implicitly drop additional information attributes.\nstandard requires information retained.RE1.4 Regression Software document assumptions made\nregard input data; example distributional assumptions, \nassumptions predictor data mean values zero. Implications \nviolations assumptions documented tested.","code":""},{"path":"standards.html","id":"pre-processing-and-variable-transformation","chapter":"6 Standards: Version 0.0.1","heading":"6.5.2 Pre-processing and Variable Transformation","text":"RE2.0 Regression Software document transformations\napplied input data, example conversion label-values factor,\nprovide ways explicitly avoid default transformations (\nerror warning conditions appropriate).RE2.1 Regression Software implement explicit parameters\ncontrolling processing missing values, ideally distinguishing NA \nNaN values Inf values (example, use na.omit() \nrelated functions stats package).Note fulfilling standard ensures compliance General\nStandard missing values (G2.13–G2.16).RE2.2 Regression Software provide different options \nprocessing missing values predictor response data. example, \npossible fit model missing predictor data order \ngenerate values associated response points, even submitted\nresponse values may missing.RE2.3 applicable, Regression Software enable data\ncentred (example, converting zero-mean equivalent\nvalues; z-scores) offset (example, zero-intercept equivalent\nvalues) via additional parameters, effects parameters\nclearly documented tested.RE2.4 Regression Software implement pre-processing\nroutines identify whether aspects input data perfectly collinear,\nnotably including:\nRE2.4a Perfect collinearity among predictor variables\nRE2.4b Perfect collinearity independent \ndependent variables\nRE2.4a Perfect collinearity among predictor variablesRE2.4b Perfect collinearity independent \ndependent variablesThese pre-processing routines also tested described .","code":""},{"path":"standards.html","id":"algorithms-1","chapter":"6 Standards: Version 0.0.1","heading":"6.5.3 Algorithms","text":"following standards apply model fitting algorithms Regression\nSoftware implement rely iterative algorithms expected\nconverge generate model statistics. Regression Software implements\nrelies iterative convergence algorithms :RE3.0 Issue appropriate warnings diagnostic messages\nmodels fail converge.RE3.1 Enable messages optionally suppressed, yet\nensure resultant model object nevertheless includes\nsufficient data identify lack convergence.RE3.2 Ensure convergence thresholds sensible default\nvalues, demonstrated explicit documentation.RE3.3 Allow explicit setting convergence thresholds, unless\nreasons explicitly documented.","code":""},{"path":"standards.html","id":"return-results","chapter":"6 Standards: Version 0.0.1","heading":"6.5.4 Return Results","text":"RE4.0 Regression Software return form “model”\nobject, generally using modifying existing class structures \nmodel objects (lm, glm, model objects packages), \ncreating new class model objects.RE4.1 Regression Software may enable ability generate\nmodel object without actually fitting values. may useful \ncontrolling batch processing computationally intensive fitting\nalgorithms.","code":""},{"path":"standards.html","id":"accessor-methods","chapter":"6 Standards: Version 0.0.1","heading":"6.5.4.1 Accessor Methods","text":"Regression Software provide functions access extract much \nfollowing kinds model data possible practicable. Access \nideally rely class-specific methods extend, implement otherwise\nequivalent versions , methods stats package named \nparentheses following standards.Model objects include, otherwise enable effectively immediate access\nfollowing descriptors. acknowledged regression models\ncan sensibly provide access descriptors, yet include access\nprovisions applicable.RE4.2 Model coefficients (via coeff() / coefficients())RE4.3 Confidence intervals coefficients (via\nconfint())RE4.4 specification model, generally formula\n(via formula())RE4.5 Numbers observations submitted model (via\nnobs())RE4.6 variance-covariance matrix model parameters\n(via vcov())RE4.7 appropriate, convergence statisticsNote compliance RE4.6 also heed General Standard\nG3.1 offering user control covariance algorithms. Regression\nSoftware provide simple direct methods return \notherwise access following form data metadata, latter\nincludes information transformations may applied \ndata prior submission modelling routines.RE4.8 Response variables, associated “metadata” \napplicable.RE4.9 Modelled values response variables.RE4.10 Model Residuals, including sufficient documentation \nenable interpretation residuals, enable users submit residuals\ntests.RE4.11 Goodness--fit statistics associated \neffect sizes model coefficients.RE4.12 appropriate, functions used transform input\ndata, associated inverse transform functions.Regression software may additionally opt provide simple direct methods\nreturn otherwise access following:RE4.13 Predictor variables, associated “metadata” \napplicable.","code":""},{"path":"standards.html","id":"prediction-extrapolation-and-forecasting","chapter":"6 Standards: Version 0.0.1","heading":"6.5.4.2 Prediction, Extrapolation, and Forecasting","text":"regression software intended , can, provide distinct abilities\nextrapolate forecast. Moreover, identifying cases regression\nmodel used extrapolate forecast may often non-trivial exercise.\nmay nevertheless possible, example input data used construct\nmodel unidimensional, data prediction based\nextend beyond range used construct model. reasonably\nunambiguous identification extrapolation forecasting using model \npossible, following standards apply:RE4.14 possible, values also provided \nextrapolation forecast errors.RE4.15 Sufficient documentation /testing \nprovided demonstrate forecast errors, confidence intervals, \nequivalent values increase forecast horizons.Distinct extrapolation forecasting abilities, following standard\napplies regression software relies , otherwise provides abilities\nprocess, categorical grouping variables:RE4.16 Regression Software models distinct responses\ndifferent categorical groups include ability submit new\ngroups predict() methods.","code":""},{"path":"standards.html","id":"reporting-return-results","chapter":"6 Standards: Version 0.0.1","heading":"6.5.4.3 Reporting Return Results","text":"RE4.17 Model objects returned Regression Software \nimplement appropriately extend default print method provides \n-screen summary model (input) parameters (output) coefficients.RE4.18 Regression Software may also implement summary\nmethods model objects, particular implement distinct\nsummary methods cases calculation summary statistics \ncomputationally non-trivial (example, bootstrapped estimates \nconfidence intervals).","code":""},{"path":"standards.html","id":"documentation-2","chapter":"6 Standards: Version 0.0.1","heading":"6.5.5 Documentation","text":"Beyond General Standards documentation,\nRegression Software explicitly describe following aspects, \nideally provide extended documentation including summary graphical reports :RE5.0 Scaling relationships sizes input data\n(numbers observations, potential extension numbers \nvariables/columns) speed algorithm.","code":""},{"path":"standards.html","id":"visualization","chapter":"6 Standards: Version 0.0.1","heading":"6.5.6 Visualization","text":"RE6.0 Model objects returned Regression Software (see\nRE4) default plot methods, either explicit\nimplementation, extension methods existing model objects, \nensuring default methods work appropriately.RE6.1 default plot method generic\nplot method dispatched class return objects (, \nS3-type plot.<myclass> function equivalent), method dispatch (\nequivalent) nevertheless exist order explicitly direct users \nappropriate function.RE6.2 default plot method produce plot \nfitted values model, optional visualisation confidence\nintervals equivalent.following standard applies software fulfilling RE4.14-4.15, \nconditions described prior standards.RE6.3 model object used generate forecast (\nexample, predict() method), default plot method \nprovide clear visual distinction modelled (interpolated) forecast\n(extrapolated) values.","code":""},{"path":"standards.html","id":"testing-3","chapter":"6 Standards: Version 0.0.1","heading":"6.5.7 Testing","text":"","code":""},{"path":"standards.html","id":"input-data-3","chapter":"6 Standards: Version 0.0.1","heading":"6.5.7.1 Input Data","text":"Tests Regression Software include following conditions cases:RE7.0 Tests noiseless, exact relationships \npredictor (independent) data.\nRE7.0a particular, tests confirm ability\nreject perfectly noiseless input data.\nRE7.0a particular, tests confirm ability\nreject perfectly noiseless input data.RE7.1 Tests noiseless, exact relationships \npredictor (independent) response (dependent) data.\nRE7.1a particular, tests confirm \nmodel fitting least fast (preferably) faster testing\nequivalent noisy data (see RE2.4b).\nRE7.1a particular, tests confirm \nmodel fitting least fast (preferably) faster testing\nequivalent noisy data (see RE2.4b).","code":""},{"path":"standards.html","id":"return-results-1","chapter":"6 Standards: Version 0.0.1","heading":"6.5.7.2 Return Results","text":"Tests Regression Software shouldRE7.2 Demonstrate output objects retain aspects input\ndata row case names (see RE1.3).RE7.3 Demonstrate test expected behaviour objects\nreturned regression software submitted accessor methods \nRE4.2–RE4.7.RE7.4 Extending directly RE4.15, appropriate,\ntests demonstrate confirm forecast errors, confidence\nintervals, equivalent values increase forecast horizons.","code":""},{"path":"standards.html","id":"spatial-software","chapter":"6 Standards: Version 0.0.1","heading":"6.6 Spatial Software","text":"Standards spatial software begin consideration standardisation\ndomains applicability. Following proceed standards according\nspatial software presumed perform one following\nsteps:Accept validate input dataApply one analytic algorithmsReturn result algorithmic applicationOffer additional functionality printing summarising return resultsTestingEach standard spatial software prefixed “SP”.","code":""},{"path":"standards.html","id":"spatial-domains","chapter":"6 Standards: Version 0.0.1","heading":"6.6.1 Spatial Domains","text":"Many developers spatial software R, including many \nfeatured CRAN Task view “Analysis Spatial\nData”, primarily\nfocussed geographic data; , data quantifying positions, structures,\nrelationships Earth planets. Spatial analyses \nnevertheless broader general geography alone. particular,\nspatial software may geometric – , concerned \npositions, structures, relationships space general specific\nsense, necessarily confined geographic systems alone.important distinguish two domains many algorithms \nprocedures devised one two domains necessarily (directly)\napplicable , commonly geometric algorithms presume\nspace rectilinear Cartesian, geographic algorithms (generally)\npresume specific curvilinear form (commonly spherical \nelliptical). Algorithms designed Cartesian space may directly\napplicable curvilinear space, vice-versa.Moreover, spatial software algorithms might intended apply spaces\narbitrary dimensionality. phrase “Cartesian” refers space \narbitrary dimensionality dimensions orthogonal described\nstraight lines; dimensions curvilinear space arbitrary\ndimensionality described curved lines. planar geometry \ntwo-dimensional Cartesian space; spherical geometry two- (maybe\nthree-)dimensional curvilinear space.One earliest still widely used R spatial packages,\nspatstat (first released\n2002), describes , “[f]ocused mainly two-dimensional point\npatterns, including multitype/marked points, spatial region.” Routines\npackage thus generally applicable two-dimensional Cartesian\ndata , even final phrase might interpreted indicate\ncomprehensive generality. spatstat routines may necessarily give\naccurate results applied curvilinear space.considerations motivate first standard spatial software:SP1.0 Spatial software explicitly indicate domain\napplicability, particular distinguish whether software may \napplied Cartesian/rectilinear/geometric domains, curvilinear/geographic\ndomains, .encourage use clear unambiguous phrases “planar”,\n“spherical”, “Cartesian”, “rectilinear” “curvilinear”, along clear\nindications dimensionality “two-” “three-dimensional.” Concepts\ndimensionality interpreted refer explicitly \ndimensionality independent spatial coordinates. Elevation third spatial\ndimension, time may also considered additional dimension. Beyond\ntwo, attributes measured spatial locations represent\nadditional dimensions.SP1.1 Spatial software explicitly indicate \ndimensional domain applicability, particular identifying\nwhether applicable two three dimensions , whether \nrestrictions dimensionality.considerations domains applicability permeate much ensuring\nstandards, distinguish “geometric software” “geographic software”,\nphrases interpreted shorthand references software\nintended use respective domains.","code":""},{"path":"standards.html","id":"input-data-structures-and-validation-2","chapter":"6 Standards: Version 0.0.1","heading":"6.6.2 Input data structures and validation","text":"Input validation important software task, important part \nstandards. many ways approach validation, class systems\nR offer particularly convenient effective means. Spatial\nSoftware particular, range class systems developed, \nrefer CRAN Task view “Analysis Spatial\nData”. Software uses\nrelies defined classes can often validate input affirming\nappropriate class(es). Software use rely class systems\ngenerally need specific routines validate input data structures.standards Time-Series\nSoftware,\nstandards Spatial Software also suggest software use\nexplicit class systems designed intended spatial data. New packages may\nimplement new class systems spatial data, may even simple\nappending class attribute matrix coordinates. primary\nmotivation following standard nevertheless encourage enhance\ninter-operability rich system classes spatial data R.SP2.0 Spatial software accept input data one \nclasses explicitly developed represent data.\nSP2.0a new classes implemented, conversion \ncommon classes spatial data R documented.\nSP2.0b Class systems ensure functions error\nappropriately, rather merely warning, response data \ninappropriate spatial domains.\nSP2.0a new classes implemented, conversion \ncommon classes spatial data R documented.SP2.0b Class systems ensure functions error\nappropriately, rather merely warning, response data \ninappropriate spatial domains.Spatial Workflows, Packages, ClassesSpatial software encompasses enormous diversity, yet workflows implemented\nspatial software often share much common. particular, coordinate\nreference systems used precisely relate pairs coordinates precise\nlocations curvilinear space, particular Earth’s ellipsoid,\nneed able compared transformed regardless specificities\nindividual software. ubiquitous need fostered development \nPROJ library representing transforming\nspatial coordinates. Several libraries built top \nalongside , notably including GDAL (“Geospatial Data Abstraction\nLibrary”) GEOS (“Geometry Engine, Open\nSource”) libraries. libraries used ,\nintegrated within, geographical spatial software commonly used today,\nlikely continue used.standard , expected spatial software \n, absent convincing explicit justification, attempt reconstruct\naspects generic libraries. Given , following standards aim \nensure spatial software remains compatible possible workflows\nestablished preceding packages aimed expose integrate \nmuch functionality generic libraries possible. use \nspecific class systems spatial data, workflows encapsulated \nassociated packages, ensures maximal ongoing compatibility \nlibraries spatial workflows general.Notable class systems associated packages R include\nsp,\nsf, \nraster, recent extensions \nstars,\nterra, \ns2. regard packages, \nfollowing single standard applies, maintainer sp made \nclear new software build upon sf, \nsp.SP2.1 Spatial Software use sp\npackage, rather use\nsf.generally,SP2.2 Geographical Spatial Software ensure maximal\ncompatibility established packages workflows, minimally :\nSP2.2a Clear extensive documentation demonstrating\nroutines software may embedded within, otherwise\nadapted , workflows rely established packages; \nSP2.2b Tests clearly demonstrate routines \nsoftware may successfully translated forms workflows\nrely established packages.\nSP2.2a Clear extensive documentation demonstrating\nroutines software may embedded within, otherwise\nadapted , workflows rely established packages; andSP2.2b Tests clearly demonstrate routines \nsoftware may successfully translated forms workflows\nrely established packages.standard refined number subsequent standards concerning\ndocumentation testing.SP2.3 Software accepts spatial input data \nstandard format established R packages (formats\nable read GDAL, therefore sf\npackage) include example \ntest code load data spatial formats, rather R-specific\nbinary formats .Rds.See sf vignette “Reading, Writing Converting Simple\nFeatures” \nuseful examples.Coordinate Reference SystemsAs described , one primary reasons development classes\nSpatial Software represent coordinate reference systems \ndata represented, ensure compatibility PROJ\nsystem generic spatial libraries. \nPROJ standards associated software library \nrecently (2020) updated (version number 7) “breaking changes” \nbackwards-compatible previous versions, particular \nlong-standing version 4. details implications changes within\ncontext spatial software R can examined blog\nentry \nr-spatial.org, \nvignette\nrgdal package. \n“breaking” nature updates partly reflects analogous “breaking changes”\nassociated updates “Well-Known Text”\n(WKT) system \nrepresenting coordinate reference systems.following standard applies software directly indirectly relies\ngeographic data uses relies upon coordinate reference systems.SP2.4 Geographical Spatial Software compliant \nversion 6 larger PROJ, WKT2\nrepresentations. primary implication, described detail \narticles linked , :\nSP2.4a Software permit coordinate reference\nsystems represented merely -called “PROJ4-strings”, \nuse least WKT2.\nSP2.4a Software permit coordinate reference\nsystems represented merely -called “PROJ4-strings”, \nuse least WKT2.General Input StructuresNew spatial software may nevertheless eschew prior packages classes\nfavour implementing new classes. Whether prior classes used \nexpected, geographic software accord much possible \nprinciples prior systems according following standards:SP2.5 Class systems input data must contain meta data \nassociated coordinate reference systems.\nSP2.5a Software implements new classes input\nspatial data (spatial components general data) \nprovide ability convert input objects alternative spatial\nclasses listed .\nSP2.5a Software implements new classes input\nspatial data (spatial components general data) \nprovide ability convert input objects alternative spatial\nclasses listed .SP2.6 Spatial Software explicitly document types\nclasses input data able passed function.SP2.7 Spatial Software implement validation routines \nconfirm inputs acceptable classes (represented otherwise\nappropriate ways software use class systems).SP2.8 Spatial Software implement single\npre-processing routine validate input data, appropriately transform\nsingle uniform type passed subsequent data-processing\nfunctions.SP2.9 pre-processing function described \nmaintain metadata attributes input data relevant \nimportant core algorithms return values.","code":""},{"path":"standards.html","id":"algorithms-2","chapter":"6 Standards: Version 0.0.1","heading":"6.6.3 Algorithms","text":"following standards conditionally applicable \nspatial software. Procedures standards deemed applicable \nparticular piece software described srr\npackage.SP3.0 Spatial software considers spatial neighbours\nenable user control neighbourhood forms sizes. \nparticular:\nSP3.0a Neighbours (able expressed) regular grids\nable considered rectangular , rectangular\ndiagonal (respectively “rook” “queen” analogy chess).\nSP3.0b Neighbourhoods irregular spaces \nminimally able controlled via integer number neighbours, \narea (equivalent distance defining area) include\nneighbours, otherwise equivalent user-controlled value.\nSP3.0a Neighbours (able expressed) regular grids\nable considered rectangular , rectangular\ndiagonal (respectively “rook” “queen” analogy chess).SP3.0b Neighbourhoods irregular spaces \nminimally able controlled via integer number neighbours, \narea (equivalent distance defining area) include\nneighbours, otherwise equivalent user-controlled value.SP3.1 Spatial software considers spatial neighbours\nwherever possible enable neighbour contributions weighted \ndistance (continuous weighting variable), rely exclusively\nuniform-weight rectangular cut-.SP3.2 Spatial software relies sampling input\ndata (even spatial coordinates) enable sampling procedures\nbased local spatial densities input data.example software adhere SP3.2 \ninput data simple matrix spatial coordinates, sampling \nimplemented using sample()\nfunction\nrandomly select elements input data\n(like sample(nrow(xy), n)). context example based \nsample()\nfunction,\nadhering standard require including additional prob vector\npoint weighted local density surrounding points. \nlead higher probabilities samples taken central\nclusters higher densities outlying extreme points. Note \nstandard merely suggests software enable density-based\nsamples taken, must, even necessarily default.Algorithms spatial software often related categories \nstatistical software, anticipated spatial software commonly\nalso subject standards categories. Nevertheless, \nspatial analyses frequently face unique challenges, \ncategory-specific standards also extension standards applied \nspatial software. following standards applicable spatial\nsoftware also fits listed categories statistical\nsoftware.Regression SoftwareSP3.3 Spatial regression software explicitly quantify\ndistinguish autocovariant autoregressive processes \ncovariant regressive processes directly related spatial structure\nalone.Unsupervised Learning SoftwareThe following standard applies spatial unsupervised learning software\nuses clustering algorithms.SP3.4 possible, spatial clustering software avoid\nusing standard non-spatial clustering algorithms spatial proximity\nmerely represented additional weighting factor favour \nexplicitly spatial algorithms.Machine Learning SoftwareOne common application machine learning algorithms applied \nspatial software analyses raster images. first following\nstandards applies individual cells pixels raster images\nrepresent fixed spatial coordinates. (standard also renders ML2.1\ninapplicable).SP3.5 Spatial machine learning software ensure \nbroadcasting procedures reconciling inputs different dimensions \napplied.definition broadcasting given end introduction \ncorresponding Machine Learning Standards, just\nInput Data Specification.SP3.6 Spatial machine learning software document (,\npossible, test) potential effects different sampling proceduresA simple example might provide examples extended documentation \ncompares effects sampling test training data \nspatial region versus sampling distinct regions. Although \ncomparable General Standard Machine Learning\nSoftware, procedures sampling spatial data may \nparticularly pronounced effects results, standard attempts \nfoster “best practice” documenting effects may arise given\npiece software.concrete example may demonstrate particular technique \ngenerating distinct test training data spatial partitioning\n(Muenchow 2019; Brenning 2012; Schratz et al. 2019; Valavi et al. 2019).\nmay nevertheless cases sampling common\nspatial region appropriate, example software intended analyse \nmodel temporally-structured spatial data appropriate\ndistinction might temporal rather spatial. Adherence standard\nmerely requires potential confounding effects \nexplicitly documented (possibly tested well).","code":""},{"path":"standards.html","id":"return-results-2","chapter":"6 Standards: Version 0.0.1","heading":"6.6.4 Return Results","text":"(functions within) Spatial Software return spatial data:SP4.0 Return values either:\nSP4.0a class input data, \nSP4.0b unique, preferably class-defined, format.\nSP4.0a class input data, orSP4.0b unique, preferably class-defined, format.SP4.1 aspects input data included output\ndata (either directly, transformed form) contain units\nensure units maintained return values.SP4.2 type class return values \nexplicitly documented.","code":""},{"path":"standards.html","id":"visualization-1","chapter":"6 Standards: Version 0.0.1","heading":"6.6.5 Visualization","text":"Spatial Software returns objects custom class structure explicitly\ndesigned represent include spatial data :SP5.0 Implement default plot methods implemented\nclass system.SP5.1 Implement appropriate placement variables along x-\ny-axes.SP5.2 Ensure axis labels include appropriate units.example SP5.1 might ensuring longitude placed \nx-axis, latitude y, although standard orientations may depend \ncoordinate reference systems aspects data software design.\npreceding three standards generally apply software \nreturns objects custom class structure yet inherently\nspatial.Spatial Software returns objects geographical coordinates :SP5.3 Offer ability generate interactive (generally\nhtml-based) visualisations results.","code":""},{"path":"standards.html","id":"testing-4","chapter":"6 Standards: Version 0.0.1","heading":"6.6.6 Testing","text":"following standards apply Spatial Software intended able\napplied data represented curvilinear systems, notably including \ngeographical data. Spatial Software following standards\n(necessarily) apply software explicitly intended applied\nexclusively Cartesian spatial data, ensured appropriate rejection\ncurvilinear data according SP2.0b.Round-Trip TestsSP6.0 Software implements routines transforming\ncoordinates input data include tests demonstrate ability \nrecover original coordinates.standard applicable software implements routines \ncoordinate transformations, even routines implemented via\nPROJ. Conversely, software routines \ncoordinate transformations need adhere SP6.0, even software\nrelies PROJ purposes.SP6.1 functions can applied Cartesian \ncurvilinear data tested application .\nSP6.1a Functions may yield inaccurate results \napplied data one forms (preceding examples\ncentroids buffers ellipsoidal data) test results\ninappropriate application functions indeed less\naccurate.\nSP6.1b Functions yield accurate results regardless\nwhether input data rectilinear curvilinear demonstrate\nequivalent accuracy cases, also demonstrate \nequivalent results may obtained first explicitly transforming\ninput data.\nSP6.1a Functions may yield inaccurate results \napplied data one forms (preceding examples\ncentroids buffers ellipsoidal data) test results\ninappropriate application functions indeed less\naccurate.SP6.1b Functions yield accurate results regardless\nwhether input data rectilinear curvilinear demonstrate\nequivalent accuracy cases, also demonstrate \nequivalent results may obtained first explicitly transforming\ninput data.Extreme Geographical CoordinatesSP6.2 Geographical Software include tests extreme\ngeographical coordinates, minimally including extension polar extremes \n+/-90 degrees.tests generally confirm software generates reliable\nresults extreme coordinates, software unable generate\nreliable results inputs nevertheless include tests indicate\napproximate bounds reliability, expected characteristics \nunreliable results.remaining standards testing Spatial Software extend directly \npreceding Algorithmic Standards (SP3), sub-section headings\nused .SP6.3 Spatial Software considers spatial neighbours\nexplicitly test possible ways defining , \nexplicitly compare quantitative effects different ways defining\nneighbours.SP6.4 Spatial Software considers spatial neighbours\nexplicitly test effects different schemes weight neighbours \nspatial proximity.Unsupervised Learning SoftwareSP6.5 Spatial Unsupervised Learning Software uses\nclustering algorithms implement tests explicitly compare results\nequivalent results obtained non-spatial clustering algorithm.Machine Learning SoftwareSP6.6 *Spatial Machine Learning Software implement tests\nexplicitly demonstrate detrimental consequences sampling test\ntraining data spatial region, rather spatially\ndistinct regions.","code":""},{"path":"standards.html","id":"standards-time-series","chapter":"6 Standards: Version 0.0.1","heading":"6.7 Time Series Software","text":"category Time Series software arguably easier define \npreceding categories, represents software primary input \nintended temporally structured data. Importantly, “temporally\nstructured” may often imply temporally ordered, need necessarily \ncase. primary definition temporally structured data \npossess kind index can used extract temporal relationships.Time series software presumed perform one following steps:Accept validate input dataApply data transformation pre-processing stepsApply one analytic algorithmsReturn result algorithmic applicationOffer additional functionality printing summarising return resultsThis document details standards steps, prefixed “TS”.","code":""},{"path":"standards.html","id":"input-data-structures-and-validation-3","chapter":"6 Standards: Version 0.0.1","heading":"6.7.1 Input data structures and validation","text":"Input validation important software task, important part \nstandards. many ways approach validation, class systems\nR offer particularly convenient effective means. Time Series\nSoftware particular, range class systems developed, \nrefer section “Time Series Classes” CRAN Task view Time\nSeries Analysis\", \nclass-conversion package tsbox. Software \nuses relies defined classes can often validate input affirming\nappropriate class(es). Software use rely class systems\ngenerally need specific routines validate input data structures. \nparticular, long history time series software R, \nvariety class systems representing time series data, new time series\npackages accept many different classes input possible \naccording following standards:TS1.0 Time Series Software use rely explicit\nclass systems developed representing time series data, \npermit generic, non-time-series inputThe core algorithms time-series software often ultimately applied \nsimple vector objects, time series software accepts simple vector\ninputs, assuming represent temporally sequential data. Permitting \ngeneric inputs nevertheless prevents assumptions asserted\ntested. Missing values pose particular problems regard. simple\nna.omit() call similar shorten length vector removing\nNA values, change explicit temporal relationship \nelements. use explicit classes time series generally ensures \nability explicitly assert properties strict temporal regularity, \ncontrol deviation expected properties.TS1.1 Time Series Software explicitly document \ntypes classes input data able passed function.documentation include demonstration input data \nleast one commonly used class time-series \nts.TS1.2 Time Series Software implement validation\nroutines confirm inputs acceptable classes (represented \notherwise appropriate ways software use class systems).TS1.3 Time Series Software implement single\npre-processing routine validate input data, appropriately transform\nsingle uniform type passed subsequent data-processing\nfunctions (tsbox package provides one\nconvenient approach ).TS1.4 pre-processing function described \nmaintain time- date-based components attributes input data.Time Series Software relies implements custom classes types\nrepresenting time-series data, following standards adhered\n:TS1.5 software ensure strict ordering time,\nfrequency, equivalent ordering index variable.TS1.6 violations ordering caught \npre-processing stages functions.","code":""},{"path":"standards.html","id":"time-intervals-and-relative-time","chapter":"6 Standards: Version 0.0.1","heading":"6.7.1.1 Time Intervals and Relative Time","text":"common packages classes time series data assume absolute\ntemporal scales represented POSIX\nclasses\ndates times, time series may also quantified relative scales\ntemporal index variable quantifies intervals rather absolute\ntimes dates. Many analytic routines accept time series inputs \nabsolute form also appropriately applied analogous data relative\nform, thus many packages accept time series inputs absolute\nrelative forms. Software can accept times series inputs \nrelative form :TS1.7 Accept inputs defined via units\npackage attributing SI units \nR vectors.TS1.8 time intervals periods may days months,\nexplicit system used represent , particularly regarding\nwhether calendar system used, whether year presumed 365\ndays, 365.2422 days, value.","code":""},{"path":"standards.html","id":"pre-processing-and-variable-transformation-1","chapter":"6 Standards: Version 0.0.1","heading":"6.7.2 Pre-processing and Variable Transformation","text":"","code":""},{"path":"standards.html","id":"missing-data","chapter":"6 Standards: Version 0.0.1","heading":"6.7.2.1 Missing Data","text":"One critical pre-processing step Time Series Software appropriate\nhandling missing data. convenient distinguish implicit\nexplicit missing data. regular time series, explicit missing data may\nrepresented NA values, irregular time series, implicit\nmissing data may represented missing rows. difference demonstrated\nfollowing table.\nMissing Values\nvalue 08:46 implicitly missing, value 08:44 \nexplicitly missing. two forms missingness may connote different\nthings, may require different forms pre-processing. mind,\nbeyond General Standards missing data\n(G2.13–G2.16), following standards apply:TS2.0 Time Series Software presumes requires regular\ndata allow explicit missing values, issue\nappropriate diagnostic messages, potentially including errors, response \nimplicit missing values.TS2.1 possible, functions provide options \nusers specify handle missing data, options minimally\nincluding:\nTS2.1a *error missing data; .\nTS2.1b warn ignore missing data, proceed analyse\nirregular data, ensuring results function calls regular yet\nmissing data return identical values submitting equivalent irregular\ndata missing values; \nTS2.1c replace missing data appropriately imputed\nvalues.\nTS2.1a *error missing data; .TS2.1b warn ignore missing data, proceed analyse\nirregular data, ensuring results function calls regular yet\nmissing data return identical values submitting equivalent irregular\ndata missing values; orTS2.1c replace missing data appropriately imputed\nvalues.latter standard modified version General Standard G2.14,\nadditional requirements via TS2.1b.","code":""},{"path":"standards.html","id":"stationarity","chapter":"6 Standards: Version 0.0.1","heading":"6.7.2.2 Stationarity","text":"Time Series Software explicitly document assumptions requirements\nmade respect stationarity otherwise input data. \nparticular, (sub-)functions assume rely stationarity :TS2.2 *Consider stationarity relevant moments\ntypically first (mean) second (variance) order, otherwise document\nconsideration may restricted lower orders .*\ntypically first (mean) second (variance) order, otherwise document\nconsideration may restricted lower orders .*TS2.3 Explicitly document assumptions /requirements\nstationarityTS2.4 Implement appropriate checks relevant forms \nstationarity, either:\nTS2.4a issue diagnostic messages warnings; \nTS2.4b enable advise appropriate transformations \nensure stationarity.\nTS2.4a issue diagnostic messages warnings; orTS2.4b enable advise appropriate transformations \nensure stationarity.two options last point (TS2.4b) respectively translate enabling\ntransformations ensure stationarity providing appropriate routines,\ngenerally triggered function parameter, advising appropriate\ntransformations, example directing users additional functions able \nimplement appropriate transformations.","code":""},{"path":"standards.html","id":"covariance-matrices","chapter":"6 Standards: Version 0.0.1","heading":"6.7.2.3 Covariance Matrices","text":"covariance matrices constructed otherwise used within input\nfunctions, :TS2.5 Incorporate system ensure row column\norders follow ordering underlying time series data. may,\nexample, done including index attribute time series\ndata attribute covariance matrix.TS2.6 applicable, covariance matrices also\ninclude specification appropriate units.General Standard G3.1 also applies Time Series Software \nconstructs uses covariance matrices.","code":""},{"path":"standards.html","id":"analytic-algorithms-2","chapter":"6 Standards: Version 0.0.1","heading":"6.7.3 Analytic Algorithms","text":"Analytic algorithms considered reflect core analytic components\nTime Series Software. may many varied, explicitly\nconsider small subset .","code":""},{"path":"standards.html","id":"forecasting","chapter":"6 Standards: Version 0.0.1","heading":"6.7.3.1 Forecasting","text":"Statistical software implements forecasting routines :TS3.0 Provide tests demonstrate least one case \nerrors widen appropriately forecast horizon.TS3.1 possible, provide least one test violates\nTS3.0TS3.2 Document general drivers forecast errors \nhorizons, demonstrated via particular cases TS3.0 TS3.1TS3.3 Either:\nTS3.3a Document, preferable via example, trim\nforecast values based specified error margin equivalent; \nTS3.3b Provide explicit mechanism trim forecast\nvalues specified error margin, either via explicit\npost-processing function, via input parameter primary analytic\nfunction.\nTS3.3a Document, preferable via example, trim\nforecast values based specified error margin equivalent; orTS3.3b Provide explicit mechanism trim forecast\nvalues specified error margin, either via explicit\npost-processing function, via input parameter primary analytic\nfunction.","code":""},{"path":"standards.html","id":"return-results-3","chapter":"6 Standards: Version 0.0.1","heading":"6.7.4 Return Results","text":"(functions within) Time Series Software return time series data:TS4.0 Return values either:\nTS4.0a class input data, example \nusing tsbox package re-convert \nstandard internal format (see 1.4, ); \nTS4.0b unique, preferably class-defined, format.\nTS4.0a class input data, example \nusing tsbox package re-convert \nstandard internal format (see 1.4, ); orTS4.0b unique, preferably class-defined, format.TS4.1 units included attributes input data \nalso included within return values.TS4.2 type class return values \nexplicitly documented.(functions within) Time Series Software return data direct\nseries:TS4.3 Return values explicitly include appropriate\nunits /time scales","code":""},{"path":"standards.html","id":"data-transformation","chapter":"6 Standards: Version 0.0.1","heading":"6.7.4.1 Data Transformation","text":"Time Series Software internally implements routines transforming data\nachieve stationarity returns forecast values :TS4.4 Document effect transformations \nforecast data, including potential effects first- second-order\nestimates.TS4.5 decreasing order preference, either:\nTS4.5a Provide explicit routines options \nback-transform data commensurate original, non-stationary input\ndata\nTS4.5b Demonstrate data may back-transformed \nform commensurate original, non-stationary input data.\nTS4.5c Document associated limitations forecast\nvalues\nTS4.5a Provide explicit routines options \nback-transform data commensurate original, non-stationary input\ndataTS4.5b Demonstrate data may back-transformed \nform commensurate original, non-stationary input data.TS4.5c Document associated limitations forecast\nvalues","code":""},{"path":"standards.html","id":"forecasting-1","chapter":"6 Standards: Version 0.0.1","heading":"6.7.4.2 Forecasting","text":"Time Series Software implements otherwise enables forecasting\nabilities, return one following three kinds information.\npresented decreasing order preference, software\nstrive return first kind object, failing second, \nthird last resort.TS4.6 Time Series Software implements otherwise\nenables forecasting return either:\nTS4.6a distribution object, example via one \nmany packages described CRAN Task View Probability\nDistributions\n(new distributional\npackage used \nfable package time-series\nforecasting).\nTS4.6b variable forecast, predicted values\nequivalent first- second-order moments (example, mean \nstandard error values).\nTS4.6c general indication error associated\nforecast estimates.\nTS4.6a distribution object, example via one \nmany packages described CRAN Task View Probability\nDistributions\n(new distributional\npackage used \nfable package time-series\nforecasting).TS4.6b variable forecast, predicted values\nequivalent first- second-order moments (example, mean \nstandard error values).TS4.6c general indication error associated\nforecast estimates.Beyond particular standards return objects, Time Series Software\nimplements otherwise enables forecasting :TS4.7 Ensure forecast (modelled) values clearly\ndistinguished observed (model input) values, either (case \norder preference) \nTS4.7a Returning forecast values alone\nTS4.7b Returning distinct list items model \nforecast values\nTS4.7c Combining model forecast values single\nreturn object appropriate additional column clearly\ndistinguishing two kinds data.\nTS4.7a Returning forecast values aloneTS4.7b Returning distinct list items model \nforecast valuesTS4.7c Combining model forecast values single\nreturn object appropriate additional column clearly\ndistinguishing two kinds data.","code":""},{"path":"standards.html","id":"visualization-2","chapter":"6 Standards: Version 0.0.1","heading":"6.7.5 Visualization","text":"Time Series Software :TS5.0 Implement default plot methods implemented\nclass system.TS5.1 representing results temporal domain(s), ensure\none axis clearly labelled “time” (equivalent), continuous\nunits.TS5.2 Default placing “time” (equivalent) variable\nhorizontal axis.TS5.3 Ensure units time, frequency, index\nvariable printed default axis.TS5.4 frequency visualization, abscissa spanning\n\\([-\\pi, \\pi]\\) avoided favour positive units \\([0, 2\\pi]\\) \n\\([0, 0.5]\\), cases appropriate additional explanation units.TS5.5 Provide options determine whether plots data \nmissing values generate continuous broken lines.results forecast operations, Time Series Software shouldTS5.6 default indicate distributional limits forecast \nplotTS5.7 default include model (input) values plot, well\nforecast (output) valuesTS5.8 default provide clear visual distinction \nmodel (input) values forecast (output) values.","code":""},{"path":"standards.html","id":"dimensionality-reduction-clustering-and-unsupervised-learning","chapter":"6 Standards: Version 0.0.1","heading":"6.8 Dimensionality Reduction, Clustering, and Unsupervised Learning","text":"sub-section details standards Dimensionality Reduction, Clustering,\nUnsupervised Learning Software – referred simplicity\n“Unsupervised Learning Software”. Software category distinguished\nRegression Software though latter aiming construct analyse one\nmappings two defined data sets (example, set \n“independent” data, \\(X\\), set “dependent” data, “Y”), whereas\nUnsupervised Learning Software aims construct analyse one \nmappings defined set input independent data, second set\n“output” data necessarily known given prior \nanalysis. key distinction Unsupervised Learning Software Algorithms \noutput data represent (generally numerical)\ntransformations input data set, output data \ndiscrete labels applied input data. Examples former type include\ndimensionality reduction ordination software algorithms, examples\nlatter include clustering discrete partitioning software \nalgorithms.examples Dimensionality Reduction, Clustering, Unsupervised\nLearning software include:ivis implements\ndimensionality reduction technique using \"Siamese Neural Network\narchitecture.tsfeaturex \npackage automate “time series feature extraction,” also provides\nexample package input output data generally\nincomparable packages category.iRF another\nexample generally incomparable package within category, one\nfeatures extracted distinct predictive features\nextracted repeated iterations random forest algorithms.compboost \npackage component-wise gradient boosting may sufficient\ngeneral potentially allow general application problems addressed \nseveral packages category.iml package may\noffer usable functionality devising general assessments software\nwithin category, offering “toolbox making machine\nlearning models interpretable” “model agnostic” way.Click following link view demonstration Application \nDimensionality Reduction, Clustering, Unsupervised Learning\nStandards.","code":""},{"path":"standards.html","id":"input-data-structures-and-validation-4","chapter":"6 Standards: Version 0.0.1","heading":"6.8.1 Input Data Structures and Validation","text":"UL1.0 Unsupervised Learning Software explicitly\ndocument expected format (types classes) input data, including\ndescriptions types classes accepted; example,\nspecification software accepts numeric inputs vector \nmatrix form, inputs must data.frame form \ncolumn row names.UL1.1 Unsupervised Learning Software provide distinct\nsub-routines assert input data expected form, issue\ninformative error messages incompatible data submitted.following code demonstrates example routine base stats\npackage fails meet standard.latter fails, yet issues uninformative error message clearly\nindicates failure provide sufficient checks class input data.UL1.2 Unsupervised learning uses row column names \nlabel output objects assert input data non-default row \ncolumn names, issue informative message provided.messages need necessarily provided default, least\noptionally available.\ndata.frame function inserts default row column names \nexplicitly specified.Generic row names almost always simple integer sequences, \nfollowing condition confirms.Generic column names may come variety formats. following code uses\ngrep expression match number characters plus optional leading\nzero followed generic sequence column numbers, appropriate matching\ncolumn names produced generic construction data.frame objects.Messages issued cases.following code illustrates hclust function implement\nchecks assertions, rather silently returns object \ndefault labels.UL1.3 Unsupervised Learning Software transfer \nrelevant aspects input data, notably including row column names, \npotentially information attributes(), corresponding aspects\nreturn objects.\nUL1.3a otherwise relevant information \ntransferred, explicitly documented.\nUL1.3a otherwise relevant information \ntransferred, explicitly documented.example function according UL1.3 \nstats::cutree()row names USArrests transferred output object. contrast,\nroutines cluster\npackage comply standard:case labels appropriately carried object returned \nagnes()\nenable transferred within\ncutree().\n(labels transferred object returned agnes, just \nway enables cutree inherit .)UL1.4 Unsupervised Learning Software document \nassumptions made regard input data; example assumptions \ndistributional forms locations (data centred \napproximately equivalent distributional scales). Implications violations\nassumptions documented tested, particular:\nUL1.4a Software responds qualitatively differently\ninput data components markedly different scales \nexplicitly document differences, implications submitting \ndata.\nUL1.4b Examples documentation use\nscale() equivalent transformations without explaining scale \napplied, explicitly illustrating contrasting consequences \napplying transformations.\nUL1.4a Software responds qualitatively differently\ninput data components markedly different scales \nexplicitly document differences, implications submitting \ndata.UL1.4b Examples documentation use\nscale() equivalent transformations without explaining scale \napplied, explicitly illustrating contrasting consequences \napplying transformations.","code":"\nd <- dist (USArrests) # example from help file for 'hclust' function\nhc <- hclust (d) # okay\nhc <- hclust (as.matrix (d))\n#> Error in if (is.na(n) || n > 65536L) stop(\"size cannot be NA nor exceed 65536\"): missing value where TRUE/FALSE needed\nx <- data.frame (matrix (1:10, ncol = 2))\nx\n#>   X1 X2\n#> 1  1  6\n#> 2  2  7\n#> 3  3  8\n#> 4  4  9\n#> 5  5 10\nidentical (rownames (x), as.character (seq (nrow (x))))\n#> [1] TRUE\nall (vapply (seq (ncol (x)), function (i)\n             grepl (paste0 (\"[[:alpha:]]0?\", i), colnames (x) [i]), logical (1)))\n#> [1] TRUE\nu <- USArrests\nrownames (u) <- seq (nrow (u))\nhc <- hclust (dist (u))\nhead (hc$labels)\n#> [1] \"1\" \"2\" \"3\" \"4\" \"5\" \"6\"\nhc <- hclust (dist (USArrests))\nhead (cutree (hc, 10))\n#>    Alabama     Alaska    Arizona   Arkansas California   Colorado \n#>          1          2          3          4          5          4\nlibrary (cluster)\nac <- agnes (USArrests) # agglomerative nesting\nhead (cutree (ac, 10))\n#> [1] 1 2 3 4 3 4"},{"path":"standards.html","id":"pre-processing-and-variable-transformation-2","chapter":"6 Standards: Version 0.0.1","heading":"6.8.2 Pre-processing and Variable Transformation","text":"UL2.0 Routines likely give unreliable irreproducible\nresults response violations assumptions regarding input data (see\nUL1.6) implement pre-processing steps diagnose potential\nviolations, issue appropriately informative messages, /include\nparameters enable suitable transformations applied.Example compliance standard documentation entries \ncenter scale. parameters \nstats::prcomp()\nfunction.UL2.1 Unsupervised Learning Software document \ntransformations applied input data, example conversion label-values\nfactor, provide ways explicitly avoid default\ntransformations (error warning conditions appropriate).UL2.2 Unsupervised Learning Software accepts missing\nvalues input data implement explicit parameters controlling \nprocessing missing values, ideally distinguishing NA NaN values\nInf values.standard applies beyond General Standards G2.13–G2.16, \nadditional requirement implementing explicit parameters.UL2.3 Unsupervised Learning Software implement\npre-processing routines identify whether aspects input data \nperfectly collinear.","code":""},{"path":"standards.html","id":"algorithms-3","chapter":"6 Standards: Version 0.0.1","heading":"6.8.3 Algorithms","text":"","code":""},{"path":"standards.html","id":"labelling","chapter":"6 Standards: Version 0.0.1","heading":"6.8.3.1 Labelling","text":"UL3.0 Algorithms apply sequential labels input data\n(clustering partitioning algorithms) ensure \nsequence follows decreasing group sizes (labels “1”, “”, “”\ndescribe largest group, “2”, “b”, “B” second largest, .)Note stats::cutree()\nfunction\naccord standard:cutree()\nfunction\napplies arbitrary integer labels groups, yet order labels \nrelated order group sizes.UL3.1 Dimensionality reduction equivalent algorithms \nlabel dimensions ensure sequences labels follows\ndecreasing “importance” (example, eigenvalues variance\ncontributions).\nstats::prcomp\nfunction accords standard:proportion variance explained component decreasing \nincreasing numeric labelling components.UL3.2 Unsupervised Learning Software input data \ngenerally include labels (array-like data row names)\nprovide additional parameter enable cases labelled.","code":"\nhc <- hclust (dist (USArrests))\ntable (cutree (hc, k = 10))\n#> \n#>  1  2  3  4  5  6  7  8  9 10 \n#>  3  3  3  6  5 10  2  5  5  8\nz <- prcomp (eurodist, rank = 5) # return maximum of 5 components\nsummary (z)\n#> Importance of first k=5 (out of 21) components:\n#>                              PC1       PC2       PC3       PC4       PC5\n#> Standard deviation     2529.6298 2157.3434 1459.4839 551.68183 369.10901\n#> Proportion of Variance    0.4591    0.3339    0.1528   0.02184   0.00977\n#> Cumulative Proportion     0.4591    0.7930    0.9458   0.96764   0.97741"},{"path":"standards.html","id":"prediction","chapter":"6 Standards: Version 0.0.1","heading":"6.8.3.2 Prediction","text":"UL3.3 applicable, Unsupervised Learning Software \nimplement routines predict properties (numerical ordinates, \ncluster memberships) additional new data without re-running entire\nalgorithm.many algorithms Hierarchical clustering can (readily) used\npredict memberships new data, algorithms can nevertheless \napplied perform task. following demonstrates output \nstats::hclust\ncan used predict membership new data using class:knn()\nfunction.\n(intended illustrate one many possible approaches.)stats::prcomp()\nfunction\nimplements predict() method conforms standard:","code":"\nlibrary (class)\n#> \n#> Attaching package: 'class'\n#> The following object is masked from 'package:igraph':\n#> \n#>     knn\nset.seed (1)\nhc <- hclust (dist (iris [, -5]))\ngroups <- cutree (hc, k = 3)\n# function to randomly select part of a data.frame and # add some randomness\nsample_df <- function (x, n = 5) {\n    x [sample (nrow (x), size = n), ] + runif (ncol (x) * n)\n}\niris_new <- sample_df (iris [, -5], n = 5)\n# use knn to predict membership of those new points:\nknnClust <- knn (train = iris [, -5], test = iris_new , k = 1, cl = groups)\nknnClust\n#> [1] 2 2 1 1 2\n#> Levels: 1 2 3\nres <- prcomp (USArrests)\narrests_new <- sample_df (USArrests, n = 5)\npredict (res, newdata = arrests_new)\n#>                      PC1        PC2        PC3       PC4\n#> North Carolina 165.17494 -30.693263 -11.682811  1.304563\n#> Maryland       129.44401  -4.132644  -2.161693  1.258237\n#> Ohio           -49.51994  12.748248   2.104966 -2.777463\n#> Colorado        35.78896  14.023774  12.869816  1.233391\n#> Georgia         41.28054  -7.203986   3.987152 -7.818416"},{"path":"standards.html","id":"group-distributions-and-associated-statistics","chapter":"6 Standards: Version 0.0.1","heading":"6.8.3.3 Group Distributions and Associated Statistics","text":"Many unsupervised learning algorithms serve label, categorise, partition\ndata. Software performs tasks commonly output kind\nlabelling grouping schemes. example principal components\nillustrates return object records standard deviations associated\ncomponent:output accords following standard:UL3.4 Objects returned Unsupervised Learning Software\nlabels, categorise, partitions data discrete groups \ninclude, provide immediate access , quantitative information \nintra-group variances equivalent, well inter-group relationships\napplicable.example principal components one inter-group\nrelationships, standard fulfilled providing information \nintra-group variances alone. Discrete clustering algorithms, contrast, yield\nresults inter-group relationships meaningful, \nrelationships can generally meaningfully provided. hclust()\nroutine,\nlike many clustering routines, simply returns scheme devising \narbitrary number clusters, \ncan meaningfully provide variances relationships . \ncutree()\nfunction,\nhowever, yield defined numbers clusters, yet devoid quantitative\ninformation variances equivalent.Compare output largely equivalent routine, clara()\nfunction\ncluster package.object contains information dissimilarities observation\ncluster medoids, context UL3.4 “information \nintra-group variances equivalent”. Moreover, inter-group information also\navailable \n“silhouette”\nclustering scheme.","code":"\nres <- prcomp (USArrests)\nprint(res)\n#> Standard deviations (1, .., p=4):\n#> [1] 83.732400 14.212402  6.489426  2.482790\n#> \n#> Rotation (n x k) = (4 x 4):\n#>                 PC1         PC2         PC3         PC4\n#> Murder   0.04170432 -0.04482166  0.07989066 -0.99492173\n#> Assault  0.99522128 -0.05876003 -0.06756974  0.03893830\n#> UrbanPop 0.04633575  0.97685748 -0.20054629 -0.05816914\n#> Rape     0.07515550  0.20071807  0.97408059  0.07232502\nsummary (res)\n#> Importance of components:\n#>                            PC1      PC2    PC3     PC4\n#> Standard deviation     83.7324 14.21240 6.4894 2.48279\n#> Proportion of Variance  0.9655  0.02782 0.0058 0.00085\n#> Cumulative Proportion   0.9655  0.99335 0.9991 1.00000\nres <- hclust (dist (USArrests))\nstr (cutree (res, k = 5))\n#>  Named int [1:50] 1 1 1 2 1 2 3 1 4 2 ...\n#>  - attr(*, \"names\")= chr [1:50] \"Alabama\" \"Alaska\" \"Arizona\" \"Arkansas\" ...\nlibrary (cluster)\ncl <- clara (USArrests, k = 10) # direct clustering into specified number of clusters\ncl$clusinfo\n#>       size  max_diss   av_diss isolation\n#>  [1,]    4 24.708298 14.284874 1.4837745\n#>  [2,]    6 28.857755 16.759943 1.7329563\n#>  [3,]    6 44.640565 23.718040 0.9677229\n#>  [4,]    6 28.005892 17.382196 0.8442061\n#>  [5,]    6 15.901258  9.363471 1.1037219\n#>  [6,]    7 29.407822 14.817031 0.9080598\n#>  [7,]    4 11.764353  6.781659 0.8165753\n#>  [8,]    3  8.766984  5.768183 0.3547323\n#>  [9,]    3 18.848077 10.101505 0.7176276\n#> [10,]    5 16.477257  8.468541 0.6273603"},{"path":"standards.html","id":"return-results-4","chapter":"6 Standards: Version 0.0.1","heading":"6.8.4 Return Results","text":"UL4.0 Unsupervised Learning Software return form\n“model” object, generally using modifying existing class\nstructures model objects, creating new class model objects.UL4.1 Unsupervised Learning Software may enable ability \ngenerate model object without actually fitting values. may useful\ncontrolling batch processing computationally intensive fitting\nalgorithms.UL4.2 return object Unsupervised Learning Software\ninclude, otherwise enable immediate extraction , parameters\nused control algorithm used.","code":""},{"path":"standards.html","id":"reporting-return-results-1","chapter":"6 Standards: Version 0.0.1","heading":"6.8.4.1 Reporting Return Results","text":"UL4.3 Model objects returned Unsupervised Learning Software\nimplement appropriately extend default print method \nprovides -screen summary model (input) parameters methods used \ngenerate results. print method may also summarise statistical aspects\noutput data results.\nUL4.3a default print method always ensure\nrestricted number rows result matrices equivalent \nprinted screen.\nUL4.3a default print method always ensure\nrestricted number rows result matrices equivalent \nprinted screen.prcomp\nobjects\nreturned function name include potential large matrices \ncomponent coordinates default printed entirety \nscreen. default print behaviour tabular objects \nR (matrix, data.frame, objects Matrix package, example)\nprint objects entirety (limited options \ngetOption(\"max.print\"), determines maximal numbers printed objects,\nlines data.frame objects). default behaviour \navoided, particularly Unsupervised Learning Software commonly returns\nobjects containing large numbers numeric entries.UL4.4 Unsupervised Learning Software also implement\nsummary methods model objects summarise primary\nstatistics used generating model (numbers observations,\nparameters methods applied). summary method may also provide summary\nstatistics resultant model.","code":""},{"path":"standards.html","id":"documentation-3","chapter":"6 Standards: Version 0.0.1","heading":"6.8.5 Documentation","text":"","code":""},{"path":"standards.html","id":"visualization-3","chapter":"6 Standards: Version 0.0.1","heading":"6.8.6 Visualization","text":"UL6.0 Objects returned Unsupervised Learning Software\ndefault plot methods, either explicit implementation,\nextension methods existing model objects, ensuring default\nmethods work appropriately, explicit reference helper packages\nfactoextra \nassociated functions.UL6.1 default plot method generic\nplot method dispatched class return objects (, \nS3-type plot.<myclass> function equivalent), method dispatch (\nequivalent) nevertheless exist order explicitly direct users \nappropriate function.UL6.2 default plot methods include labelling components\nreturn objects (cluster labels), routines ensure \nlabels automatically placed ensure readability, /\nappropriate diagnostic messages issued readability likely \ncompromised (example, attempting place many labels).","code":""},{"path":"standards.html","id":"testing-5","chapter":"6 Standards: Version 0.0.1","heading":"6.8.7 Testing","text":"Unsupervised Learning Software test following properties \nbehaviours:UL7.0 Inappropriate types input data rejected \nexpected error messages.","code":""},{"path":"standards.html","id":"input-scaling","chapter":"6 Standards: Version 0.0.1","heading":"6.8.7.1 Input Scaling","text":"following tests implement Unsupervised Learning Software \ninputs presumed required scaled particular ways (\nmean values zero).UL7.1 Tests demonstrate violations assumed\ninput properties yield unreliable invalid outputs, clarify \nunreliability invalidity manifest properties \nreturned objects.","code":""},{"path":"standards.html","id":"output-labelling","chapter":"6 Standards: Version 0.0.1","heading":"6.8.7.2 Output Labelling","text":"regard labelling output data, tests Unsupervised Learning\nSoftware :UL7.2 Demonstrate labels placed output data follow\ndecreasing group sizes (UL3.0)UL7.3 *Demonstrate labels input data propagated ,\nmay recovered , output data.","code":""},{"path":"standards.html","id":"prediction-1","chapter":"6 Standards: Version 0.0.1","heading":"6.8.7.3 Prediction","text":"regard prediction, tests Unsupervised Learning Software :UL7.4 Demonstrate submission new data previously\nfitted model can generate results efficiently initial model\nfitting.","code":""},{"path":"standards.html","id":"batch-processing-1","chapter":"6 Standards: Version 0.0.1","heading":"6.8.7.4 Batch Processing","text":"Unsupervised Learning Software implements batch processing routines:UL7.5 Batch processing routines explicitly tested,\ncommonly via extended tests (see G4.10–G4.12).\nUL7.5a Tests batch processing routines \ndemonstrate equivalent results obtained direct (non-batch)\nprocessing.\nUL7.5a Tests batch processing routines \ndemonstrate equivalent results obtained direct (non-batch)\nprocessing.","code":""},{"path":"appendices.html","id":"appendices","chapter":"A Appendices","heading":"A Appendices","text":"","code":""},{"path":"appendices.html","id":"python","chapter":"A Appendices","heading":"A.1 Notes on Scope and the Python Statistical Ecosystem","text":"Two factors may usefully noted regard:potential number python packages statistical analyses likely\nrelatively restricted relative numbers R packages.\nTaking indicative presentations previous three Joint Statistical\nMeetings (JSMs; 2018-2020), python packages referred \nabstract, 32 R packages presented, along two\nmeta-platforms R packages. Presentations Symposium Data\nScience Statistics (SDSS) 2018-19 similarly including numerous\npresentations R packages, along presentation \nthree\npython\npackages. may accordingly \nexpected potential expansion include python packages demand\nrelatively little time effort compared devoted R\npackages primary software scope.spite , community python users enormously greater,\nreflected currently 311,915 packages compared \n17,751 packages CRAN, 17 times \nmany python packages. Similarly, 41.7% respondents 2019\nstackoverflow developer\nsurvey nominated python \npopular language, compared 5.8% nominated R.relative importance python powerfully reflected temporal trends\nstackoverflow developer\nsurvey previous three\nyears, results shown following graphic.Python used loved R, statistics \npython consistently grown faster rate past three years \nequivalent statistics R.languages nevertheless relative well-defined standards software\npackaging, python via Python Package Index\n(pypi), R\nvia CRAN. contrast CRAN, runs \nchecks packages daily basis, automatic checks \npypi packages, \nalmost form package minimally conforms standards may \nsubmitted. much lower effective barrier entry likely partially\ncontributes far greater numbers \npypi\n(311,915) \nCRAN (17,751) packages.","code":""},{"path":"appendices.html","id":"appendix-categories","chapter":"A Appendices","heading":"A.2 Empirical Derivation of Categories","text":"attempted derive realistic categorisation using empirical data\nseveral sources potential software submissions, including \napparently “statistical” R packages published Journal Open Source\nSoftware (JOSS), packages published Journal \nStatistical Software, software presented \n2018 2019 Joint Statistical Meetings (JSM), Symposia Data\nScience Statistics (SDSS), well CRAN task views. also compiled\nlist descriptions packages rejected \nrOpenSci\ncurrent scope current inability consider\nstatistical packages, along selection recent statistical\nR packages\naccepted JOSS. (full list R package published JOSS can \nviewed https://joss.theoj.org/papers///R).allocated one key words (phrases) abstract, use \nfrequencies inter-connections inform following\ncategorisation represented interactive\ngraphic\n(also included Appendix), derived \nanalyses abstracts statistical software submitted rOpenSci\nJOSS. (Several additional analyses graphical representations \nraw data included auxiliary github\nrepository.) primary\nnodes emerge empirical analyses (associated relative\nsizes parentheses) shown following table.Table .1: frequent key words JOSS abstracts (N = 92) statistical software. Proportions scaled per abstract, abstract generally multiple key words, sum proportions exceeds one.top key words inter-relationships within main network\ndiagram\nused distinguish following primary categories representing \nterms appear 5% abstracts, along two additional\ncategories “spatial” “education”. excluded key word\n“Estimates” generic usefully inform standards, also\ncollected strongly-connected terms single categories.Table .2: Proposed categorisation statistical software, corresponding proportions JOSS software matching categoryThe full network diagram can reduced categories ,\ninterconnections weighted first- second-order interconnections\nintermediate categories, give following, simplified diagram\n(“scores” denotes “statistical indices scores”; diagram\nbest inspected dragging individual nodes see connections \nothers).Standards considered ensuing categories must developed \nreference inter-relationships categories, particular \npotential ambiguity within categorisation. example \nambiguity, potential difficulties associated categorisation, \ncategory “network” software appropriate describes \ngrapherator package (\naccompanying JOSS paper)\neffectively distribution generator data represented \nparticular format happens represent graph; three JSM\npresentations, one network-based clustering high-dimensional\ndata,\none community structure dynamic\nnetworks\none Gaussian graphical\nmodels.\nStandards derived network software must accommodate diversity \napplications, must accommodate software “network” category\nmay pertain relatively minor aspect, primary algorithms\nroutines may related network software direct way.","code":"#> `summarise()` has grouped output by 'from'. You can override using the `.groups` argument.\n#> `summarise()` has grouped output by 'from'. You can override using the `.groups` argument."},{"path":"appendices.html","id":"appendix-keywords","chapter":"A Appendices","heading":"A.3 Analysis of statistical software keywords","text":"\nJOSS\nconducts peer review process, publishes textual descriptions \naccepted software. piece software web page \njournal’s site, text presented compiled .pdf-format\ndocument, along links open review, well software\nrepository. published document must included within software\nrepository file named paper.md, enables automatic extraction \nanalysis text descriptions software. Rather attempt\ncomprehensive, unavoidably subjective, categorization software, \ntextual descriptions used identify key words phrases (hereafter,\n“keywords”) encapsulated purpose, function, general\ndescriptive elements piece software. paper generally yielded\nmultiple keywords. Extracting papers judged potentially \nscope allowed construction network topics, nodes\nkey words phrases, connections pair nodes\nreflected number times two keywords co-occurred across papers.extracted papers accepted published JOSS (217 time \nwriting early 2020), manually determined broadly\nstatistical, reducing total 92. read contents \n, recorded many keywords possible paper. \nresultant network shown following interactive graphic, nodes\nscaled numbers occurrences, edges numbers co-occurrences.\n(click\n\nfull-screen version link code.)network visualization enables immediate identification less\ncentral concepts including, case, several may otherwise \nconceived potentially scope. used network \ndefine set key “scope” concepts. figure also reveals many\nkeywords somewhat “lower level” kinds concepts \nmight otherwise used define scoping categories. example, keywords\n“likelihood” “probability” likely useful defining\nactual categories statistical software, yet turned lie \ncentres relatively well-defined groups related keywords.also examined forms input output data 92\npieces software described JOSS papers, constructed \nadditional\ngraph\ndirectionally relating different data formats.","code":"#> `summarise()` has grouped output by 'from'. You can override using the `.groups` argument."},{"path":"appendices.html","id":"appendix-other-software-standards","chapter":"A Appendices","heading":"A.4 Other Software Standards","text":"Among noteworthy instances software standards, following \nparticularly relevant:Core Infrastructure Initiative’s Best Practices\nBadge, granted \nsoftware meeting extensive list \ncriteria.\nlist criteria provides singularly useful reference software\nstandards.Software Sustainability Institute’s\nSoftware Evaluation\nGuide,\nparticular guide Criteria-based software\nevaluation,\nconsiders two primary categories Usability Sustainability\nMaintainability, divided numerous sub-categories.\nguide identifies numerous concrete criteria sub-category,\nexplicitly detailed order provide example kind \nstandards might adapted developed application present\nproject.Transparent Statistics\nGuidelines, “HCI\n(Human Computer Interaction) Working Group”. currently \nbeginning phases, document aims provide concrete guidance \n“transparent statistical communication.” development continues, \nlikely provide useful guidelines best practices statistical\nsoftware produces reports results.technical considerations Object Management\nGroup’s Automated Source Code CISQ\nMaintainability Measure (CISQ\nrefers Consortium Software\nQuality). guide describes number \nmeasures can automatically extracted used quantify \nmaintainability source code. None measures already\nconsidered one preceding two documents, \nidentification measures particularly amenable automated assessment\nprovides particularly useful reference.also rOpenSci’s guide package development, maintenance, peer\nreview, provides standards type\nR packages, primarily within first chapter. Another notable example \ntidyverse design guide, \nsection Conventions R Modeling\nPackages \nprovides guidance model-fitting APIs.Specific standards neural network algorithms also developed \npart google 2019 Summer Code\nproject, resulting dedicated\nR package, NNbenchmark,\naccompanying results—-called\n“notebooks”—\napplying benchmarks suite neural network packages.","code":""},{"path":"appendices.html","id":"bibliography","chapter":"A Appendices","heading":"A.5 Bibliography","text":"Brenning, . 2012. “Spatial Cross-Validation Bootstrap Assessment Prediction Rules Remote Sensing: R Package Sperrorest.” 2012 IEEE International Geoscience Remote Sensing Symposium, 5372–5. https://doi.org/10.1109/IGARSS.2012.6352393.Estivill-Castro, Vladimir. 2002. “Many Clustering Algorithms: Position Paper.” ACM SIGKDD Explorations Newsletter 4 (1): 65–75. https://doi.org/10.1145/568574.568575.Muenchow, Jannes, Jakub Nowosad. 2019. Chapter 11 Statistical Learning Geocomputation R. https://geocompr.robinlovelace.net/.Schratz, Patrick, Jannes Muenchow, Eugenia Iturritxa, Jakob Richter, Alexander Brenning. 2019. “Hyperparameter Tuning Performance Assessment Statistical Machine-Learning Algorithms Using Spatial Data.” Ecological Modelling 406 (August): 109–20. https://doi.org/10.1016/j.ecolmodel.2019.06.002.Valavi, Roozbeh, Jane Elith, José J. Lahoz‐Monfort, Gurutzeta Guillera‐Arroita. 2019. “blockCV: R Package Generating Spatially Environmentally Separated Folds K-Fold Cross-Validation Species Distribution Models.” Methods Ecology Evolution 10 (2): 225–32. https://doi.org/https://doi.org/10.1111/2041-210X.13107.","code":""}]
